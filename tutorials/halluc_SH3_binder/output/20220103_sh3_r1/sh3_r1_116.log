/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[22:34:09] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 116, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_116, length 87...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.2333      1.8118      2.9661      0.0004      1.3878
          10      1.0685      1.7454      2.8948      0.0001      0.7021
          20      1.0044      1.7634      2.9365      0.1313      0.0599
          30      1.0075      1.6805      2.8777      0.2212      0.0372
          40      0.9295      1.6443      2.8579      0.0000      0.1451
          50      1.1474      1.6125      2.9547      0.5496      0.0708
          60      1.1063      1.5760      2.9575      0.3351      0.3278
          70      0.9055      1.5381      2.9437      0.0000      0.0454
          80      0.9129      1.6393      2.9049      0.0003      0.0200
          90      1.0900      1.5600      2.9330      0.4560      0.0451
         100      1.2051      1.6259      2.9302      0.7235      0.0221
         110      0.9448      1.7050      2.9330      0.0351      0.0161
         120      0.9290      1.6476      2.9473      0.0000      0.0501
         130      0.9365      1.5585      2.9576      0.0686      0.0291
         140      0.9814      1.6499      2.9326      0.1585      0.0074
         150      1.2456      1.6106      2.9597      0.8222      0.0132
         160      1.1350      1.6433      2.9526      0.5369      0.0053
         170      0.9257      1.6634      2.9509      0.0002      0.0138
         180      1.0812      1.5712      2.8259      0.4952      0.0186
         190      0.9579      1.5541      2.9165      0.1386      0.0414
         200      1.2820      1.5706      2.8965      0.9682      0.0066
         210      1.0122      1.5905      2.8702      0.2895      0.0212
         220      1.5906      1.5377      2.9368      1.7265      0.0254
         230      0.8968      1.4591      2.8764      0.0004      0.1478
         240      0.9219      1.5462      2.9173      0.0365      0.0732
         250      0.8953      1.5118      2.9023      0.0000      0.0627
         260      0.8936      1.5384      2.8861      0.0000      0.0436
         270      1.0342      1.5521      2.9033      0.3339      0.0478
         280      1.4528      1.5428      2.8806      1.4113      0.0182
         290      0.9050      1.5247      2.8878      0.0000      0.1123
         300      0.8840      1.5337      2.8703      0.0013      0.0134
         310      0.9161      1.5165      2.8599      0.0000      0.2042
         320      1.1772      1.5419      2.7587      0.7843      0.0166
         330      0.8992      1.5882      2.8583      0.0190      0.0116
         340      0.8802      1.5914      2.7997      0.0003      0.0095
         350      0.9636      1.6558      2.8762      0.0000      0.2860
         360      0.9398      1.5163      2.7728      0.0000      0.4101
         370      0.8834      1.4925      2.7821      0.0000      0.1426
         380      0.8712      1.5797      2.7489      0.0000      0.0274
         390      0.8708      1.5704      2.6782      0.0382      0.0287
         400      0.8722      1.5011      2.7099      0.0000      0.1501
         410      1.3548      1.5299      2.6159      1.2269      0.1742
         420      0.8918      1.5945      2.7310      0.0000      0.1336
         430      0.8525      1.5259      2.7096      0.0000      0.0271
         440      1.0296      1.5192      2.2859      0.6485      0.0458
         450      0.7642      1.5613      2.2323      0.0001      0.0270
         460      0.7781      1.5510      2.3122      0.0000      0.0275
         470      0.7191      1.5097      2.0611      0.0000      0.0247
         480      0.7598      1.5192      2.2490      0.0000      0.0306
         490      0.7309      1.4975      2.1169      0.0000      0.0399
         500      0.7722      1.5098      2.0639      0.1278      0.0317
         510      0.7340      1.6352      2.0079      0.0000      0.0269
         520      1.1117      1.6287      2.1988      0.0000      1.7309
         530      1.0080      1.6751      2.1640      0.0000      1.2011
         540      0.8965      1.5473      2.3960      0.0000      0.5391
         550      0.8269      1.5758      2.4742      0.0000      0.0845
         560      0.8484      1.6141      2.5181      0.0143      0.0811
         570      0.8090      1.5575      2.3924      0.0030      0.0889
         580      0.8299      1.5966      2.5175      0.0000      0.0354
         590      0.8099      1.5432      2.4613      0.0000      0.0451
         600      0.7868      1.5154      2.3833      0.0000      0.0352
       final      0.6905      1.4910      1.9331      0.0001      0.0282
best loss step: 495
Max CUDA memory: 1.3663G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_116: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_116 in 15.88 minutes.

Generating sh3_r1_117, length 90...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      2.3241      1.7257      2.9923      3.4486      0.0054
          10      2.4477      1.6607      2.8562      3.7002      0.3213
          20      1.2589      1.6173      2.8944      0.8630      0.0569
          30      1.0981      1.6710      2.8808      0.0397      0.8594
          40      1.2433      1.6148      2.8664      0.7709      0.1936
          50      1.0004      1.7252      2.8768      0.1309      0.1379
          60      0.9027      1.6396      2.8436      0.0070      0.0162
          70      0.9273      1.7270      2.8374      0.0009      0.0700
          80      0.9257      1.5203      2.6951      0.1892      0.0347
          90      0.8193      1.5428      2.4912      0.0074      0.0474
         100      0.7980      1.6072      2.3489      0.0011      0.0318
         110      0.8276      1.5081      2.5814      0.0000      0.0484
         120      0.8683      1.5934      2.6193      0.0442      0.0404
         130      0.8567      1.5353      2.6501      0.0000      0.0983
         140      0.8434      1.6681      2.5000      0.0000      0.0488
         150      0.8376      1.5434      2.5602      0.0001      0.0843
         160      0.8853      1.5834      2.6636      0.0725      0.0345
         170      1.4973      1.4751      2.6048      1.6921      0.0225
         180      0.8093      1.4997      2.5116      0.0005      0.0345
         190      0.8070      1.5016      2.4920      0.0000      0.0414
         200      1.1890      1.5484      2.5086      0.9345      0.0188
         210      0.8136      1.4880      2.5536      0.0001      0.0261
         220      0.8266      1.4125      2.4305      0.1278      0.0342
         230      0.9705      1.4829      2.4572      0.4470      0.0185
         240      0.7701      1.4179      2.3685      0.0156      0.0330
         250      0.7272      1.4854      2.1207      0.0000      0.0301
         260      0.9562      1.4523      2.4188      0.0186      0.8726
         270      0.8980      1.6485      2.3688      0.0000      0.4729
         280      0.8197      1.5970      2.4196      0.0001      0.0816
         290      0.8448      1.6210      2.5031      0.0000      0.0997
         300      0.8071      1.5849      2.3421      0.0001      0.1081
         310      0.8033      1.5768      2.3259      0.0001      0.1137
         320      0.8107      1.5655      2.3878      0.0001      0.0999
         330      0.8076      1.5619      2.3674      0.0108      0.0872
         340      0.7833      1.4444      2.3845      0.0008      0.0859
         350      0.7601      1.4750      2.1902      0.0158      0.1038
         360      0.7533      1.4167      2.2494      0.0002      0.1000
         370      0.7480      1.4716      2.1680      0.0001      0.0999
         380      0.7723      1.5588      2.2115      0.0000      0.0909
         390      0.7959      1.4711      2.3465      0.0234      0.1153
         400      0.7585      1.5153      2.1760      0.0001      0.1012
         410      0.7872      1.5260      2.3188      0.0000      0.0912
         420      0.8208      1.4683      2.4669      0.0000      0.1686
         430      0.7702      1.4917      2.2593      0.0000      0.0999
         440      0.7705      1.5345      2.2274      0.0001      0.0903
         450      0.7997      1.4287      2.3490      0.0000      0.2206
         460      1.0967      1.4937      2.3750      0.7605      0.0938
         470      0.7556      1.4810      2.1727      0.0124      0.0995
         480      0.9507      1.5202      2.4495      0.3347      0.1146
         490      0.7975      1.4758      2.4062      0.0000      0.1054
         500      0.7711      1.4846      2.2816      0.0001      0.0889
         510      0.9885      1.4804      2.2397      0.5675      0.0876
         520      0.7529      1.4601      2.2186      0.0000      0.0856
         530      0.7508      1.4337      2.2395      0.0000      0.0808
         540      0.7928      1.4734      2.3889      0.0000      0.1016
         550      0.9665      1.4651      2.3676      0.4615      0.0767
         560      0.7409      1.4308      2.1834      0.0000      0.0900
         570      0.7684      1.4834      2.2762      0.0000      0.0824
         580      0.7768      1.4060      2.2416      0.0804      0.0755
         590      0.7351      1.4734      2.1279      0.0001      0.0741
         600      1.1747      1.5562      2.4554      0.0000      1.8619
       final      0.7191      1.4406      2.0746      0.0000      0.0803
best loss step: 593
Max CUDA memory: 1.4355G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_117: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_117 in 16.30 minutes.
