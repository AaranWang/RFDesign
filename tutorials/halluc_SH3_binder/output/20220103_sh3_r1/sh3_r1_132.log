/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[23:04:08] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 132, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_132, length 85...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.1548      1.7206      2.9742      0.4557      0.1681
          10      0.9310      1.6919      2.9547      0.0002      0.0083
          20      1.0508      1.6351      2.7437      0.0166      0.8422
          30      1.2466      1.6147      2.8582      0.8322      0.0956
          40      0.8938      1.5537      2.7495      0.0000      0.1660
          50      0.9564      1.6246      2.7662      0.0000      0.3911
          60      0.9581      1.6495      2.8195      0.1528      0.0156
          70      0.9111      1.6446      2.7606      0.0000      0.1502
          80      0.8934      1.6454      2.7110      0.0107      0.0889
          90      0.9181      1.6464      2.7361      0.0314      0.1453
         100      0.9268      1.6382      2.8415      0.0714      0.0117
         110      0.8646      1.5585      2.7502      0.0015      0.0115
         120      0.8963      1.5893      2.7193      0.0667      0.0394
         130      0.8608      1.5500      2.7253      0.0007      0.0274
         140      0.8527      1.6031      2.6089      0.0000      0.0517
         150      0.9115      1.5680      2.6559      0.0000      0.3337
         160      0.8416      1.5596      2.5830      0.0000      0.0656
         170      0.8352      1.5405      2.4295      0.0000      0.2060
         180      2.7901      1.5664      2.6347      0.0000      9.7495
         190      0.8318      1.4850      2.4530      0.0000      0.2208
         200      0.8391      1.6025      2.4317      0.0000      0.1614
         210      0.8990      1.5898      2.4217      0.1559      0.1720
         220      0.8043      1.5226      2.3491      0.0001      0.1497
         230      1.2488      1.6335      2.4177      1.0115      0.1698
         240      0.8239      1.6023      2.3695      0.0000      0.1478
         250      0.7832      1.4149      2.3193      0.0000      0.1819
         260      0.8285      1.5695      2.4141      0.0000      0.1587
         270      0.8389      1.6409      2.3913      0.0001      0.1622
         280      0.8372      1.5835      2.4635      0.0000      0.1390
         290      2.1675      1.5245      2.3682      0.0000      6.9450
         300      0.7735      1.4448      2.2731      0.0000      0.1496
         310      0.9634      1.5477      2.4418      0.3511      0.1254
         320      0.7865      1.4684      2.3375      0.0000      0.1267
         330      0.7847      1.4903      2.2871      0.0000      0.1458
         340      0.8363      1.5814      2.4450      0.0000      0.1553
         350      0.8555      1.6651      2.5033      0.0001      0.1089
         360      0.8278      1.6029      2.3674      0.0000      0.1687
         370      0.8479      1.5088      2.5815      0.0000      0.1490
         380      0.9847      1.5583      2.7234      0.1892      0.2634
         390      0.8153      1.4759      2.4339      0.0000      0.1665
         400      0.7790      1.4465      2.2492      0.0000      0.1994
         410      0.7654      1.4035      2.2452      0.0000      0.1782
         420      0.8261      1.5535      2.3713      0.0000      0.2056
         430      0.7965      1.4515      2.3549      0.0000      0.1762
         440      0.7944      1.5058      2.3398      0.0000      0.1266
         450      0.8120      1.4425      2.3661      0.0000      0.2515
         460      0.7955      1.5503      2.3087      0.0000      0.1187
         470      0.8562      1.5279      2.3676      0.0997      0.1857
         480      0.7961      1.4610      2.3618      0.0000      0.1579
         490      0.8111      1.5433      2.3742      0.0005      0.1369
         500      0.8966      1.5461      2.3017      0.2390      0.1574
         510      0.8128      1.4610      2.3251      0.0000      0.2777
         520      0.7787      1.4922      2.2871      0.0000      0.1141
         530      0.8652      1.4759      2.3713      0.0654      0.3481
         540      0.8616      1.5129      2.3936      0.1074      0.1866
         550      0.9703      1.6432      2.3931      0.3525      0.1104
         560      0.8361      1.5667      2.4107      0.0221      0.1590
         570      2.9046      1.5451      2.5834      0.0000     10.3947
         580      0.7563      1.4872      2.1615      0.0025      0.1278
         590      0.7542      1.4943      2.1703      0.0000      0.1062
         600      0.8194      1.5988      2.4112      0.0000      0.0869
       final      0.7482      1.4638      2.1458      0.0001      0.1309
best loss step: 579
Max CUDA memory: 1.3034G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_132: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_132 in 15.74 minutes.

Generating sh3_r1_133, length 87...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      3.4262      1.7762      2.9093      6.2188      0.0079
          10      0.8816      1.6492      2.7289      0.0005      0.0287
          20      0.8860      1.5210      2.8576      0.0154      0.0209
          30      1.5625      1.4750      2.8855      1.7200      0.0122
          40      0.8826      1.4395      2.8789      0.0003      0.0939
          50      1.7589      1.5062      2.8321      2.1897      0.0769
          60      0.8937      1.5307      2.7880      0.0001      0.1497
          70      1.6456      1.4625      2.7266      0.0000      4.0389
          80      1.0218      1.4734      2.6010      0.4987      0.0373
          90      0.8333      1.4705      2.6805      0.0001      0.0152
         100      0.8591      1.5649      2.7144      0.0000      0.0159
         110      0.8012      1.4617      2.5160      0.0000      0.0281
         120      0.8097      1.4608      2.5567      0.0000      0.0308
         130      0.7715      1.4412      2.3807      0.0000      0.0358
         140      0.7701      1.4607      2.3401      0.0000      0.0499
         150      0.8056      1.5193      2.4329      0.0000      0.0757
         160      0.8295      1.5704      2.5400      0.0001      0.0368
         170      1.5630      1.5318      2.6617      1.7795      0.0626
         180      0.8286      1.5569      2.5512      0.0000      0.0349
         190      1.6990      1.4944      2.6792      0.0000      4.3213
         200      2.2172      1.5204      2.6119      0.0000      6.9535
         210      0.8151      1.5505      2.3501      0.0425      0.0899
         220      0.8450      1.5598      2.5369      0.0286      0.0713
         230      0.7785      1.5144      2.3071      0.0000      0.0711
         240      0.7800      1.4340      2.3870      0.0000      0.0792
         250      0.8213      1.4913      2.5638      0.0000      0.0515
         260      1.9420      1.4458      2.4161      2.9023      0.0435
         270      0.7447      1.4235      2.2502      0.0000      0.0499
         280      0.7762      1.4408      2.3291      0.0000      0.1113
         290      0.8011      1.4935      2.4268      0.0000      0.0851
         300      0.7675      1.3975      2.3716      0.0000      0.0686
         310      0.7643      1.5230      2.2498      0.0000      0.0489
         320      1.5760      1.5349      2.3043      0.0000      4.0406
         330      0.7463      1.4586      2.2224      0.0000      0.0504
         340      0.7456      1.4811      2.2020      0.0000      0.0451
         350      0.7345      1.4451      2.1694      0.0000      0.0579
         360      0.7365      1.4650      2.1629      0.0036      0.0475
         370      0.7243      1.3918      2.1695      0.0001      0.0599
         380      0.7391      1.4551      2.1833      0.0074      0.0426
         390      0.7355      1.5039      2.1303      0.0000      0.0432
         400      0.7417      1.5548      2.1168      0.0000      0.0370
         410      0.7307      1.5033      2.1012      0.0000      0.0491
         420      0.7423      1.5064      2.1656      0.0000      0.0394
         430      0.7394      1.5948      2.0718      0.0000      0.0302
         440      0.7407      1.5121      2.1539      0.0000      0.0375
         450      0.7007      1.4623      2.0025      0.0003      0.0383
         460      0.7148      1.4565      2.0771      0.0000      0.0401
         470      0.7185      1.4973      2.0614      0.0000      0.0340
         480      0.7209      1.4890      2.0690      0.0000      0.0467
         490      0.6946      1.5005      1.9363      0.0000      0.0361
         500      0.7399      1.4695      2.1292      0.0312      0.0385
         510      0.7175      1.4919      2.0577      0.0000      0.0378
         520      0.7169      1.5215      2.0296      0.0000      0.0334
         530      0.7403      1.4378      2.2236      0.0000      0.0400
         540      0.7332      1.4436      2.1725      0.0000      0.0501
         550      0.7385      1.4462      2.2095      0.0000      0.0369
         560      0.8567      1.4185      2.3986      0.0000      0.4664
         570      0.7046      1.4871      1.9956      0.0000      0.0405
         580      0.7097      1.3842      2.0634      0.0306      0.0398
         590      0.8017      1.5219      2.4613      0.0000      0.0251
         600      0.7491      1.6028      2.1161      0.0000      0.0263
       final      0.6678      1.3687      1.9304      0.0002      0.0399
best loss step: 477
Max CUDA memory: 1.3521G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_133: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_133 in 15.90 minutes.
