/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[20:29:33] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 36, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_36, length 82...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.4520      1.6112      2.8717      1.2205      0.3362
          10      1.8058      1.5924      2.8596      2.2797      0.0175
          20      1.1101      1.6029      2.9040      0.5196      0.0045
          30      0.9760      1.5793      2.8663      0.2109      0.0123
          40      1.5016      1.6794      2.8334      1.4935      0.0081
          50      0.9372      1.6296      2.8417      0.1045      0.0056
          60      0.8513      1.4980      2.7463      0.0000      0.0120
          70      0.8781      1.5431      2.8317      0.0043      0.0070
          80      0.8361      1.5172      2.6478      0.0000      0.0153
          90      0.9166      1.4628      2.6190      0.2455      0.0103
         100      0.8197      1.4797      2.4292      0.0884      0.0129
         110      0.7923      1.4924      2.4372      0.0095      0.0129
         120      0.8828      1.4566      2.8401      0.0000      0.1172
         130      0.7959      1.4219      2.4447      0.0501      0.0125
         140      0.8287      1.4870      2.6472      0.0002      0.0088
         150      0.8523      1.4495      2.3918      0.2052      0.0099
         160      0.7748      1.4623      2.3984      0.0000      0.0133
         170      0.7615      1.4592      2.3296      0.0000      0.0189
         180      0.7801      1.4566      2.3380      0.0000      0.1061
         190      0.7791      1.5384      2.3463      0.0001      0.0103
         200      0.8136      1.5198      2.5109      0.0134      0.0104
         210      0.7699      1.5077      2.3225      0.0021      0.0149
         220      0.8047      1.5169      2.4934      0.0000      0.0133
         230      0.7733      1.5000      2.3113      0.0218      0.0116
         240      0.8194      1.4612      2.6284      0.0000      0.0074
         250      0.7818      1.4344      2.4610      0.0000      0.0136
         260      0.8055      1.4777      2.5344      0.0004      0.0145
         270      0.8907      1.5440      2.4917      0.2031      0.0114
         280      0.8279      1.5132      2.3089      0.1492      0.0188
         290      0.8042      1.4276      2.5760      0.0000      0.0175
         300      0.7825      1.5354      2.3656      0.0001      0.0115
         310      1.1830      1.4649      2.3387      1.0508      0.0100
         320      0.7595      1.5286      2.1938      0.0319      0.0112
         330      0.7612      1.5219      2.2715      0.0000      0.0126
         340      0.7597      1.5127      2.2724      0.0000      0.0134
         350      0.7875      1.5411      2.2694      0.0547      0.0176
         360      0.7454      1.4755      2.2327      0.0000      0.0186
         370      0.7762      1.5723      2.2877      0.0027      0.0159
         380      0.7543      1.5882      2.1643      0.0000      0.0190
         390      0.8326      1.4879      2.5902      0.0382      0.0086
         400      0.9715      1.4834      2.3163      0.5215      0.0147
         410      0.7533      1.5073      2.2454      0.0001      0.0135
         420      0.8549      1.5033      2.4227      0.1676      0.0132
         430      0.7577      1.6112      2.1632      0.0010      0.0119
         440      0.8474      1.6726      2.2238      0.1646      0.0114
         450      0.7584      1.6228      2.1534      0.0014      0.0130
         460      0.8881      1.5226      2.3757      0.2645      0.0131
         470      0.7685      1.5474      2.2741      0.0001      0.0209
         480      0.7376      1.4703      2.1967      0.0000      0.0212
         490      0.8271      1.5398      2.5727      0.0041      0.0150
         500      0.7788      1.4846      2.3915      0.0000      0.0182
         510      0.7928      1.4891      2.2208      0.1179      0.0182
         520      0.8750      1.5086      2.2248      0.3133      0.0150
         530      0.7432      1.5228      2.1722      0.0000      0.0208
         540      0.8575      1.6548      2.3161      0.1527      0.0113
         550      0.7462      1.4901      2.2214      0.0017      0.0162
         560      0.7272      1.4807      2.1407      0.0000      0.0147
         570      0.7475      1.4876      2.2361      0.0000      0.0139
         580      0.7994      1.4860      2.3189      0.0866      0.0188
         590      0.7618      1.5017      2.1822      0.0522      0.0209
         600      0.7392      1.5123      2.1523      0.0056      0.0203
       final      0.7263      1.4537      2.1592      0.0000      0.0184
best loss step: 562
Max CUDA memory: 1.2282G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_36: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_36 in 14.69 minutes.

Generating sh3_r1_37, length 80...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      0.9344      1.6393      2.9853      0.0151      0.0174
          10      0.9028      1.5746      2.9068      0.0000      0.0324
          20      0.8861      1.5671      2.8497      0.0004      0.0129
          30      0.9201      1.4838      2.7913      0.0000      0.3254
          40      1.9821      1.6049      2.7515      2.7654      0.0233
          50      0.8496      1.4965      2.7122      0.0000      0.0393
          60      0.8593      1.5089      2.7188      0.0247      0.0195
          70      0.8722      1.5273      2.5581      0.1260      0.0237
          80      0.9081      1.5031      2.4878      0.2530      0.0434
          90      0.8499      1.5216      2.7234      0.0001      0.0043
         100      1.9890      1.5309      2.6842      0.0000      5.7300
         110      1.5910      1.4933      2.6338      1.8742      0.0794
         120      1.3828      1.4830      2.5415      1.3886      0.1120
         130      0.8388      1.4928      2.3543      0.0017      0.3436
         140      0.8054      1.4759      2.3186      0.0021      0.2281
         150      0.7972      1.5316      2.1827      0.0000      0.2714
         160      0.8455      1.5107      2.3557      0.0000      0.3610
         170      0.8406      1.4702      2.3949      0.0186      0.3006
         180      0.7959      1.4656      2.2564      0.0000      0.2573
         190      0.8198      1.5159      2.1902      0.0677      0.2576
         200      1.3886      1.4143      2.3339      0.0000      3.1948
         210      0.8461      1.5028      2.2411      0.1150      0.2566
         220      0.8305      1.5845      2.2290      0.0000      0.3389
         230      0.8430      1.4804      2.4804      0.0000      0.2545
         240      0.7772      1.4966      2.1437      0.0000      0.2456
         250      1.4538      1.4527      2.2540      0.0000      3.5621
         260      0.7521      1.4438      2.0978      0.0027      0.2133
         270      0.7900      1.3784      2.3006      0.0000      0.2710
         280      0.8318      1.5264      2.4335      0.0003      0.1986
         290      0.7878      1.4423      2.2641      0.0175      0.1975
         300      0.7802      1.3777      2.3093      0.0000      0.2138
         310      0.7975      1.4965      2.2805      0.0006      0.2095
         320      0.7818      1.4748      2.2356      0.0000      0.1988
         330      0.8658      1.4613      2.4763      0.0000      0.3916
         340      0.7833      1.4812      2.2293      0.0000      0.2058
         350      0.7575      1.4086      2.1865      0.0000      0.1922
         360      0.7625      1.4120      2.2188      0.0000      0.1816
         370      0.9384      1.4810      2.6346      0.0000      0.5765
         380      0.8328      1.4750      2.4429      0.0001      0.2460
         390      0.8052      1.5078      2.2770      0.0000      0.2412
         400      0.8194      1.5174      2.3957      0.0000      0.1839
         410      0.7876      1.4718      2.2578      0.0000      0.2084
         420      0.8305      1.4557      2.4642      0.0000      0.2326
         430      0.8366      1.4984      2.5610      0.0004      0.1227
         440      0.8045      1.4820      2.2953      0.0000      0.2451
         450      3.4841      1.4974      2.5086      0.0000     13.4146
         460      0.7552      1.4291      2.1501      0.0000      0.1969
         470      0.8240      1.5157      2.3055      0.0000      0.2986
         480      0.8365      1.5229      2.4873      0.0000      0.1725
         490      0.7622      1.4218      2.2219      0.0000      0.1673
         500      0.8893      1.4974      2.6974      0.0294      0.1927
         510      0.8016      1.4303      2.2839      0.0000      0.2938
         520      0.8490      1.5078      2.3188      0.0945      0.2297
         530      0.7878      1.4869      2.2617      0.0000      0.1903
         540      0.8023      1.5556      2.2800      0.0000      0.1758
         550      0.7713      1.4747      2.1893      0.0000      0.1923
         560      0.9111      1.4577      2.3314      0.2566      0.2531
         570      0.7643      1.4640      2.1846      0.0000      0.1727
         580      0.7995      1.4706      2.2601      0.0429      0.1810
         590      0.7599      1.4568      2.1689      0.0000      0.1736
         600      3.5461      1.4872      2.5229      0.0000     13.7203
       final      0.7432      1.4112      2.1432      0.0000      0.1613
best loss step: 548
Max CUDA memory: 1.1795G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_37: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_37 in 14.56 minutes.
