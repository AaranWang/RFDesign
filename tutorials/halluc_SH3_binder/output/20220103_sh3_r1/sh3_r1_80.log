/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[21:47:19] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 80, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_80, length 56...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.6822      1.9560      2.8590      1.7443      0.1075
          10      2.3868      1.7327      2.9057      0.0001      7.2954
          20      0.9345      1.7151      2.7638      0.0001      0.1934
          30      0.8987      1.7139      2.7586      0.0000      0.0212
          40      0.8588      1.5848      2.6709      0.0001      0.0380
          50      0.8206      1.5166      2.4712      0.0000      0.1153
          60      0.9014      1.4947      2.5136      0.1862      0.1261
          70      0.8271      1.5307      2.5467      0.0001      0.0580
          80      0.7837      1.5123      2.3233      0.0000      0.0829
          90      0.7624      1.3769      2.2713      0.0000      0.1637
         100      0.8326      1.5732      2.4882      0.0001      0.1014
         110      0.7669      1.4862      2.2582      0.0009      0.0885
         120      0.7969      1.4752      2.4039      0.0000      0.1053
         130      0.7812      1.4579      2.3705      0.0000      0.0773
         140      0.8484      1.5055      2.5557      0.0001      0.1804
         150      0.8201      1.4605      2.5225      0.0000      0.1175
         160      0.8063      1.4973      2.4701      0.0000      0.0639
         170      0.7791      1.3636      2.4070      0.0000      0.1248
         180      0.8030      1.4987      2.4125      0.0001      0.1037
         190      0.7715      1.3916      2.3484      0.0000      0.1176
         200      0.8001      1.4803      2.3767      0.0000      0.1437
         210      0.7462      1.4147      2.2241      0.0000      0.0921
         220      0.7632      1.4060      2.2830      0.0000      0.1268
         230      0.7609      1.4171      2.2703      0.0000      0.1169
         240      0.8566      1.4435      2.1702      0.3075      0.0546
         250      0.8975      1.5256      2.4826      0.2003      0.0787
         260      0.8026      1.4606      2.4042      0.0000      0.1484
         270      0.7350      1.3711      2.1796      0.0000      0.1244
         280      0.7941      1.4629      2.3958      0.0000      0.1118
         290      0.7648      1.4370      2.3081      0.0002      0.0783
         300      0.7571      1.4560      2.2447      0.0004      0.0839
         310      0.7719      1.4910      2.2810      0.0000      0.0872
         320      0.7329      1.3502      2.2017      0.0000      0.1125
         330      0.8345      1.3967      2.2215      0.2440      0.0662
         340      0.7673      1.4388      2.2042      0.0704      0.0528
         350      0.7926      1.4300      2.3878      0.0000      0.1450
         360      0.7543      1.4337      2.2653      0.0001      0.0725
         370      0.8033      1.4369      2.4751      0.0000      0.1046
         380      0.7758      1.5001      2.3090      0.0000      0.0699
         390      0.7907      1.5639      2.3127      0.0000      0.0771
         400      0.7022      1.3318      2.0860      0.0000      0.0930
         410      0.7781      1.6031      2.2176      0.0000      0.0701
         420      0.7215      1.3975      2.1230      0.0000      0.0872
         430      0.7754      1.3982      2.3180      0.0000      0.1606
         440      0.7311      1.4462      2.1332      0.0000      0.0761
         450      0.7899      1.5371      2.3249      0.0000      0.0873
         460      0.7642      1.5783      2.1730      0.0001      0.0694
         470      0.7379      1.5008      2.0974      0.0012      0.0890
         480      0.7356      1.4456      2.1215      0.0001      0.1107
         490      0.7398      1.4732      2.1184      0.0001      0.1069
         500      0.7801      1.5000      2.2151      0.0085      0.1683
         510      0.7602      1.3760      2.2975      0.0000      0.1276
         520      0.7498      1.4841      2.1751      0.0000      0.0897
         530      0.7660      1.5626      2.1645      0.0000      0.1027
         540      0.7487      1.4524      2.1779      0.0000      0.1133
         550      0.7354      1.3825      2.2229      0.0000      0.0718
         560      0.7681      1.4423      2.3330      0.0003      0.0648
         570      0.7316      1.4220      2.1787      0.0000      0.0574
         580      0.7494      1.4186      2.2227      0.0000      0.1058
         590      0.8000      1.4386      2.4223      0.0000      0.1389
         600      0.7727      1.3671      2.2890      0.0000      0.2076
       final      0.7021      1.3910      2.0542      0.0001      0.0651
best loss step: 86
Max CUDA memory: 0.7116G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_80: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_80 in 13.07 minutes.

Generating sh3_r1_81, length 97...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      2.3315      1.7412      2.9672      0.0960      6.7571
          10      0.9944      1.7128      2.8359      0.1275      0.1683
          20      0.9128      1.6652      2.8825      0.0001      0.0162
          30      1.4874      1.7808      2.9600      1.2960      0.1039
          40      0.9124      1.6806      2.8718      0.0001      0.0094
          50      0.9349      1.6845      2.9022      0.0012      0.0855
          60      1.0972      1.5803      2.7845      0.4509      0.2193
          70      0.8861      1.6627      2.7563      0.0002      0.0111
          80      0.8780      1.5879      2.7110      0.0000      0.0912
          90      0.8926      1.6864      2.7651      0.0000      0.0113
         100      0.8761      1.6474      2.7067      0.0001      0.0265
         110      0.8564      1.6399      2.6135      0.0001      0.0282
         120      2.5179      1.6842      2.7758      4.0187      0.0920
         130      0.8537      1.5818      2.6701      0.0000      0.0166
         140      0.9218      1.5706      2.7560      0.0117      0.2590
         150      0.9057      1.6155      2.7577      0.0613      0.0325
         160      0.8422      1.5580      2.5933      0.0001      0.0596
         170      0.8513      1.5053      2.5838      0.0000      0.1671
         180      0.8378      1.5436      2.5845      0.0000      0.0607
         190      0.8228      1.5142      2.4983      0.0003      0.1009
         200      0.8694      1.6018      2.6287      0.0001      0.1161
         210      0.8766      1.6121      2.6627      0.0001      0.1083
         220      0.8508      1.5045      2.6433      0.0000      0.1059
         230      2.2852      1.5423      2.6720      0.9631      5.2854
         240      1.7315      1.6227      2.6083      0.0667      4.2930
         250      0.8603      1.5559      2.6723      0.0054      0.0627
         260      1.1180      1.5276      2.5628      0.0004      1.4989
         270      0.8610      1.5510      2.5151      0.0545      0.1298
         280      0.8019      1.4918      2.4516      0.0000      0.0663
         290      0.8499      1.5718      2.6206      0.0000      0.0568
         300      0.8097      1.5238      2.3550      0.0439      0.0818
         310      0.8821      1.6270      2.7161      0.0000      0.0673
         320      0.8002      1.4941      2.4423      0.0000      0.0644
         330      0.7794      1.4610      2.3590      0.0000      0.0772
         340      0.8641      1.4552      2.4162      0.1587      0.1316
         350      0.7940      1.4434      2.4793      0.0000      0.0471
         360      0.8733      1.5047      2.4331      0.1753      0.0779
         370      0.7962      1.4628      2.4350      0.0000      0.0834
         380      0.9751      1.4121      2.4486      0.4346      0.1459
         390      0.7448      1.4214      2.2152      0.0000      0.0876
         400      0.7804      1.4165      2.4047      0.0000      0.0806
         410      0.7162      1.3376      2.1390      0.0004      0.1035
         420      0.7708      1.4670      2.3078      0.0000      0.0794
         430      0.7098      1.3085      2.1592      0.0000      0.0814
         440      0.7609      1.3797      2.3591      0.0000      0.0659
         450      0.7461      1.3932      2.2598      0.0000      0.0777
         460      0.8146      1.4777      2.4356      0.0000      0.1596
         470      0.7115      1.3584      2.0890      0.0000      0.1103
         480      0.6909      1.2941      2.0652      0.0000      0.0950
         490      0.7570      1.4544      2.2284      0.0001      0.1021
         500      0.7389      1.4121      2.1748      0.0000      0.1076
         510      0.7173      1.3760      2.1200      0.0000      0.0905
         520      0.7249      1.4040      2.1156      0.0009      0.1033
         530      0.7394      1.3821      2.2201      0.0000      0.0948
         540      0.7491      1.3670      2.2831      0.0001      0.0949
         550      0.6997      1.3307      2.0682      0.0000      0.0995
         560      0.7421      1.3482      2.2852      0.0000      0.0769
         570      0.7084      1.3714      2.0861      0.0000      0.0845
         580      0.7250      1.3704      2.1698      0.0000      0.0850
         590      0.7047      1.3214      2.1016      0.0000      0.1003
         600      0.7251      1.3287      2.1894      0.0000      0.1074
       final      0.6832      1.3201      2.0032      0.0000      0.0929
best loss step: 544
Max CUDA memory: 1.6275G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_81: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_81 in 16.04 minutes.
