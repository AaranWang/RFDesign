/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[23:38:42] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 158, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_158, length 95...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.1552      1.6353      2.9518      0.5685      0.0521
          10      0.8474      1.6004      2.6248      0.0000      0.0119
          20      0.7520      1.5347      2.1927      0.0000      0.0326
          30      0.7810      1.6073      2.2508      0.0008      0.0456
          40      0.7446      1.5879      2.1027      0.0002      0.0322
          50      1.1501      1.5873      2.4451      0.0000      1.7182
          60      0.8596      1.5758      2.6014      0.0001      0.1207
          70      0.8071      1.5614      2.4076      0.0000      0.0664
          80      0.7640      1.5787      2.2065      0.0001      0.0343
          90      0.7515      1.5932      2.1358      0.0000      0.0285
         100      0.7783      1.5195      2.3485      0.0000      0.0234
         110      0.7619      1.5358      2.2434      0.0000      0.0303
         120      0.7817      1.6068      2.2567      0.0004      0.0442
         130      0.8223      1.5285      2.5223      0.0000      0.0608
         140      0.8240      1.5827      2.4394      0.0054      0.0870
         150      0.8617      1.6094      2.6157      0.0000      0.0833
         160      0.8718      1.5180      2.5510      0.1329      0.0243
         170      0.8081      1.4766      2.5409      0.0000      0.0229
         180      0.7803      1.5106      2.3515      0.0000      0.0392
         190      0.7553      1.4864      2.2481      0.0000      0.0420
         200      0.7534      1.4864      2.2242      0.0000      0.0564
         210      0.7085      1.4151      2.0981      0.0000      0.0291
         220      0.7412      1.4343      2.2424      0.0000      0.0290
         230      0.7211      1.4406      2.1281      0.0000      0.0369
         240      0.7346      1.5025      2.1373      0.0000      0.0331
         250      1.7792      1.5093      2.5219      0.0000      4.8648
         260      0.9974      1.5260      2.6219      0.0008      0.8377
         270      1.5689      1.5135      2.6224      1.5757      0.5574
         280      0.8126      1.5058      2.5316      0.0000      0.0255
         290      0.7831      1.5055      2.3826      0.0000      0.0273
         300      0.7822      1.4933      2.3778      0.0000      0.0398
         310      0.8013      1.4974      2.4819      0.0000      0.0269
         320      0.7842      1.4441      2.4617      0.0000      0.0153
         330      0.8740      1.5705      2.3935      0.1978      0.0103
         340      0.6989      1.3762      2.0997      0.0000      0.0186
         350      1.0670      1.5328      2.5164      0.0000      1.2858
         360      0.7400      1.4340      2.2220      0.0099      0.0243
         370      0.7334      1.4327      2.2151      0.0000      0.0191
         380      0.7332      1.4608      2.1767      0.0024      0.0238
         390      0.7245      1.5068      2.0857      0.0000      0.0300
         400      1.2006      1.4424      2.3801      0.2010      1.7784
         410      0.7391      1.5222      2.1288      0.0000      0.0444
         420      0.7083      1.4559      2.0576      0.0000      0.0279
         430      0.7140      1.4590      2.0376      0.0248      0.0236
         440      0.9876      1.5564      2.2378      0.0000      1.1437
         450      0.7227      1.4719      2.1150      0.0000      0.0266
         460      0.7426      1.4828      2.2060      0.0000      0.0243
         470      0.7092      1.4692      2.0452      0.0000      0.0314
         480      0.7393      1.4888      2.1774      0.0000      0.0303
         490      0.7108      1.4843      2.0447      0.0000      0.0247
         500      0.7338      1.4920      2.1497      0.0000      0.0273
         510      0.7566      1.4919      2.2643      0.0000      0.0270
         520      0.6936      1.4855      1.9602      0.0000      0.0222
         530      0.7283      1.4636      2.1302      0.0107      0.0263
         540      0.7124      1.4470      2.0895      0.0000      0.0253
         550      0.8507      1.5228      2.4791      0.0000      0.2513
         560      0.7338      1.4786      2.1663      0.0000      0.0239
         570      0.7479      1.4578      2.0081      0.1237      0.0266
         580      1.7859      1.5358      2.3615      0.4579      4.1165
         590      0.7001      1.4389      2.0361      0.0000      0.0256
         600      0.7252      1.4771      2.1220      0.0022      0.0224
       final      0.6785      1.5027      1.8659      0.0000      0.0240
best loss step: 576
Max CUDA memory: 1.5754G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_158: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_158 in 17.16 minutes.

Generating sh3_r1_159, length 71...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.2126      1.7177      2.8651      0.2557      0.9691
          10      1.3792      1.6343      2.8500      1.1877      0.0362
          20      1.4268      1.5986      2.7833      0.0000      2.7520
          30      0.8796      1.6565      2.7170      0.0000      0.0246
          40      0.8906      1.5412      2.6871      0.0000      0.2246
          50      0.8425      1.5291      2.5998      0.0000      0.0836
          60      0.8279      1.5686      2.5278      0.0116      0.0199
          70      0.8139      1.4598      2.5577      0.0002      0.0516
          80      0.8195      1.5310      2.5159      0.0000      0.0506
          90      0.8050      1.5489      2.4469      0.0000      0.0289
         100      0.8638      1.5149      2.6181      0.0323      0.1216
         110      0.8367      1.4872      2.6130      0.0000      0.0832
         120      0.8258      1.4439      2.5722      0.0367      0.0393
         130      0.8404      1.5458      2.6302      0.0001      0.0260
         140      0.8214      1.4389      2.4176      0.1040      0.0427
         150      0.8179      1.4572      2.5768      0.0000      0.0552
         160      0.7717      1.4357      2.3916      0.0030      0.0249
         170      0.7737      1.5738      2.2727      0.0000      0.0220
         180      0.8105      1.5292      2.4020      0.0485      0.0242
         190      0.7889      1.5202      2.4014      0.0000      0.0230
         200      0.7621      1.4378      2.3380      0.0031      0.0286
         210      0.8059      1.5217      2.4824      0.0001      0.0251
         220      0.7862      1.4607      2.4353      0.0000      0.0351
         230      0.8103      1.5378      2.4875      0.0000      0.0263
         240      0.7952      1.5178      2.4328      0.0000      0.0254
         250      0.7419      1.4358      2.2404      0.0000      0.0331
         260      0.8030      1.4686      2.4610      0.0306      0.0245
         270      0.8192      1.4735      2.5025      0.0117      0.0965
         280      0.8385      1.5192      2.6284      0.0000      0.0450
         290      0.8058      1.4634      2.5113      0.0000      0.0544
         300      0.8757      1.5693      2.6986      0.0020      0.1066
         310      1.5559      1.5811      2.6846      0.0000      3.5138
         320      0.8693      1.5801      2.6917      0.0000      0.0746
         330      0.8469      1.5307      2.5695      0.0546      0.0252
         340      0.7988      1.5061      2.4459      0.0000      0.0421
         350      0.8351      1.5483      2.5881      0.0041      0.0311
         360      0.8272      1.4739      2.5949      0.0005      0.0662
         370      0.7714      1.4588      2.3749      0.0000      0.0230
         380      0.8439      1.5754      2.6185      0.0000      0.0255
         390      0.8363      1.4464      2.6028      0.0195      0.0930
         400      0.8122      1.6187      2.3963      0.0000      0.0460
         410      0.9002      1.5276      2.6957      0.0000      0.2775
         420      0.7931      1.5077      2.4294      0.0000      0.0284
         430      0.7546      1.4886      2.2663      0.0000      0.0181
         440      0.7497      1.4370      2.2840      0.0000      0.0274
         450      0.8311      1.6273      2.4850      0.0000      0.0431
         460      0.7686      1.4500      2.3655      0.0000      0.0274
         470      0.8023      1.6166      2.3777      0.0000      0.0174
         480      0.7785      1.4213      2.4477      0.0002      0.0230
         490      0.7771      1.4637      2.3947      0.0007      0.0257
         500      0.8236      1.4980      2.5312      0.0002      0.0882
         510      0.7585      1.4246      2.3319      0.0001      0.0360
         520      0.8175      1.4601      2.5612      0.0001      0.0661
         530      0.8002      1.5206      2.3216      0.0706      0.0179
         540      0.9262      1.4411      2.3555      0.0000      0.8343
         550      0.9418      1.5495      2.5259      0.3038      0.0258
         560      0.7645      1.4591      2.3298      0.0002      0.0331
         570      0.7626      1.5201      2.2711      0.0000      0.0218
         580      0.7596      1.4213      2.3305      0.0076      0.0312
         590      0.7822      1.5569      2.3267      0.0000      0.0275
         600      0.7731      1.4395      2.3789      0.0000      0.0469
       final      0.7222      1.4393      2.1409      0.0016      0.0277
best loss step: 599
Max CUDA memory: 0.9994G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_159: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_159 in 14.73 minutes.
