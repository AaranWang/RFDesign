/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[23:50:11] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 164, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_164, length 84...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.0558      1.6228      2.9978      0.3279      0.0025
          10      1.0073      1.5194      2.8342      0.3224      0.0378
          20      1.2102      1.6149      2.8174      0.7978      0.0233
          30      0.9230      1.5246      2.6668      0.2004      0.0231
          40      0.8173      1.6101      2.4127      0.0260      0.0118
          50      0.8235      1.6323      2.4693      0.0000      0.0159
          60      0.7332      1.5287      2.1220      0.0000      0.0152
          70      0.7031      1.5397      1.9635      0.0000      0.0121
          80      0.6903      1.4894      1.9508      0.0000      0.0113
          90      0.7039      1.5383      1.9708      0.0000      0.0104
         100      0.7096      1.5551      1.9802      0.0011      0.0102
         110      0.7530      1.4945      2.0272      0.1137      0.0160
         120      1.5667      1.5222      2.4430      0.6568      2.5548
         130      0.7224      1.5660      1.9602      0.0363      0.0132
         140      0.7112      1.5514      1.9928      0.0000      0.0116
         150      0.7192      1.4896      2.0944      0.0000      0.0120
         160      0.8900      1.5259      2.1220      0.3955      0.0113
         170      0.8287      1.5380      2.1750      0.2108      0.0088
         180      0.7531      1.5942      2.1605      0.0000      0.0109
         190      0.7034      1.5091      1.9977      0.0001      0.0102
         200      0.7717      1.5437      2.3057      0.0000      0.0089
         210      0.7092      1.5746      1.9602      0.0001      0.0112
         220      0.7092      1.5270      2.0043      0.0021      0.0103
         230      0.6714      1.5018      1.8421      0.0005      0.0123
         240      0.7085      1.5753      1.9555      0.0000      0.0115
         250      1.0284      1.4814      2.2990      0.0000      1.3617
         260      0.7015      1.5129      1.9827      0.0000      0.0119
         270      0.7202      1.4991      2.0927      0.0000      0.0091
         280      0.6794      1.4873      1.8990      0.0000      0.0108
         290      0.6733      1.4669      1.8880      0.0000      0.0117
         300      0.9684      1.5628      2.3762      0.0000      0.9030
         310      0.6726      1.4930      1.8595      0.0000      0.0102
         320      0.6814      1.5409      1.8537      0.0001      0.0121
         330      0.6942      1.5357      1.8369      0.0448      0.0090
         340      0.7473      1.4864      1.9394      0.1494      0.0119
         350      0.6799      1.5255      1.8610      0.0000      0.0130
         360      0.6686      1.5048      1.8237      0.0012      0.0123
         370      0.6648      1.4858      1.8270      0.0000      0.0113
         380      0.6657      1.5164      1.7986      0.0000      0.0133
         390      0.6821      1.5649      1.8308      0.0011      0.0123
         400      0.6811      1.4842      1.9065      0.0000      0.0146
         410      0.7001      1.4604      1.9836      0.0240      0.0085
         420      0.8230      1.5334      2.1425      0.0000      0.4394
         430      0.7120      1.5713      1.9719      0.0017      0.0133
         440      0.7937      1.5609      2.3800      0.0000      0.0275
         450      0.7190      1.5774      1.9966      0.0039      0.0131
         460      0.6611      1.5442      1.7490      0.0005      0.0114
         470      0.6746      1.5038      1.8564      0.0011      0.0105
         480      0.7300      1.5517      2.0677      0.0100      0.0105
         490      0.6984      1.5261      1.9537      0.0000      0.0122
         500      0.6679      1.4990      1.8292      0.0000      0.0115
         510      0.7107      1.4843      2.0590      0.0000      0.0103
         520      0.7418      1.5528      2.1461      0.0000      0.0100
         530      0.6904      1.5440      1.8961      0.0000      0.0121
         540      0.6881      1.4668      1.9630      0.0008      0.0091
         550      0.6789      1.5452      1.8397      0.0000      0.0094
         560      0.6692      1.4963      1.8386      0.0000      0.0108
         570      0.6723      1.4860      1.8635      0.0000      0.0122
         580      0.9354      1.4808      2.3594      0.0000      0.8365
         590      0.8384      1.5533      2.5172      0.0001      0.1214
         600      0.6812      1.5413      1.8542      0.0000      0.0103
       final      0.6415      1.4645      1.7330      0.0000      0.0102
best loss step: 366
Max CUDA memory: 1.2713G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_164: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_164 in 13.97 minutes.

Generating sh3_r1_165, length 86...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.0098      1.7938      2.9771      0.0039      0.2701
          10      1.9078      1.6319      2.8988      1.1209      2.7667
          20      1.2553      1.6944      2.7537      0.9086      0.0112
          30      1.2863      1.6676      2.8283      0.9560      0.0235
          40      1.7377      1.6855      2.8675      2.0567      0.0219
          50      1.1116      1.5672      2.8454      0.4918      0.1618
          60      1.3330      1.5619      2.7824      1.1511      0.0185
          70      2.2477      1.6493      2.8048      3.3815      0.0212
          80      0.8622      1.5829      2.6945      0.0000      0.0338
          90      0.9090      1.6347      2.8573      0.0174      0.0184
         100      0.9288      1.5275      2.8169      0.1430      0.0134
         110      0.8613      1.5725      2.7172      0.0000      0.0169
         120      0.8611      1.5408      2.7505      0.0000      0.0143
         130      0.8556      1.4972      2.7578      0.0000      0.0229
         140      0.9065      1.6605      2.7735      0.0438      0.0110
         150      0.8655      1.5634      2.6894      0.0000      0.0745
         160      0.8152      1.5389      2.4482      0.0334      0.0218
         170      0.8393      1.5097      2.6596      0.0000      0.0273
         180      0.8477      1.5016      2.7137      0.0000      0.0230
         190      0.7693      1.5490      2.2696      0.0001      0.0278
         200      0.7652      1.4527      2.3308      0.0000      0.0426
         210      0.7569      1.4620      2.2968      0.0000      0.0257
         220      0.7748      1.4692      2.3770      0.0000      0.0280
         230      0.7632      1.5286      2.2592      0.0000      0.0280
         240      0.7873      1.5383      2.3793      0.0000      0.0190
         250      0.7737      1.5103      2.3115      0.0000      0.0468
         260      0.8351      1.5544      2.5921      0.0001      0.0288
         270      0.8473      1.5310      2.5800      0.0000      0.1254
         280      0.7368      1.3960      2.2662      0.0000      0.0220
         290      0.7509      1.4215      2.3149      0.0000      0.0183
         300      0.8041      1.5607      2.3908      0.0000      0.0690
         310      0.7426      1.3933      2.2809      0.0000      0.0386
         320      0.6940      1.3732      2.0640      0.0000      0.0329
         330      0.7418      1.4611      2.2221      0.0000      0.0256
         340      0.7263      1.3795      2.2159      0.0000      0.0362
         350      0.7851      1.5266      2.3677      0.0000      0.0311
         360      0.7434      1.4209      2.2578      0.0000      0.0383
         370      0.7606      1.4948      2.2809      0.0000      0.0274
         380      1.2671      1.5330      2.5222      0.0000      2.2804
         390      0.7229      1.3989      2.1747      0.0000      0.0408
         400      0.6992      1.3504      2.1144      0.0000      0.0312
         410      0.7049      1.3338      2.1590      0.0000      0.0317
         420      0.7441      1.4022      2.2888      0.0000      0.0296
         430      0.6802      1.3352      2.0325      0.0000      0.0335
         440      0.7025      1.4407      2.0424      0.0000      0.0292
         450      0.7264      1.4783      2.1114      0.0037      0.0347
         460      0.7154      1.3899      2.1577      0.0000      0.0296
         470      0.7290      1.4371      2.1762      0.0001      0.0317
         480      0.6936      1.3411      2.0972      0.0001      0.0297
         490      0.7298      1.3947      2.2233      0.0000      0.0310
         500      0.7642      1.4824      2.3130      0.0000      0.0254
         510      0.6913      1.3723      2.0538      0.0000      0.0301
         520      0.6850      1.3388      2.0632      0.0008      0.0212
         530      0.7238      1.4070      2.1859      0.0001      0.0259
         540      0.7538      1.3504      2.3115      0.0447      0.0178
         550      0.7856      1.4803      2.3089      0.0584      0.0222
         560      0.7103      1.3881      2.1365      0.0000      0.0270
         570      1.3085      1.4323      2.5699      0.1051      2.3301
         580      0.7561      1.4748      2.2846      0.0000      0.0211
         590      0.8234      1.4385      2.1523      0.2534      0.0195
         600      0.7747      1.4481      2.4037      0.0000      0.0220
       final      0.6782      1.3682      1.9934      0.0000      0.0292
best loss step: 486
Max CUDA memory: 1.3370G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_165: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_165 in 14.16 minutes.
