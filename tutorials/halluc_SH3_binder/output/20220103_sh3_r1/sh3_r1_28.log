/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[20:25:38] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 28, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_28, length 95...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      2.0790      1.7613      2.9896      2.8093      0.0257
          10      0.9400      1.6639      2.8771      0.0287      0.1015
          20      1.0071      1.6961      2.9100      0.1625      0.1044
          30      0.9202      1.6164      2.9329      0.0226      0.0064
          40      1.1307      1.5855      2.8827      0.5861      0.0133
          50      1.0209      1.5178      2.8742      0.3269      0.0589
          60      1.1486      1.5564      2.8641      0.6542      0.0142
          70      1.0234      1.4954      2.9138      0.3429      0.0220
          80      0.8766      1.4836      2.8752      0.0000      0.0244
          90      1.3699      1.5526      2.9055      0.0000      2.3912
         100      0.8967      1.5814      2.8777      0.0000      0.0242
         110      0.9207      1.5973      2.8806      0.0531      0.0192
         120      1.4476      1.5882      2.8781      1.3779      0.0160
         130      0.9333      1.6094      2.8960      0.0701      0.0211
         140      1.0841      1.6274      2.9425      0.4105      0.0294
         150      0.9533      1.6098      2.9123      0.0845      0.0754
         160      0.8844      1.5885      2.8080      0.0000      0.0254
         170      1.2953      1.6178      2.8865      0.9211      0.1301
         180      1.0251      1.5396      2.8981      0.3399      0.0080
         190      0.8608      1.4622      2.8247      0.0005      0.0164
         200      0.8651      1.5163      2.7895      0.0000      0.0197
         210      1.0053      1.6191      2.8137      0.2473      0.0991
         220      1.0175      1.5149      2.8052      0.3735      0.0206
         230      0.8768      1.5703      2.7846      0.0000      0.0292
         240      0.8971      1.6058      2.8482      0.0121      0.0073
         250      0.9690      1.6157      2.8372      0.1872      0.0177
         260      0.8875      1.5831      2.8198      0.0100      0.0145
         270      2.5434      1.5715      2.6941      4.1915      0.0685
         280      0.8696      1.6375      2.6926      0.0000      0.0176
         290      0.8738      1.5472      2.8083      0.0000      0.0138
         300      0.8702      1.5660      2.7482      0.0142      0.0082
         310      0.8732      1.5444      2.8127      0.0000      0.0088
         320      0.9189      1.4549      2.7391      0.1676      0.0650
         330      1.1511      1.4692      2.7329      0.7670      0.0198
         340      0.8218      1.4333      2.6605      0.0000      0.0154
         350      0.9445      1.5456      2.8009      0.1820      0.0120
         360      0.9371      1.4705      2.6846      0.0000      0.5302
         370      0.8189      1.5543      2.4929      0.0001      0.0472
         380      0.7647      1.4671      2.2381      0.0000      0.1184
         390      0.7421      1.4469      2.1984      0.0003      0.0648
         400      0.7486      1.5039      2.1792      0.0000      0.0600
         410      0.8926      1.5183      2.3263      0.2771      0.0641
         420      0.7462      1.5291      2.1303      0.0014      0.0688
         430      0.7894      1.5606      2.2361      0.0000      0.1502
         440      0.7456      1.4730      2.1261      0.0000      0.1289
         450      0.9588      1.4706      2.4318      0.4005      0.0906
         460      0.7587      1.5140      2.1455      0.0008      0.1324
         470      0.7831      1.4904      2.2921      0.0004      0.1322
         480      0.7324      1.4148      2.1013      0.0000      0.1460
         490      0.7195      1.3028      2.1518      0.0003      0.1423
         500      0.7469      1.4101      2.2126      0.0000      0.1119
         510      0.7395      1.3899      2.1922      0.0001      0.1152
         520      0.7433      1.3564      2.2424      0.0000      0.1178
         530      0.7489      1.3822      2.2805      0.0000      0.0818
         540      0.7049      1.3259      2.0922      0.0001      0.1062
         550      0.7561      1.3960      2.2863      0.0014      0.0955
         560      0.7306      1.3473      2.1985      0.0000      0.1070
         570      0.7089      1.3101      2.1056      0.0000      0.1286
         580      0.7258      1.3715      2.1376      0.0003      0.1193
         590      0.7123      1.3053      2.1330      0.0000      0.1231
         600      0.7119      1.3473      2.0836      0.0000      0.1288
       final      0.7049      1.3259      2.0922      0.0001      0.1062
best loss step: 540
Max CUDA memory: 1.5754G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_28: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_28 in 16.26 minutes.

Generating sh3_r1_29, length 89...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.3812      1.8044      2.9734      0.1464      1.8353
          10      1.0160      1.7385      2.7424      0.0000      0.5990
          20      0.8690      1.6822      2.6125      0.0000      0.0502
          30      0.8770      1.6494      2.6271      0.0000      0.1083
          40      2.2340      1.5502      2.4885      0.0000      7.1313
          50      0.8342      1.5185      2.2496      0.1767      0.0494
          60      0.7910      1.5533      2.3696      0.0000      0.0322
          70      0.8158      1.6007      2.3925      0.0000      0.0856
          80      0.8328      1.5824      2.5675      0.0000      0.0143
          90      0.7823      1.5515      2.2676      0.0324      0.0276
         100      0.8205      1.4910      2.3896      0.0950      0.0317
         110      0.7685      1.5906      2.2342      0.0000      0.0178
         120      0.7642      1.5416      2.2360      0.0000      0.0435
         130      0.7698      1.4497      2.2389      0.0333      0.0941
         140      0.8511      1.4943      2.3140      0.2066      0.0341
         150      0.7207      1.4914      2.0850      0.0000      0.0273
         160      0.7483      1.5548      2.1591      0.0000      0.0277
         170      1.4047      1.5033      2.4760      0.0000      3.0444
         180      0.7347      1.4780      2.1569      0.0000      0.0384
         190      1.2775      1.5029      2.4483      0.0002      2.4359
         200      0.7132      1.4880      2.0370      0.0000      0.0412
         210      0.7587      1.4817      2.2798      0.0000      0.0320
         220      0.7599      1.4609      2.3083      0.0000      0.0305
         230      0.7395      1.5435      2.1165      0.0000      0.0376
         240      0.7580      1.4225      2.0983      0.1233      0.0227
         250      1.2852      1.5416      2.6101      0.0000      2.2746
         260      0.7381      1.4100      2.2471      0.0000      0.0333
         270      0.7868      1.5416      2.3555      0.0000      0.0369
         280      0.7184      1.4374      2.1297      0.0000      0.0247
         290      0.8041      1.5882      2.3820      0.0000      0.0504
         300      0.7646      1.4759      2.3232      0.0000      0.0239
         310      0.7087      1.4357      2.0749      0.0000      0.0328
         320      0.7049      1.3961      2.1001      0.0000      0.0281
         330      0.7259      1.4509      2.1398      0.0000      0.0390
         340      0.7491      1.4586      2.2550      0.0001      0.0318
         350      0.7479      1.4750      2.2369      0.0000      0.0276
         360      0.6918      1.3945      2.0339      0.0001      0.0302
         370      0.7797      1.4977      2.3242      0.0102      0.0562
         380      0.7403      1.5045      2.1467      0.0075      0.0352
         390      0.7671      1.5176      2.2926      0.0000      0.0254
         400      0.7296      1.4613      2.1593      0.0000      0.0276
         410      0.7544      1.4722      2.1082      0.0814      0.0289
         420      0.7368      1.4280      2.1609      0.0312      0.0326
         430      0.7490      1.4001      2.1704      0.0701      0.0340
         440      0.7409      1.5708      2.1061      0.0000      0.0278
         450      0.7502      1.4370      2.2904      0.0000      0.0235
         460      0.7474      1.4870      2.2217      0.0014      0.0253
         470      0.7462      1.5580      2.1387      0.0001      0.0342
         480      0.7198      1.4700      2.0962      0.0000      0.0326
         490      0.7340      1.4813      2.1617      0.0000      0.0271
         500      0.7355      1.5317      2.1198      0.0002      0.0254
         510      0.7571      1.4458      2.2964      0.0000      0.0435
         520      0.7269      1.5246      2.0759      0.0000      0.0342
         530      0.7324      1.4766      2.1448      0.0000      0.0404
         540      0.7673      1.4591      2.3435      0.0000      0.0341
         550      0.7210      1.4682      2.0968      0.0000      0.0400
         560      0.6938      1.4039      2.0372      0.0000      0.0281
         570      1.6301      1.6562      2.5130      1.9752      0.0309
         580      0.7118      1.4093      2.1088      0.0000      0.0411
         590      0.7400      1.4536      2.2128      0.0002      0.0332
         600      0.7320      1.4751      2.1510      0.0000      0.0338
       final      0.6918      1.3945      2.0339      0.0001      0.0302
best loss step: 360
Max CUDA memory: 1.4150G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_29: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_29 in 15.29 minutes.
