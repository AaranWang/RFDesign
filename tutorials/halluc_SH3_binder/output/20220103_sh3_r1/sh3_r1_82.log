/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[21:49:06] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 82, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_82, length 70...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      0.9836      1.9191      2.9891      0.0006      0.0085
          10      2.3415      1.5475      2.8868      0.8308      5.6117
          20      1.1086      1.6012      2.9452      0.4908      0.0150
          30      1.2188      1.6137      2.9563      0.7574      0.0094
          40      1.2406      1.6078      2.9181      0.8369      0.0034
          50      0.9054      1.5943      2.9278      0.0000      0.0051
          60      0.9136      1.5879      2.9019      0.0356      0.0073
          70      0.9573      1.6528      2.8558      0.1359      0.0059
          80      0.8817      1.5263      2.7983      0.0244      0.0353
          90      0.8135      1.4770      2.5545      0.0000      0.0359
         100      1.1989      1.8415      2.5901      0.7625      0.0380
         110      0.8581      1.5632      2.6338      0.0000      0.0934
         120      1.0254      1.5153      2.5296      0.0000      1.0823
         130      0.8915      1.6289      2.6971      0.0000      0.1317
         140      0.8590      1.6394      2.6326      0.0000      0.0229
         150      0.8065      1.6771      2.3272      0.0001      0.0278
         160      0.7920      1.5588      2.3808      0.0000      0.0203
         170      0.8734      1.6167      2.5727      0.0001      0.1773
         180      0.8099      1.7479      2.2803      0.0001      0.0214
         190      0.8244      1.7299      2.1637      0.1051      0.0180
         200      0.8008      1.7079      2.2682      0.0000      0.0279
         210      0.7722      1.5890      2.2475      0.0000      0.0247
         220      0.8338      1.6970      2.4251      0.0003      0.0464
         230      0.7068      1.6128      1.8990      0.0007      0.0208
         240      0.7673      1.6305      2.1838      0.0000      0.0220
         250      0.7869      1.6705      2.2421      0.0000      0.0216
         260      0.7601      1.6246      2.1503      0.0000      0.0259
         270      0.7691      1.6105      2.2092      0.0000      0.0256
         280      0.7679      1.5493      2.2652      0.0000      0.0249
         290      0.7636      1.6513      2.1416      0.0000      0.0253
         300      0.7341      1.6300      2.0144      0.0000      0.0260
         310      0.8189      1.6829      2.3830      0.0000      0.0286
         320      0.7691      1.7058      2.1190      0.0000      0.0206
         330      0.7338      1.5954      2.0536      0.0000      0.0198
         340      0.7630      1.5978      2.1831      0.0000      0.0343
         350      0.8310      1.6622      2.3986      0.0111      0.0721
         360      0.8158      1.6121      2.2396      0.0986      0.0301
         370      0.7547      1.5938      2.1446      0.0000      0.0353
         380      0.9215      1.6325      2.5273      0.0001      0.4476
         390      0.7383      1.6477      2.0155      0.0000      0.0281
         400      0.8157      1.6330      2.4125      0.0064      0.0204
         410      0.7403      1.6684      2.0060      0.0000      0.0272
         420      0.7433      1.5738      2.1118      0.0000      0.0307
         430      0.7575      1.6581      2.1023      0.0000      0.0272
         440      0.7979      1.6249      2.3225      0.0000      0.0422
         450      0.7560      1.7300      2.0216      0.0000      0.0286
         460      0.8408      1.5612      2.3544      0.1158      0.0569
         470      1.2407      1.5674      2.2864      1.1682      0.0136
         480      0.7206      1.4500      2.1071      0.0000      0.0459
         490      0.9110      1.6106      2.3584      0.2840      0.0179
         500      0.7355      1.6090      2.0438      0.0001      0.0243
         510      0.7970      1.4361      2.4027      0.0372      0.0717
         520      0.7941      1.4977      2.4158      0.0104      0.0365
         530      0.8030      1.6198      2.3521      0.0000      0.0429
         540      0.7953      1.5826      2.3516      0.0014      0.0397
         550      0.7458      1.5270      2.1544      0.0000      0.0477
         560      0.8019      1.6142      2.3667      0.0000      0.0287
         570      0.7784      1.5031      2.3308      0.0000      0.0582
         580      0.7528      1.6628      2.0723      0.0000      0.0289
         590      0.7865      1.6214      2.2874      0.0000      0.0236
         600      0.8398      1.6697      2.5103      0.0001      0.0191
       final      0.7068      1.6128      1.8990      0.0007      0.0208
best loss step: 230
Max CUDA memory: 0.9662G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_82: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_82 in 14.25 minutes.

Generating sh3_r1_83, length 63...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      0.9573      1.8018      2.9806      0.0000      0.0040
          10      2.0940      1.8424      2.8815      2.8697      0.0068
          20      0.8733      1.5616      2.7659      0.0000      0.0391
          30      0.8728      1.5749      2.7808      0.0000      0.0084
          40      1.4665      1.5328      2.5233      0.0000      3.2767
          50      0.8724      1.6985      2.6593      0.0001      0.0041
          60      0.8844      1.6565      2.5807      0.0000      0.1849
          70      0.7929      1.5772      2.3842      0.0000      0.0033
          80      0.7841      1.5390      2.3742      0.0000      0.0072
          90      0.7749      1.4944      2.3763      0.0000      0.0039
         100      0.7434      1.5145      2.1992      0.0000      0.0034
         110      0.8887      1.5260      2.4537      0.0369      0.3898
         120      0.8704      1.5944      2.5819      0.0000      0.1755
         130      0.8367      1.5439      2.3778      0.0000      0.2616
         140      0.7716      1.4442      2.3086      0.0001      0.1053
         150      0.7962      1.5624      2.3269      0.0000      0.0918
         160      0.7705      1.5295      2.2321      0.0000      0.0908
         170      2.6244      1.5382      2.4527      0.0000      9.1309
         180      1.1343      1.5763      2.4228      0.0000      1.6722
         190      0.9257      1.5758      2.4682      0.0000      0.5845
         200      1.0298      1.6089      2.6407      0.0000      0.8992
         210      0.8119      1.5683      2.3325      0.0000      0.1589
         220      0.7948      1.4912      2.3452      0.0153      0.1071
         230      0.7700      1.5115      2.2595      0.0000      0.0790
         240      0.7761      1.5962      2.2072      0.0000      0.0769
         250      0.7476      1.5173      2.1446      0.0000      0.0763
         260      0.7982      1.5917      2.3161      0.0000      0.0832
         270      0.7510      1.5221      2.1480      0.0000      0.0852
         280      0.8254      1.5471      2.4386      0.0000      0.1412
         290      0.8147      1.4975      2.4922      0.0000      0.0837
         300      0.8056      1.5896      2.3454      0.0000      0.0927
         310      2.6681      1.5541      2.4471      0.0000      9.3393
         320      0.7757      1.4959      2.2880      0.0000      0.0944
         330      0.8166      1.6073      2.3732      0.0000      0.1023
         340      0.7884      1.5600      2.2870      0.0000      0.0949
         350      0.7699      1.4239      2.3285      0.0000      0.0970
         360      0.7690      1.4838      2.2828      0.0000      0.0786
         370      0.7908      1.5811      2.2778      0.0000      0.0948
         380      0.7576      1.4598      2.2618      0.0000      0.0662
         390      0.7659      1.5585      2.1830      0.0000      0.0880
         400      0.7760      1.5236      2.2591      0.0000      0.0974
         410      0.7730      1.4516      2.3104      0.0000      0.1027
         420      0.7419      1.4216      2.1920      0.0000      0.0959
         430      0.8053      1.5157      2.4170      0.0000      0.0941
         440      0.7368      1.4001      2.2053      0.0000      0.0784
         450      0.7733      1.5258      2.2700      0.0000      0.0705
         460      0.7912      1.5884      2.2968      0.0001      0.0705
         470      0.8191      1.5944      2.4221      0.0000      0.0788
         480      0.8251      1.6612      2.3149      0.0485      0.0526
         490      0.7576      1.5617      2.1505      0.0000      0.0760
         500      0.7780      1.5010      2.3014      0.0000      0.0876
         510      0.7546      1.4786      2.2128      0.0000      0.0814
         520      0.7705      1.4648      2.2938      0.0000      0.0939
         530      0.8997      1.5233      2.5818      0.0000      0.3935
         540      0.7498      1.4776      2.1818      0.0000      0.0894
         550      0.8072      1.6142      2.3596      0.0007      0.0606
         560      0.7954      1.4634      2.4300      0.0000      0.0834
         570      0.7905      1.4857      2.3866      0.0000      0.0800
         580      0.7727      1.4897      2.2766      0.0000      0.0971
         590      0.8421      1.5575      2.4845      0.0000      0.1686
         600      0.8419      1.5345      2.5311      0.0000      0.1437
       final      0.7011      1.4885      2.0135      0.0000      0.0035
best loss step: 93
Max CUDA memory: 0.8358G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_83: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_83 in 13.99 minutes.
