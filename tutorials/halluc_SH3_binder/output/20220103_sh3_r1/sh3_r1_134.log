/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[23:04:53] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 134, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_134, length 79...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.4817      1.7599      2.9256      1.3536      0.0157
          10      1.5206      1.6017      2.9850      0.0464      2.9235
          20      1.3953      1.6848      2.9237      1.0799      0.2080
          30      1.3488      1.6990      2.9291      0.5820      0.9518
          40      0.9928      1.7112      2.8753      0.1246      0.1283
          50      1.0802      1.7069      2.9174      0.3252      0.1265
          60      1.2932      1.6480      2.8913      0.7680      0.3905
          70      1.4067      1.5836      2.8566      1.1799      0.2335
          80      0.9287      1.6746      2.8865      0.0000      0.0825
          90      1.0571      1.6743      2.8688      0.3221      0.0983
         100      1.8466      1.6359      2.8299      2.3714      0.0246
         110      0.9125      1.6756      2.8649      0.0000      0.0220
         120      1.0123      1.6531      2.9152      0.1930      0.1075
         130      1.6168      1.6174      2.8693      1.7630      0.0713
         140      0.9046      1.5856      2.8063      0.0000      0.1310
         150      0.8910      1.5668      2.8159      0.0000      0.0725
         160      0.8380      1.5864      2.5854      0.0000      0.0183
         170      0.8057      1.6224      2.3857      0.0023      0.0158
         180      0.7940      1.5813      2.3705      0.0000      0.0182
         190      0.8712      1.5996      2.6785      0.0000      0.0781
         200      0.8190      1.6006      2.4793      0.0018      0.0115
         210      0.9221      1.7178      2.3272      0.2779      0.0097
         220      0.8619      1.5961      2.5917      0.0000      0.1218
         230      0.7577      1.5664      2.2032      0.0002      0.0184
         240      0.7423      1.5961      2.0908      0.0000      0.0248
         250      0.7785      1.5104      2.3628      0.0003      0.0190
         260      0.7547      1.6397      2.1125      0.0000      0.0213
         270      0.7441      1.5736      2.1327      0.0001      0.0140
         280      0.7329      1.4581      2.1839      0.0000      0.0224
         290      2.4130      1.4890      2.6849      0.0000      7.8913
         300      0.8135      1.4857      2.4854      0.0001      0.0965
         310      0.7599      1.4557      2.3184      0.0006      0.0243
         320      0.7088      1.4223      2.0976      0.0000      0.0241
         330      0.7472      1.4477      2.2626      0.0000      0.0259
         340      0.7433      1.4806      2.2169      0.0000      0.0191
         350      0.7366      1.5075      2.1599      0.0000      0.0155
         360      0.7997      1.5158      2.4455      0.0076      0.0218
         370      0.7651      1.4476      2.3548      0.0000      0.0231
         380      0.8154      1.5093      2.5616      0.0000      0.0059
         390      0.7428      1.5823      2.1153      0.0000      0.0162
         400      0.7535      1.4703      2.2846      0.0000      0.0125
         410      0.7618      1.5458      2.2492      0.0000      0.0139
         420      0.7274      1.4802      2.1394      0.0000      0.0173
         430      2.3921      1.4879      2.5463      0.0000      7.9262
         440      0.7526      1.4945      2.2289      0.0000      0.0399
         450      0.7282      1.4286      2.1896      0.0000      0.0230
         460      0.7077      1.4441      2.0707      0.0000      0.0239
         470      0.7865      1.4398      2.4027      0.0000      0.0902
         480      0.7566      1.3796      2.3854      0.0000      0.0181
         490      0.7543      1.4101      2.3472      0.0000      0.0143
         500      0.7429      1.4456      2.2542      0.0027      0.0093
         510      0.7241      1.4402      2.1633      0.0018      0.0135
         520      0.7294      1.4184      2.1883      0.0000      0.0401
         530      0.7410      1.4837      2.2063      0.0003      0.0146
         540      0.7635      1.4887      2.3104      0.0000      0.0182
         550      0.7459      1.5001      2.2081      0.0000      0.0210
         560      0.7329      1.4135      2.2268      0.0000      0.0244
         570      0.7284      1.4300      2.1851      0.0000      0.0271
         580      0.6939      1.4208      2.0319      0.0000      0.0170
         590      0.8566      1.5011      2.3647      0.2040      0.0090
         600      0.7362      1.4372      2.2108      0.0000      0.0331
       final      0.6833      1.3752      2.0209      0.0000      0.0204
best loss step: 546
Max CUDA memory: 1.1597G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_134: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_134 in 16.18 minutes.

Generating sh3_r1_135, length 92...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.5294      1.6573      2.9472      0.0000      3.0422
          10      1.1627      1.5885      2.9789      0.0000      1.2458
          20      0.9249      1.7094      2.9023      0.0000      0.0129
          30      0.8562      1.4442      2.8180      0.0000      0.0189
          40      1.4548      1.5473      2.8341      1.4083      0.0757
          50      1.4611      1.5513      2.8190      1.4553      0.0248
          60      1.6504      1.6488      2.8833      1.8553      0.0093
          70      1.2089      1.4761      2.6934      0.8988      0.0775
          80      0.9261      1.5590      2.7179      0.1674      0.0186
          90      0.8177      1.5191      2.5477      0.0037      0.0144
         100      0.8533      1.7030      2.5444      0.0000      0.0190
         110      0.8841      1.6440      2.7625      0.0000      0.0139
         120      1.5624      1.6637      2.6534      1.7416      0.0114
         130      0.8077      1.5609      2.4547      0.0013      0.0202
         140      0.9031      1.5644      2.7196      0.0000      0.2313
         150      0.7837      1.4514      2.4235      0.0000      0.0435
         160      1.0038      1.4640      2.5374      0.4966      0.0245
         170      0.8099      1.4332      2.5650      0.0000      0.0513
         180      0.8258      1.4546      2.6243      0.0028      0.0443
         190      0.7831      1.4340      2.3955      0.0184      0.0493
         200      0.8513      1.4639      2.5392      0.1148      0.0236
         210      0.7909      1.4276      2.4885      0.0001      0.0380
         220      0.8241      1.4809      2.5872      0.0016      0.0491
         230      0.7800      1.4403      2.4258      0.0025      0.0287
         240      0.8156      1.4471      2.5636      0.0189      0.0295
         250      1.8008      1.4742      2.7238      0.5887      3.6285
         260      0.7984      1.3898      2.4351      0.0665      0.0339
         270      0.7615      1.3904      2.3836      0.0005      0.0325
         280      0.8283      1.4919      2.6123      0.0061      0.0248
         290      0.7461      1.4160      2.2644      0.0000      0.0503
         300      0.7927      1.4832      2.4532      0.0016      0.0239
         310      0.9351      1.4433      2.3440      0.4335      0.0212
         320      0.7989      1.3774      2.4621      0.0006      0.1538
         330      0.7749      1.3887      2.3597      0.0000      0.1262
         340      0.7910      1.4548      2.4808      0.0001      0.0194
         350      0.7740      1.4025      2.4343      0.0005      0.0324
         360      0.7517      1.3816      2.3506      0.0005      0.0251
         370      0.7821      1.4227      2.4537      0.0005      0.0328
         380      0.9065      1.4357      2.5903      0.2443      0.0182
         390      0.8054      1.4166      2.5835      0.0000      0.0271
         400      0.7735      1.4181      2.4279      0.0000      0.0214
         410      0.8467      1.5225      2.6886      0.0034      0.0154
         420      0.7466      1.4405      2.2675      0.0000      0.0247
         430      0.7788      1.3970      2.4819      0.0000      0.0151
         440      0.7648      1.4148      2.3790      0.0000      0.0300
         450      0.7795      1.4380      2.4229      0.0000      0.0365
         460      0.7501      1.4110      2.3156      0.0000      0.0238
         470      0.7626      1.4463      2.3279      0.0002      0.0386
         480      0.7555      1.4373      2.2975      0.0000      0.0426
         490      0.7969      1.4775      2.4591      0.0103      0.0272
         500      0.7801      1.3976      2.4791      0.0000      0.0237
         510      0.8353      1.4818      2.6770      0.0000      0.0177
         520      0.8233      1.4498      2.6300      0.0000      0.0366
         530      0.7712      1.4231      2.4121      0.0000      0.0208
         540      0.8877      1.5253      2.7153      0.0000      0.1978
         550      0.7744      1.4739      2.3711      0.0005      0.0260
         560      0.7693      1.4179      2.3850      0.0002      0.0430
         570      0.7839      1.4259      2.4710      0.0009      0.0206
         580      0.7810      1.4165      2.4618      0.0000      0.0267
         590      0.7481      1.4324      2.2624      0.0000      0.0457
         600      0.7780      1.4123      2.4529      0.0000      0.0248
       final      0.7213      1.3944      2.1849      0.0005      0.0263
best loss step: 396
Max CUDA memory: 1.4884G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_135: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_135 in 17.17 minutes.
