/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[22:45:31] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 120, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_120, length 96...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.2420      1.7495      2.9504      0.7218      0.0668
          10      0.9005      1.5948      2.7096      0.0001      0.1980
          20      1.2149      1.6886      2.7472      0.0001      1.6386
          30      1.7483      1.7105      2.9152      2.0519      0.0119
          40      1.1526      1.6561      2.9269      0.5008      0.1783
          50      1.0550      1.7482      2.9555      0.2458      0.0797
          60      1.4082      1.6349      2.9365      1.2077      0.0541
          70      1.2116      1.6620      2.9277      0.6937      0.0809
          80      0.9133      1.6042      2.9070      0.0002      0.0548
          90      1.0851      1.6289      2.8995      0.3954      0.1062
         100      0.9918      1.6766      2.9023      0.0000      0.3802
         110      0.9109      1.6165      2.8816      0.0056      0.0453
         120      0.9215      1.5573      2.8482      0.0520      0.0978
         130      0.8869      1.6053      2.7878      0.0112      0.0192
         140      1.3478      1.6267      2.8786      1.0950      0.0437
         150      0.9533      1.6918      2.8601      0.0921      0.0305
         160      0.9163      1.5761      2.8712      0.0527      0.0286
         170      0.8974      1.6041      2.8586      0.0027      0.0189
         180      1.1556      1.6469      2.8244      0.6443      0.0179
         190      0.8758      1.5659      2.7925      0.0000      0.0209
         200      0.8612      1.5367      2.7373      0.0059      0.0203
         210      0.9114      1.6012      2.6774      0.1336      0.0110
         220      1.0285      1.5561      2.7245      0.4233      0.0153
         230      0.9503      1.6032      2.8595      0.0232      0.2422
         240      1.1457      1.5830      2.8249      0.1352      1.0502
         250      0.8660      1.6164      2.6661      0.0000      0.0475
         260      0.8761      1.5385      2.7515      0.0355      0.0192
         270      1.2527      1.5285      2.7333      0.9217      0.1584
         280      0.8570      1.5796      2.6848      0.0000      0.0207
         290      0.8374      1.5593      2.6040      0.0000      0.0239
         300      0.8143      1.5077      2.5256      0.0001      0.0382
         310      0.9115      1.5732      2.4421      0.2543      0.0337
         320      0.8365      1.5358      2.6236      0.0000      0.0230
         330      0.8276      1.5484      2.5644      0.0000      0.0250
         340      0.8054      1.5517      2.4371      0.0000      0.0382
         350      0.8255      1.5800      2.5178      0.0000      0.0296
         360      0.7909      1.5621      2.3662      0.0000      0.0263
         370      0.8218      1.5239      2.5642      0.0000      0.0210
         380      0.8096      1.5225      2.4976      0.0025      0.0231
         390      2.5837      1.5578      2.5627      4.3702      0.0575
         400      0.8299      1.4959      2.6173      0.0000      0.0363
         410      0.7658      1.4047      2.3904      0.0001      0.0337
         420      0.7800      1.5175      2.3302      0.0002      0.0516
         430      0.8017      1.4836      2.4023      0.0453      0.0321
         440      0.8018      1.4518      2.5261      0.0000      0.0312
         450      0.8073      1.5333      2.4683      0.0001      0.0347
         460      0.7439      1.4709      2.2064      0.0011      0.0400
         470      0.9382      1.4666      2.5194      0.2068      0.2913
         480      0.7779      1.4596      2.3961      0.0000      0.0340
         490      0.7700      1.4431      2.3652      0.0000      0.0418
         500      0.7676      1.4676      2.3421      0.0000      0.0285
         510      0.7790      1.3956      2.4604      0.0003      0.0385
         520      0.7595      1.5470      2.2135      0.0000      0.0371
         530      0.8045      1.4696      2.5279      0.0000      0.0249
         540      0.7888      1.3604      2.2436      0.1519      0.0359
         550      1.3824      1.3991      2.5712      0.0442      2.8536
         560      0.7771      1.5136      2.3258      0.0000      0.0461
         570      0.7165      1.3616      2.1732      0.0010      0.0459
         580      0.7741      1.6016      2.2299      0.0000      0.0391
         590      0.8261      1.4735      2.3098      0.0000      0.3472
         600      0.8141      1.5270      2.2099      0.0001      0.3335
       final      0.7028      1.3178      2.0891      0.0333      0.0406
best loss step: 574
Max CUDA memory: 1.6005G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_120: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_120 in 15.90 minutes.

Generating sh3_r1_121, length 75...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.2222      1.5433      2.9088      0.0000      1.6588
          10      1.3754      1.5412      2.8612      1.2301      0.0145
          20      1.4334      1.5648      2.8234      1.3837      0.0115
          30      1.2168      1.5440      2.8190      0.8343      0.0522
          40      0.8756      1.6094      2.7480      0.0001      0.0203
          50      0.8690      1.5680      2.7535      0.0000      0.0233
          60      0.7939      1.5322      2.3862      0.0000      0.0510
          70      0.7666      1.5098      2.2806      0.0000      0.0425
          80      0.8669      1.5474      2.7355      0.0203      0.0110
          90      0.8623      1.5388      2.7258      0.0000      0.0468
         100      0.7903      1.4377      2.4711      0.0000      0.0429
         110      1.6125      1.7993      2.7563      0.8106      1.8857
         120      0.8223      1.5474      2.5102      0.0000      0.0540
         130      0.8184      1.4814      2.5647      0.0000      0.0459
         140      0.7927      1.5034      2.3947      0.0001      0.0655
         150      0.8339      1.5486      2.5365      0.0272      0.0301
         160      0.8326      1.5252      2.6138      0.0072      0.0097
         170      0.8334      1.5258      2.5986      0.0000      0.0424
         180      0.8136      1.4948      2.5051      0.0112      0.0456
         190      0.7838      1.4612      2.3813      0.0000      0.0766
         200      0.7868      1.4600      2.3902      0.0000      0.0836
         210      1.5150      1.5569      2.6292      1.6910      0.0068
         220      0.7274      1.4737      2.1132      0.0000      0.0500
         230      0.7879      1.4338      2.4677      0.0000      0.0383
         240      0.7534      1.4826      2.2226      0.0000      0.0621
         250      1.3187      1.5557      2.7322      1.1475      0.0109
         260      0.7651      1.4069      2.3533      0.0000      0.0655
         270      0.8136      1.4995      2.5602      0.0000      0.0080
         280      1.1831      1.6181      2.4077      0.9385      0.0130
         290      0.7542      1.4887      2.2377      0.0000      0.0446
         300      0.8005      1.5607      2.3873      0.0001      0.0541
         310      0.8346      1.5770      2.5042      0.0021      0.0876
         320      0.7981      1.6584      2.3099      0.0001      0.0224
         330      0.9046      1.6409      2.5693      0.0000      0.3126
         340      0.8500      1.5732      2.5620      0.0502      0.0142
         350      0.8181      1.5602      2.4146      0.0279      0.0601
         360      0.7479      1.4247      2.2575      0.0000      0.0574
         370      0.7563      1.4620      2.2722      0.0000      0.0473
         380      0.7674      1.4668      2.2970      0.0000      0.0731
         390      0.7556      1.4599      2.2503      0.0000      0.0680
         400      0.8096      1.4774      2.2716      0.1231      0.0525
         410      0.7461      1.4981      2.1879      0.0000      0.0445
         420      0.7353      1.4389      2.1932      0.0000      0.0446
         430      0.7173      1.4643      2.0713      0.0000      0.0509
         440      0.7931      1.4415      2.4658      0.0000      0.0580
         450      0.7240      1.4429      2.1282      0.0000      0.0488
         460      0.7098      1.4342      2.0741      0.0000      0.0406
         470      0.7655      1.5165      2.2645      0.0012      0.0443
         480      0.7779      1.4428      2.3900      0.0004      0.0561
         490      0.7432      1.5012      2.1550      0.0001      0.0598
         500      0.7420      1.4916      2.1755      0.0000      0.0432
         510      0.7237      1.4294      2.1254      0.0000      0.0638
         520      0.7116      1.4188      2.0825      0.0000      0.0567
         530      0.7109      1.4178      2.0709      0.0000      0.0659
         540      0.7359      1.3879      2.2270      0.0007      0.0630
         550      0.7583      1.4418      2.2830      0.0000      0.0669
         560      0.7200      1.4444      2.0841      0.0000      0.0713
         570      0.7360      1.4517      2.1767      0.0000      0.0516
         580      0.7892      1.4669      2.3862      0.0005      0.0919
         590      0.7475      1.4617      2.2309      0.0000      0.0448
         600      0.7404      1.4043      2.2416      0.0000      0.0560
       final      0.6979      1.4408      2.0062      0.0000      0.0425
best loss step: 527
Max CUDA memory: 1.0800G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_121: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_121 in 13.70 minutes.
