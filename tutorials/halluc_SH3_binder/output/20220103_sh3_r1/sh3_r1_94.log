/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[22:01:15] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 94, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_94, length 79...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.6115      1.8358      2.9632      1.5368      0.1847
          10      1.6484      1.7268      2.6923      1.5385      0.7457
          20      0.8599      1.6754      2.5877      0.0003      0.0357
          30      0.7810      1.5049      2.3661      0.0000      0.0340
          40      0.7896      1.4962      2.4178      0.0000      0.0340
          50      0.7840      1.6019      2.2880      0.0004      0.0295
          60      0.7518      1.5555      2.1714      0.0001      0.0318
          70      0.7455      1.5029      2.1798      0.0000      0.0446
          80      0.7545      1.4681      2.2659      0.0000      0.0384
          90      0.8041      1.4515      2.5165      0.0000      0.0523
         100      0.7036      1.3908      2.0666      0.0000      0.0604
         110      0.7956      1.5024      2.4554      0.0000      0.0201
         120      0.8411      1.5625      2.5467      0.0011      0.0939
         130      0.6926      1.4677      1.9746      0.0000      0.0207
         140      0.6668      1.4262      1.8865      0.0000      0.0216
         150      0.6632      1.3826      1.9029      0.0000      0.0305
         160      0.6598      1.3744      1.9003      0.0000      0.0241
         170      0.6858      1.3812      2.0198      0.0001      0.0277
         180      0.7779      1.3936      2.1971      0.1415      0.0159
         190      0.6845      1.3999      1.9957      0.0008      0.0253
         200      0.6878      1.4346      1.9808      0.0000      0.0236
         210      0.6912      1.4614      1.9722      0.0000      0.0222
         220      0.6704      1.3889      1.9347      0.0000      0.0285
         230      0.6761      1.4729      1.8806      0.0000      0.0272
         240      0.6646      1.3870      1.9079      0.0001      0.0282
         250      0.6742      1.4179      1.9255      0.0000      0.0273
         260      0.6653      1.3687      1.9323      0.0000      0.0256
         270      0.6791      1.4103      1.9623      0.0000      0.0230
         280      0.6728      1.3885      1.9458      0.0001      0.0294
         290      0.6638      1.3595      1.9300      0.0000      0.0293
         300      0.6885      1.4260      1.9912      0.0000      0.0255
         310      0.7265      1.5543      2.0295      0.0139      0.0208
         320      0.6599      1.3940      1.8826      0.0000      0.0228
         330      0.7053      1.4070      2.0970      0.0000      0.0224
         340      0.6371      1.2939      1.8639      0.0000      0.0276
         350      0.6563      1.3818      1.8722      0.0000      0.0274
         360      0.6808      1.4003      1.9723      0.0000      0.0316
         370      0.6657      1.3823      1.9171      0.0000      0.0291
         380      0.6671      1.3737      1.9369      0.0000      0.0249
         390      0.6661      1.3669      1.9367      0.0000      0.0270
         400      0.6779      1.3874      1.9778      0.0000      0.0243
         410      0.6835      1.5116      1.8835      0.0000      0.0225
         420      0.6891      1.4493      1.9660      0.0000      0.0299
         430      0.6643      1.3922      1.9009      0.0000      0.0285
         440      0.6621      1.3860      1.9028      0.0001      0.0216
         450      0.6751      1.3805      1.9691      0.0000      0.0258
         460      0.6738      1.4089      1.9273      0.0000      0.0327
         470      0.6559      1.4088      1.8429      0.0000      0.0278
         480      0.6696      1.3896      1.9351      0.0000      0.0235
         490      0.6904      1.4149      2.0020      0.0000      0.0349
         500      0.6562      1.3674      1.8800      0.0007      0.0325
         510      0.6692      1.3915      1.9271      0.0000      0.0274
         520      0.6929      1.4216      2.0104      0.0000      0.0325
         530      0.6647      1.3723      1.9241      0.0000      0.0271
         540      0.6750      1.4068      1.9418      0.0000      0.0262
         550      0.6886      1.4558      1.9607      0.0000      0.0267
         560      0.6779      1.4241      1.9336      0.0000      0.0320
         570      0.6550      1.3850      1.8643      0.0000      0.0258
         580      0.6759      1.4336      1.9215      0.0001      0.0242
         590      0.6615      1.3529      1.9264      0.0000      0.0282
         600      0.6602      1.3277      1.9388      0.0003      0.0340
       final      0.6352      1.3094      1.8411      0.0000      0.0256
best loss step: 338
Max CUDA memory: 1.1597G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_94: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_94 in 15.27 minutes.

Generating sh3_r1_95, length 92...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      2.5038      1.7720      2.9953      3.8396      0.0725
          10      0.9318      1.7208      2.9095      0.0000      0.0288
          20      0.8954      1.6222      2.7483      0.0000      0.1065
          30      1.6987      1.5686      2.7244      2.0485      0.1037
          40      0.8207      1.5939      2.4504      0.0000      0.0593
          50      0.7698      1.6126      2.1639      0.0000      0.0725
          60      0.8106      1.5811      2.4054      0.0000      0.0663
          70      0.7166      1.4326      2.0862      0.0000      0.0641
          80      0.7205      1.5269      2.0148      0.0000      0.0606
          90      0.7842      1.5183      2.3406      0.0044      0.0534
         100      0.7428      1.4745      2.1898      0.0000      0.0497
         110      0.7332      1.4797      2.1127      0.0000      0.0734
         120      0.8420      1.5430      2.5186      0.0001      0.1484
         130      0.7446      1.5641      2.0962      0.0000      0.0628
         140      0.7139      1.4129      2.0897      0.0005      0.0660
         150      0.7744      1.6327      2.1773      0.0000      0.0620
         160      0.7499      1.5833      2.0950      0.0000      0.0710
         170      0.7119      1.4685      2.0278      0.0001      0.0629
         180      0.7338      1.5088      2.1057      0.0002      0.0544
         190      0.7006      1.4279      2.0056      0.0003      0.0690
         200      0.7062      1.4357      2.0182      0.0000      0.0771
         210      0.7441      1.4938      2.1665      0.0018      0.0566
         220      0.6925      1.3814      2.0044      0.0000      0.0767
         230      0.7348      1.4775      2.1302      0.0002      0.0657
         240      0.7223      1.4675      2.0889      0.0000      0.0551
         250      0.6932      1.4268      1.9769      0.0000      0.0621
         260      0.7062      1.4390      2.0321      0.0000      0.0599
         270      0.6898      1.4166      1.9704      0.0000      0.0621
         280      0.6681      1.3818      1.9101      0.0000      0.0486
         290      0.7165      1.4339      2.0856      0.0000      0.0631
         300      0.6999      1.4438      1.9993      0.0000      0.0566
         310      0.6981      1.4760      1.9648      0.0000      0.0496
         320      0.6684      1.3940      1.8848      0.0000      0.0630
         330      0.6809      1.3501      1.9868      0.0000      0.0676
         340      0.6938      1.4264      1.9871      0.0000      0.0555
         350      0.7236      1.4585      2.1025      0.0000      0.0571
         360      0.6714      1.3650      1.9401      0.0000      0.0516
         370      0.6847      1.4088      1.9570      0.0000      0.0577
         380      0.6771      1.3593      1.9713      0.0000      0.0547
         390      0.6656      1.3582      1.9087      0.0000      0.0610
         400      0.6664      1.3406      1.9357      0.0000      0.0558
         410      0.6968      1.4391      1.9848      0.0000      0.0599
         420      0.6839      1.3685      1.9954      0.0000      0.0559
         430      0.7260      1.4455      2.1247      0.0000      0.0599
         440      0.7010      1.4645      1.9784      0.0000      0.0623
         450      0.8063      1.5767      2.0778      0.1655      0.0458
         460      0.6956      1.4159      1.9957      0.0000      0.0666
         470      0.7466      1.5096      2.1657      0.0000      0.0576
         480      0.6838      1.3662      1.9929      0.0000      0.0598
         490      0.7017      1.3897      2.0664      0.0000      0.0524
         500      0.7003      1.4151      2.0327      0.0000      0.0536
         510      0.6878      1.3710      2.0057      0.0000      0.0624
         520      0.7121      1.4343      2.0703      0.0000      0.0558
         530      0.6841      1.3760      1.9846      0.0000      0.0601
         540      0.6772      1.3801      1.9500      0.0000      0.0559
         550      0.6631      1.3728      1.8829      0.0000      0.0599
         560      0.6713      1.3772      1.9264      0.0000      0.0527
         570      0.6891      1.4063      1.9704      0.0000      0.0689
         580      0.6841      1.4540      1.9071      0.0000      0.0596
         590      0.6927      1.4177      1.9815      0.0000      0.0642
         600      0.6790      1.4035      1.9285      0.0000      0.0632
       final      0.6535      1.3591      1.8555      0.0000      0.0528
best loss step: 359
Max CUDA memory: 1.4884G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_95: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_95 in 16.35 minutes.
