/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[00:11:03] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 178, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_178, length 78...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      3.4034      1.6676      2.9151      0.0001     12.4340
          10      1.3189      1.6896      2.7276      1.0405      0.0965
          20      0.9229      1.6326      2.6646      0.0005      0.3163
          30      0.8043      1.5446      2.4524      0.0001      0.0244
          40      0.6879      1.4063      2.0154      0.0000      0.0176
          50      0.6556      1.3845      1.8780      0.0000      0.0153
          60      0.6841      1.4191      1.9657      0.0066      0.0224
          70      0.6519      1.3999      1.8387      0.0000      0.0208
          80      0.6372      1.3299      1.8344      0.0000      0.0218
          90      0.6550      1.4020      1.8509      0.0003      0.0217
         100      0.6436      1.3600      1.8335      0.0000      0.0247
         110      0.6388      1.3557      1.8135      0.0000      0.0249
         120      0.6376      1.3000      1.8660      0.0000      0.0219
         130      0.6556      1.3321      1.9206      0.0000      0.0255
         140      0.6600      1.3595      1.9194      0.0000      0.0213
         150      0.6639      1.4236      1.8693      0.0000      0.0265
         160      0.6698      1.3531      1.9737      0.0000      0.0224
         170      0.6542      1.4224      1.8251      0.0000      0.0234
         180      0.6387      1.3215      1.8507      0.0000      0.0214
         190      0.6469      1.3448      1.8684      0.0000      0.0214
         200      0.6599      1.4286      1.8522      0.0000      0.0186
         210      0.6368      1.3224      1.8371      0.0000      0.0245
         220      0.6447      1.3594      1.8385      0.0000      0.0254
         230      0.6580      1.3786      1.8819      0.0000      0.0293
         240      0.6950      1.4754      1.9757      0.0000      0.0238
         250      0.6468      1.3472      1.8584      0.0000      0.0284
         260      0.6825      1.3829      2.0085      0.0000      0.0210
         270      0.6503      1.4047      1.8237      0.0000      0.0232
         280      0.6648      1.4209      1.8859      0.0000      0.0171
         290      0.6301      1.3073      1.8240      0.0000      0.0191
         300      0.6605      1.4053      1.8718      0.0000      0.0253
         310      0.6460      1.3448      1.8566      0.0000      0.0287
         320      0.6839      1.3766      2.0194      0.0000      0.0237
         330      0.7071      1.4935      2.0136      0.0000      0.0281
         340      0.7413      1.4029      2.0829      0.0976      0.0255
         350      0.6497      1.3404      1.8856      0.0000      0.0224
         360      0.6891      1.4166      1.9991      0.0005      0.0287
         370      0.7284      1.5388      2.0753      0.0002      0.0277
         380      0.6447      1.3388      1.8623      0.0000      0.0224
         390      0.7323      1.4329      2.2054      0.0000      0.0229
         400      0.6457      1.4123      1.7894      0.0000      0.0269
         410      0.6576      1.3679      1.8936      0.0002      0.0260
         420      0.6634      1.3736      1.9176      0.0000      0.0259
         430      0.6371      1.3558      1.8062      0.0000      0.0236
         440      0.6599      1.3085      1.9641      0.0004      0.0259
         450      0.6835      1.4575      1.9408      0.0000      0.0192
         460      0.6535      1.3742      1.8721      0.0000      0.0213
         470      0.6725      1.3752      1.9626      0.0000      0.0250
         480      0.6742      1.4133      1.8832      0.0258      0.0227
         490      0.6593      1.4020      1.8724      0.0000      0.0221
         500      0.6347      1.3388      1.8077      0.0000      0.0269
         510      0.7038      1.3772      2.1242      0.0000      0.0178
         520      0.6499      1.3630      1.8615      0.0000      0.0250
         530      0.6597      1.3751      1.8959      0.0007      0.0263
         540      0.6486      1.3334      1.8839      0.0000      0.0259
         550      0.6440      1.4054      1.7880      0.0000      0.0266
         560      0.6246      1.3096      1.7892      0.0000      0.0242
         570      0.6782      1.4068      1.9573      0.0000      0.0267
         580      0.6350      1.3338      1.8206      0.0000      0.0208
         590      0.6724      1.3151      2.0214      0.0000      0.0257
         600      0.6529      1.3626      1.8771      0.0000      0.0249
       final      0.6196      1.3025      1.7690      0.0000      0.0266
best loss step: 131
Max CUDA memory: 1.1405G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_178: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_178 in 15.18 minutes.

Generating sh3_r1_179, length 89...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      3.0300      1.8449      2.9824      5.1333      0.0560
          10      1.1620      1.7840      2.8181      0.5826      0.0428
          20      0.8747      1.6312      2.5805      0.0529      0.0559
          30      0.8442      1.6249      2.5035      0.0000      0.0923
          40      1.0875      1.5921      2.3197      0.7287      0.0682
          50      0.7556      1.5613      2.1482      0.0000      0.0687
          60      0.7420      1.5628      2.0889      0.0000      0.0582
          70      0.7668      1.5685      2.2089      0.0000      0.0567
          80      0.7529      1.5152      2.1994      0.0000      0.0498
          90      0.7250      1.4481      2.1288      0.0000      0.0483
         100      0.7416      1.5403      2.1069      0.0000      0.0605
         110      0.7538      1.4100      2.0348      0.1384      0.0476
         120      0.7192      1.5038      2.0469      0.0000      0.0450
         130      0.7011      1.4748      1.9755      0.0000      0.0551
         140      0.7058      1.4709      1.9849      0.0091      0.0548
         150      0.7283      1.4563      2.1398      0.0000      0.0454
         160      0.7694      1.4124      2.0629      0.1585      0.0545
         170      0.7042      1.4327      2.0434      0.0000      0.0450
         180      0.7063      1.4260      2.0317      0.0141      0.0455
         190      0.7278      1.4358      2.1105      0.0204      0.0521
         200      1.7628      1.4193      2.0492      2.6488      0.0478
         210      0.7767      1.4709      2.3595      0.0000      0.0534
         220      0.7725      1.4936      2.3102      0.0000      0.0589
         230      0.7056      1.4592      2.0221      0.0000      0.0467
         240      0.6964      1.4427      1.9878      0.0000      0.0514
         250      0.6843      1.4235      1.9445      0.0015      0.0506
         260      0.7146      1.4577      1.9994      0.0325      0.0511
         270      0.7317      1.5734      2.0372      0.0001      0.0480
         280      1.1598      1.5367      2.0037      1.1062      0.0463
         290      0.7068      1.4505      2.0384      0.0016      0.0421
         300      0.6814      1.5075      1.8535      0.0000      0.0459
         310      0.7074      1.4670      2.0220      0.0007      0.0468
         320      0.7057      1.5229      1.9607      0.0000      0.0449
         330      0.6802      1.4170      1.9333      0.0005      0.0495
         340      0.6824      1.4109      1.9535      0.0010      0.0454
         350      0.6934      1.4086      1.9668      0.0224      0.0466
         360      0.6949      1.4596      1.9670      0.0003      0.0471
         370      0.7092      1.4210      2.0752      0.0000      0.0499
         380      0.7274      1.4562      2.0906      0.0238      0.0425
         390      0.6894      1.4701      1.9301      0.0000      0.0470
         400      0.7898      1.4602      2.4389      0.0091      0.0315
         410      0.6783      1.4068      1.9375      0.0000      0.0473
         420      0.6602      1.3616      1.8950      0.0000      0.0444
         430      0.6682      1.3783      1.9155      0.0000      0.0472
         440      0.6882      1.4059      1.9800      0.0036      0.0478
         450      0.7158      1.4590      2.0761      0.0000      0.0440
         460      0.6826      1.4333      1.9277      0.0011      0.0496
         470      0.7011      1.4632      1.9918      0.0000      0.0503
         480      0.6919      1.4801      1.9330      0.0001      0.0463
         490      0.7132      1.5032      2.0085      0.0000      0.0542
         500      0.7125      1.5348      1.9714      0.0000      0.0561
         510      0.7740      1.4773      2.3244      0.0000      0.0683
         520      0.7200      1.4985      2.0380      0.0091      0.0451
         530      0.6747      1.3932      1.8763      0.0279      0.0483
         540      0.6723      1.4500      1.8642      0.0010      0.0453
         550      0.6987      1.5488      1.8959      0.0001      0.0488
         560      0.6785      1.4595      1.8882      0.0000      0.0449
         570      0.7258      1.4816      2.0986      0.0002      0.0483
         580      0.6746      1.4552      1.8689      0.0000      0.0488
         590      0.7029      1.4547      2.0072      0.0000      0.0524
         600      0.7007      1.5135      1.9361      0.0033      0.0473
       final      0.6559      1.3546      1.8847      0.0000      0.0402
best loss step: 432
Max CUDA memory: 1.4170G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_179: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_179 in 15.97 minutes.
