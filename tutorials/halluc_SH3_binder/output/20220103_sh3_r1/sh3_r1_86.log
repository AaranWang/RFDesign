/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[21:54:28] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 86, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_86, length 77...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      3.3311      1.6462      2.8832      0.0000     12.1262
          10      0.9085      1.6780      2.8600      0.0000      0.0044
          20      0.9119      1.5821      2.8403      0.0662      0.0048
          30      0.8702      1.5761      2.7661      0.0000      0.0088
          40      0.9607      1.4988      2.6107      0.0005      0.6929
          50      0.7547      1.5256      2.2112      0.0000      0.0366
          60      0.7382      1.4702      2.1772      0.0000      0.0437
          70      0.6723      1.4124      1.9155      0.0000      0.0338
          80      0.6857      1.4437      1.9542      0.0000      0.0306
          90      0.7418      1.5089      2.1734      0.0000      0.0267
         100      0.6961      1.4165      2.0363      0.0004      0.0269
         110      0.7086      1.3511      2.1504      0.0047      0.0319
         120      0.7297      1.4881      2.1268      0.0001      0.0336
         130      0.7426      1.5163      2.1696      0.0004      0.0265
         140      0.7359      1.4462      2.1703      0.0197      0.0235
         150      0.7087      1.4689      2.0458      0.0000      0.0289
         160      0.7015      1.4203      2.0566      0.0000      0.0308
         170      0.6956      1.4098      2.0383      0.0001      0.0298
         180      0.6719      1.3739      1.9622      0.0005      0.0226
         190      0.7069      1.4489      2.0572      0.0003      0.0275
         200      0.7176      1.4710      2.0842      0.0001      0.0324
         210      0.7263      1.4350      2.1711      0.0004      0.0244
         220      0.7228      1.4793      2.0326      0.0382      0.0253
         230      0.7726      1.5252      2.3153      0.0000      0.0224
         240      0.7066      1.4361      2.0678      0.0001      0.0289
         250      0.7285      1.5455      2.0706      0.0000      0.0264
         260      0.6918      1.3981      2.0314      0.0021      0.0254
         270      0.7380      1.4967      2.1630      0.0000      0.0302
         280      0.7183      1.4598      2.1117      0.0000      0.0199
         290      0.6910      1.3792      2.0543      0.0000      0.0213
         300      0.7923      1.4491      2.0522      0.2161      0.0278
         310      0.7959      1.4025      2.2690      0.1412      0.0256
         320      0.7375      1.4365      2.2332      0.0002      0.0174
         330      0.6988      1.4033      2.0112      0.0280      0.0237
         340      0.7337      1.4445      2.2043      0.0000      0.0198
         350      0.7129      1.4508      2.0891      0.0002      0.0245
         360      0.7079      1.4102      2.0101      0.0492      0.0209
         370      0.7187      1.4656      2.1040      0.0000      0.0237
         380      0.6984      1.4456      1.9950      0.0135      0.0244
         390      0.7333      1.4333      2.2092      0.0001      0.0235
         400      0.6862      1.4141      1.9867      0.0035      0.0229
         410      0.7176      1.4542      2.1083      0.0009      0.0240
         420      0.7052      1.4069      2.0927      0.0001      0.0263
         430      0.7207      1.4498      2.1244      0.0037      0.0218
         440      0.7148      1.4518      2.1002      0.0001      0.0221
         450      0.7397      1.4593      2.0910      0.0601      0.0280
         460      0.7078      1.3580      2.1581      0.0000      0.0231
         470      0.6705      1.3713      1.9238      0.0181      0.0213
         480      0.7383      1.5405      2.1242      0.0003      0.0264
         490      0.7233      1.4071      2.1831      0.0014      0.0233
         500      0.7065      1.4671      2.0424      0.0001      0.0229
         510      0.7131      1.4391      2.0992      0.0000      0.0271
         520      0.7463      1.5219      2.1800      0.0018      0.0261
         530      1.7195      1.4579      2.4746      0.0000      4.6648
         540      0.7728      1.6102      2.2232      0.0055      0.0197
         550      0.7070      1.4000      2.1104      0.0002      0.0241
         560      0.7290      1.5135      2.1139      0.0000      0.0175
         570      0.7454      1.4789      2.2100      0.0095      0.0189
         580      0.7113      1.4845      2.0450      0.0000      0.0270
         590      0.7016      1.4598      2.0255      0.0003      0.0223
         600      0.7148      1.4629      2.0527      0.0170      0.0246
       final      0.6681      1.3685      1.9141      0.0167      0.0246
best loss step: 482
Max CUDA memory: 1.1069G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_86: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_86 in 14.57 minutes.

Generating sh3_r1_87, length 85...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.4372      1.6993      2.9176      0.3215      1.9262
          10      0.9475      1.7070      2.7513      0.0001      0.2787
          20      0.9106      1.7448      2.7648      0.0033      0.0370
          30      1.1540      1.5391      2.7923      0.6275      0.1837
          40      1.0572      1.5814      2.7989      0.3762      0.1532
          50      0.8861      1.5515      2.7523      0.0000      0.1267
          60      0.8392      1.5658      2.6137      0.0007      0.0153
          70      0.8546      1.6122      2.5731      0.0001      0.0876
          80      0.8886      1.6662      2.7193      0.0037      0.0502
          90      0.8387      1.6440      2.5077      0.0001      0.0417
         100      0.8197      1.5168      2.5415      0.0000      0.0402
         110      1.0864      1.5181      2.6150      0.6390      0.0212
         120      0.7531      1.4690      2.2658      0.0000      0.0306
         130      0.9046      1.5280      2.6286      0.0000      0.3665
         140      0.8653      1.5518      2.5888      0.0228      0.1406
         150      0.8306      1.6135      2.5034      0.0000      0.0363
         160      0.8449      1.6103      2.5789      0.0000      0.0351
         170      0.8971      1.5765      2.5838      0.0038      0.3173
         180      0.8851      1.5471      2.6483      0.0113      0.2077
         190      0.8102      1.5585      2.4591      0.0000      0.0335
         200      0.7979      1.4228      2.3784      0.0797      0.0291
         210      0.7898      1.5117      2.4125      0.0000      0.0250
         220      0.8628      1.6846      2.6077      0.0000      0.0217
         230      0.8240      1.5627      2.5248      0.0000      0.0322
         240      0.8336      1.4994      2.4640      0.0499      0.1049
         250      0.9319      1.4996      2.5190      0.2878      0.0655
         260      0.7734      1.5226      2.2816      0.0000      0.0628
         270      0.8507      1.5273      2.6466      0.0000      0.0796
         280      0.8311      1.5171      2.6018      0.0000      0.0364
         290      0.8100      1.5275      2.4578      0.0001      0.0648
         300      0.7965      1.5967      2.3527      0.0000      0.0329
         310      0.7517      1.4552      2.2493      0.0000      0.0538
         320      0.7690      1.4839      2.2727      0.0165      0.0555
         330      0.7596      1.4581      2.2667      0.0023      0.0688
         340      0.7686      1.4839      2.2609      0.0046      0.0891
         350      0.7577      1.5425      2.1602      0.0000      0.0860
         360      0.7380      1.5011      2.1050      0.0000      0.0837
         370      0.7311      1.4260      2.1375      0.0003      0.0914
         380      0.7455      1.5199      2.1458      0.0000      0.0616
         390      0.7723      1.5722      2.2373      0.0000      0.0520
         400      0.7264      1.4584      2.1113      0.0000      0.0624
         410      0.9177      1.5163      2.4007      0.0000      0.6713
         420      0.7355      1.5136      2.1192      0.0000      0.0445
         430      0.7258      1.4562      2.1214      0.0000      0.0513
         440      0.9922      1.5789      2.5807      0.0000      0.8015
         450      0.7344      1.5160      2.0818      0.0000      0.0740
         460      0.8628      1.4916      2.4618      0.0031      0.3543
         470      0.8626      1.4620      2.5281      0.0001      0.3227
         480      0.7457      1.4333      2.1684      0.0398      0.0474
         490      0.7649      1.4906      2.3052      0.0000      0.0287
         500      0.7077      1.3448      2.1301      0.0001      0.0636
         510      0.7419      1.4735      2.1763      0.0063      0.0472
         520      0.7596      1.5428      2.2061      0.0000      0.0490
         530      0.7327      1.4112      2.1846      0.0000      0.0675
         540      0.8261      1.5227      2.5496      0.0000      0.0583
         550      0.7471      1.5281      2.1605      0.0001      0.0465
         560      0.7491      1.4533      2.2409      0.0000      0.0513
         570      0.7227      1.4454      2.1010      0.0005      0.0661
         580      0.7513      1.5676      2.1315      0.0015      0.0542
         590      0.8059      1.5073      2.4032      0.0001      0.1191
         600      0.7541      1.4044      2.3085      0.0001      0.0576
       final      0.6872      1.3582      2.0305      0.0001      0.0474
best loss step: 542
Max CUDA memory: 1.3117G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_87: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_87 in 14.83 minutes.
