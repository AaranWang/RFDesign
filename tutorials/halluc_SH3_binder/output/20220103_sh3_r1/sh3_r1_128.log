/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[22:56:11] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 128, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_128, length 74...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      2.1159      1.7833      2.8976      2.9432      0.0120
          10      0.9584      1.8223      2.8796      0.0002      0.0900
          20      0.9849      1.6575      2.8410      0.1596      0.1067
          30      0.8781      1.5109      2.7988      0.0000      0.0808
          40      0.8248      1.5042      2.5057      0.0229      0.0682
          50      0.8246      1.4091      2.4896      0.0823      0.0595
          60      0.8440      1.5146      2.6106      0.0000      0.0948
          70      0.7898      1.5255      2.3773      0.0000      0.0460
          80      0.7465      1.4126      2.2386      0.0088      0.0638
          90      0.7362      1.3846      2.2285      0.0000      0.0678
         100      0.7593      1.4104      2.3209      0.0000      0.0652
         110      0.7659      1.4316      2.3533      0.0003      0.0440
         120      0.7922      1.7574      2.1394      0.0124      0.0393
         130      0.7253      1.4695      2.1137      0.0000      0.0434
         140      0.6937      1.3213      2.0308      0.0319      0.0529
         150      0.7261      1.3621      2.1889      0.0072      0.0651
         160      0.7902      1.3407      2.0314      0.2652      0.0484
         170      0.7306      1.3395      2.1384      0.0209      0.1334
         180      0.7407      1.3342      2.2220      0.0010      0.1455
         190      0.6859      1.3090      2.0659      0.0056      0.0435
         200      0.7322      1.4378      2.0706      0.0003      0.1521
         210      0.7266      1.3151      2.1347      0.0201      0.1431
         220      0.7183      1.3647      2.0715      0.0002      0.1548
         230      0.7397      1.3790      2.1695      0.0000      0.1501
         240      0.6982      1.3400      2.0071      0.0002      0.1433
         250      0.7150      1.3105      2.1229      0.0003      0.1409
         260      0.7084      1.3008      2.0853      0.0001      0.1556
         270      0.7036      1.3479      2.0182      0.0004      0.1511
         280      0.7171      1.3816      2.0642      0.0001      0.1396
         290      0.7316      1.3553      2.1532      0.0000      0.1496
         300      0.7181      1.2855      2.0264      0.0622      0.1540
         310      0.6979      1.2875      2.0567      0.0000      0.1454
         320      0.7078      1.3375      1.9957      0.0282      0.1492
         330      0.6973      1.2975      2.0462      0.0008      0.1410
         340      0.6905      1.2765      2.0067      0.0109      0.1476
         350      0.7352      1.4070      2.1487      0.0000      0.1204
         360      0.7247      1.4202      2.0640      0.0000      0.1392
         370      0.7162      1.4150      2.0035      0.0135      0.1357
         380      0.7269      1.3711      2.1116      0.0009      0.1502
         390      0.6905      1.2764      2.0377      0.0002      0.1379
         400      0.7456      1.3834      2.1456      0.0274      0.1444
         410      0.7532      1.3516      2.2184      0.0187      0.1585
         420      0.7146      1.3911      2.0383      0.0001      0.1433
         430      0.7048      1.3589      2.0174      0.0006      0.1465
         440      0.6988      1.3297      2.0219      0.0000      0.1426
         450      0.7202      1.3377      2.0089      0.0566      0.1412
         460      0.7147      1.3005      2.0166      0.0583      0.1399
         470      0.6867      1.2878      2.0014      0.0031      0.1383
         480      0.7279      1.3123      2.0834      0.0539      0.1360
         490      0.7708      1.3139      2.1105      0.1333      0.1630
         500      0.7243      1.3176      2.1561      0.0002      0.1472
         510      0.7101      1.3437      2.0469      0.0021      0.1557
         520      0.7431      1.4000      2.1697      0.0001      0.1457
         530      0.7186      1.3511      2.0674      0.0164      0.1418
         540      0.6951      1.3093      2.0134      0.0009      0.1508
         550      0.6947      1.2751      2.0498      0.0025      0.1438
         560      0.7109      1.3880      1.9917      0.0140      0.1466
         570      0.7021      1.3227      2.0413      0.0000      0.1467
         580      0.7146      1.2728      2.1269      0.0142      0.1447
         590      0.6658      1.2155      1.9680      0.0009      0.1438
         600      0.7074      1.3281      1.9931      0.0384      0.1391
       final      0.6658      1.2155      1.9680      0.0009      0.1438
best loss step: 590
Max CUDA memory: 1.0476G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_128: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_128 in 14.78 minutes.

Generating sh3_r1_129, length 80...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.0261      1.7454      2.8716      0.0098      0.4938
          10      0.9265      1.6382      2.9196      0.0009      0.0731
          20      1.8191      1.6894      2.8819      1.8539      0.8164
          30      0.9301      1.7101      2.9286      0.0001      0.0117
          40      0.9036      1.5852      2.8094      0.0000      0.1234
          50      0.9125      1.6596      2.8500      0.0000      0.0531
          60      0.8826      1.5839      2.7576      0.0156      0.0402
          70      0.8674      1.5459      2.7588      0.0000      0.0325
          80      0.8598      1.5480      2.7441      0.0000      0.0066
          90      0.8518      1.5883      2.6129      0.0000      0.0577
         100      0.8476      1.5430      2.6516      0.0000      0.0433
         110      0.8113      1.4548      2.5899      0.0000      0.0118
         120      0.8053      1.5511      2.4575      0.0004      0.0170
         130      0.8347      1.6178      2.5227      0.0001      0.0327
         140      0.7603      1.4890      2.2955      0.0000      0.0170
         150      0.7253      1.5037      2.1067      0.0000      0.0161
         160      0.7074      1.4555      2.0604      0.0000      0.0208
         170      0.7658      1.4653      2.3430      0.0017      0.0174
         180      0.6835      1.4090      1.9880      0.0000      0.0205
         190      0.6935      1.4998      1.9490      0.0000      0.0187
         200      0.6758      1.4339      1.9241      0.0000      0.0210
         210      0.6741      1.4628      1.8883      0.0000      0.0197
         220      0.6654      1.4407      1.8676      0.0000      0.0186
         230      0.6626      1.4015      1.8909      0.0000      0.0205
         240      0.6596      1.3666      1.9135      0.0000      0.0179
         250      0.6669      1.4612      1.8531      0.0000      0.0204
         260      0.6422      1.3892      1.8009      0.0000      0.0208
         270      0.6577      1.4084      1.8603      0.0000      0.0196
         280      0.6488      1.3997      1.8262      0.0000      0.0182
         290      0.6507      1.4421      1.7922      0.0000      0.0194
         300      0.6380      1.3696      1.8018      0.0000      0.0183
         310      0.6745      1.4300      1.9250      0.0000      0.0178
         320      0.6529      1.3829      1.8612      0.0000      0.0202
         330      0.6504      1.3671      1.8659      0.0000      0.0191
         340      0.6545      1.4174      1.8362      0.0000      0.0189
         350      0.6652      1.4434      1.8639      0.0000      0.0189
         360      0.6659      1.4453      1.8681      0.0000      0.0159
         370      0.6539      1.4006      1.8539      0.0000      0.0148
         380      0.6598      1.3940      1.8836      0.0000      0.0212
         390      0.6711      1.4395      1.8977      0.0000      0.0183
         400      0.6328      1.3631      1.7831      0.0000      0.0181
         410      0.6601      1.4076      1.8733      0.0000      0.0197
         420      0.6524      1.4457      1.7962      0.0000      0.0202
         430      0.6762      1.4401      1.9223      0.0000      0.0188
         440      0.6602      1.4643      1.8182      0.0000      0.0184
         450      0.6527      1.3701      1.8724      0.0000      0.0211
         460      0.6824      1.4019      1.9911      0.0000      0.0191
         470      0.6330      1.3456      1.8010      0.0000      0.0187
         480      0.6427      1.3779      1.8186      0.0000      0.0171
         490      0.6589      1.3843      1.8915      0.0000      0.0185
         500      0.6503      1.3871      1.8476      0.0000      0.0167
         510      0.6313      1.3557      1.7815      0.0000      0.0191
         520      0.6459      1.4019      1.8112      0.0000      0.0162
         530      0.6285      1.3393      1.7862      0.0000      0.0168
         540      0.6379      1.3919      1.7822      0.0000      0.0157
         550      0.6297      1.3069      1.8231      0.0000      0.0187
         560      0.6827      1.3724      2.0216      0.0000      0.0196
         570      0.6234      1.3321      1.7668      0.0000      0.0180
         580      0.6412      1.3720      1.8147      0.0000      0.0195
         590      0.6672      1.4119      1.9076      0.0000      0.0167
         600      0.6393      1.3633      1.8142      0.0000      0.0191
       final      0.6218      1.3149      1.7775      0.0000      0.0168
best loss step: 567
Max CUDA memory: 1.1847G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_129: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_129 in 14.76 minutes.
