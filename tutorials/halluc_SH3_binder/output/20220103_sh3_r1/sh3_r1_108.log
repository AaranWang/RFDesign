/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[22:26:40] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 108, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_108, length 86...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.0060      1.6397      2.9655      0.0601      0.3046
          10      1.3059      1.6963      2.8940      0.8710      0.1970
          20      0.8917      1.6415      2.7348      0.0319      0.0185
          30      1.8048      1.6742      2.9255      2.2103      0.0039
          40      0.9908      1.6513      2.8640      0.2123      0.0142
          50      0.9488      1.6120      2.9765      0.0141      0.1274
          60      1.4232      1.6079      2.9647      0.8633      0.8169
          70      0.9048      1.5821      2.9126      0.0016      0.0262
          80      0.9210      1.6311      2.9318      0.0000      0.0420
          90      0.9529      1.6006      2.8970      0.0000      0.2668
         100      0.9177      1.6487      2.9207      0.0000      0.0190
         110      1.0277      1.5199      2.9539      0.3251      0.0144
         120      0.8986      1.5194      2.9508      0.0005      0.0216
         130      0.8905      1.5329      2.8044      0.0465      0.0220
         140      0.9089      1.5837      2.9306      0.0000      0.0299
         150      1.5365      1.5401      2.9619      0.0000      3.1803
         160      1.3513      1.5856      2.9412      1.0226      0.1844
         170      1.2713      1.5543      2.9000      0.7831      0.3363
         180      0.9634      1.5746      2.8558      0.1841      0.0180
         190      1.1764      1.5797      2.9108      0.6822      0.0272
         200      0.9013      1.5211      2.9103      0.0248      0.0256
         210      0.9336      1.5571      2.8977      0.0968      0.0195
         220      0.9154      1.6515      2.9040      0.0000      0.0214
         230      0.8930      1.5098      2.9097      0.0000      0.0455
         240      0.9035      1.6113      2.8961      0.0001      0.0098
         250      0.9038      1.6743      2.8315      0.0008      0.0114
         260      0.9125      1.6120      2.9350      0.0000      0.0155
         270      0.9000      1.5347      2.9491      0.0000      0.0160
         280      0.9474      1.5887      2.8660      0.0993      0.0835
         290      1.3760      1.5403      2.8164      1.2450      0.0335
         300      1.0865      1.5556      2.8341      0.5171      0.0086
         310      0.8313      1.4976      2.6275      0.0000      0.0315
         320      0.8074      1.5552      2.4540      0.0000      0.0276
         330      0.7804      1.5479      2.3333      0.0001      0.0207
         340      0.8077      1.5769      2.4410      0.0001      0.0203
         350      0.7819      1.4452      2.4415      0.0000      0.0226
         360      0.7838      1.6137      2.2818      0.0000      0.0234
         370      0.7532      1.5813      2.1558      0.0000      0.0286
         380      0.7728      1.5131      2.3233      0.0000      0.0274
         390      0.7538      1.5389      2.2034      0.0000      0.0268
         400      0.7568      1.5481      2.2059      0.0000      0.0300
         410      0.7413      1.5089      2.1660      0.0000      0.0315
         420      0.7379      1.5068      2.1591      0.0000      0.0238
         430      1.3984      1.6080      2.3125      0.0000      3.0713
         440      0.7314      1.5009      2.1358      0.0000      0.0202
         450      0.7302      1.4797      2.1527      0.0000      0.0187
         460      0.7458      1.5834      2.1303      0.0000      0.0152
         470      0.7022      1.4390      2.0534      0.0000      0.0187
         480      0.6918      1.4929      1.9485      0.0001      0.0174
         490      0.6952      1.4960      1.9591      0.0000      0.0209
         500      0.6761      1.4706      1.8870      0.0000      0.0228
         510      0.7288      1.5542      2.0618      0.0000      0.0280
         520      0.7136      1.5357      2.0105      0.0000      0.0216
         530      0.7085      1.5173      1.9997      0.0000      0.0256
         540      0.7055      1.4994      2.0121      0.0000      0.0161
         550      0.7043      1.4789      2.0179      0.0000      0.0248
         560      0.7239      1.5334      2.0659      0.0000      0.0203
         570      0.7036      1.4999      1.9966      0.0000      0.0216
         580      0.7466      1.5337      2.1739      0.0030      0.0193
         590      0.7089      1.5131      2.0155      0.0000      0.0161
         600      0.7229      1.5332      2.0583      0.0000      0.0229
       final      0.6702      1.4415      1.8894      0.0000      0.0202
best loss step: 509
Max CUDA memory: 1.3285G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_108: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_108 in 15.10 minutes.

Generating sh3_r1_109, length 56...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.6566      1.6744      2.8545      0.4366      2.8807
          10      1.2030      1.7856      2.9554      0.0100      1.2539
          20      1.6369      1.8354      2.8734      1.7212      0.0330
          30      1.4327      1.6703      2.9164      1.2818      0.0133
          40      1.0303      1.6368      2.9484      0.0205      0.5256
          50      0.9823      1.5581      2.9333      0.0002      0.4197
          60      0.9120      1.6138      2.9138      0.0000      0.0321
          70      0.8887      1.5138      2.8260      0.0000      0.1036
          80      1.1629      1.5625      2.8971      0.5001      0.3548
          90      1.3819      1.4885      2.9225      1.2354      0.0279
         100      0.9194      1.4594      2.6637      0.0153      0.4435
         110      1.9700      1.4722      2.9284      2.7021      0.0450
         120      0.9007      1.4901      2.8350      0.0000      0.1786
         130      0.8447      1.4249      2.7297      0.0001      0.0686
         140      0.9133      1.6269      2.7784      0.0330      0.0950
         150      1.3957      1.5385      2.7634      0.0056      2.6655
         160      0.8868      1.4875      2.7272      0.0000      0.2195
         170      0.8873      1.4905      2.7955      0.0050      0.1408
         180      0.8994      1.5966      2.8695      0.0003      0.0302
         190      0.8734      1.5130      2.8230      0.0015      0.0280
         200      0.8968      1.5179      2.7993      0.0021      0.1624
         210      1.2739      1.5054      2.8118      0.9677      0.1169
         220      1.0716      1.5590      2.8263      0.4561      0.0605
         230      0.9093      1.5632      2.7624      0.0463      0.1284
         240      1.3203      1.5343      2.7770      1.0991      0.0917
         250      0.9238      1.5869      2.8193      0.0000      0.2128
         260      1.2757      1.4784      2.8373      1.0101      0.0425
         270      0.8497      1.5959      2.6122      0.0002      0.0400
         280      1.2501      1.6615      2.7343      0.9213      0.0122
         290      0.9770      1.5278      2.5908      0.3702      0.0259
         300      1.1850      1.5421      2.6521      0.0000      1.7311
         310      1.0681      1.4752      2.1932      0.8191      0.0339
         320      0.7958      1.6815      2.2771      0.0000      0.0203
         330      1.1691      1.5254      2.5809      0.3837      0.9718
         340      1.0244      1.5162      2.5382      0.0000      1.0676
         350      0.9918      1.4674      2.6406      0.0000      0.8509
         360      0.9779      1.5937      2.6412      0.0000      0.6546
         370      0.8867      1.5123      2.5925      0.0000      0.3288
         380      0.8423      1.4775      2.6855      0.0000      0.0484
         390      0.8524      1.5619      2.6039      0.0000      0.0964
         400      0.9381      1.5037      2.5676      0.0000      0.6191
         410      0.8545      1.5967      2.6191      0.0000      0.0569
         420      0.8500      1.5562      2.5644      0.0190      0.0913
         430      0.8817      1.6597      2.5939      0.0000      0.1548
         440      0.8414      1.5872      2.5761      0.0000      0.0436
         450      0.8222      1.5251      2.4975      0.0000      0.0882
         460      0.7964      1.5256      2.3257      0.0000      0.1309
         470      0.7956      1.4969      2.3948      0.0066      0.0733
         480      0.7965      1.4695      2.3889      0.0225      0.0790
         490      0.8485      1.6101      2.5620      0.0000      0.0704
         500      0.7881      1.5147      2.3325      0.0000      0.0933
         510      0.9227      1.5358      2.4938      0.0001      0.5839
         520      0.8077      1.5610      2.4276      0.0000      0.0498
         530      0.8680      1.6202      2.5285      0.0000      0.1914
         540      0.8908      1.3879      2.2919      0.0166      0.7411
         550      0.7953      1.5484      2.3397      0.0000      0.0883
         560      0.9672      1.5411      2.4978      0.0000      0.7969
         570      0.9603      1.5513      2.6224      0.0000      0.6278
         580      0.9622      1.5534      2.7085      0.0000      0.5493
         590      0.8472      1.5614      2.5637      0.0000      0.1111
         600      0.9604      1.6016      2.6136      0.2617      0.0634
       final      0.7585      1.5404      2.2242      0.0007      0.0264
best loss step: 311
Max CUDA memory: 0.7158G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_109: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_109 in 14.12 minutes.
