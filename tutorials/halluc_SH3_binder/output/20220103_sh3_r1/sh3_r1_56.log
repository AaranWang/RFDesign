/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[20:59:46] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 56, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_56, length 83...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      2.3260      1.7725      2.9055      3.3990      0.1538
          10      0.9421      1.8774      2.7526      0.0003      0.0800
          20      0.9554      1.7763      2.6425      0.1656      0.0269
          30      0.8365      1.6513      2.4299      0.0277      0.0459
          40      0.8022      1.7264      2.2433      0.0078      0.0257
          50      0.7848      1.5254      2.3086      0.0330      0.0238
          60      0.7330      1.6228      2.0098      0.0000      0.0324
          70      0.7557      1.6063      2.1354      0.0000      0.0368
          80      0.7467      1.5017      2.1689      0.0161      0.0307
          90      0.7989      1.5871      2.3441      0.0000      0.0633
         100      0.7504      1.5672      2.1562      0.0000      0.0285
         110      0.7751      1.5044      2.3276      0.0000      0.0433
         120      0.7839      1.5971      2.2854      0.0000      0.0368
         130      0.7872      1.6364      2.2769      0.0000      0.0226
         140      0.7623      1.6198      2.1601      0.0000      0.0314
         150      0.9418      1.5884      2.7023      0.0001      0.4182
         160      0.7356      1.5145      2.1058      0.0137      0.0304
         170      0.7453      1.5600      2.0158      0.0648      0.0212
         180      0.8162      1.4825      2.5000      0.0000      0.0983
         190      0.8363      1.5607      2.4617      0.0627      0.0336
         200      0.8457      1.5537      2.5630      0.0001      0.1115
         210      0.8297      1.5922      2.5202      0.0009      0.0342
         220      0.8417      1.5193      2.6334      0.0000      0.0558
         230      0.8253      1.6419      2.4477      0.0000      0.0367
         240      0.7529      1.5295      2.1861      0.0030      0.0428
         250      0.7683      1.5558      2.2618      0.0000      0.0239
         260      0.8226      1.6361      2.4422      0.0000      0.0345
         270      0.7896      1.6681      2.2396      0.0003      0.0397
         280      0.7468      1.5105      2.1571      0.0186      0.0293
         290      0.7890      1.5872      2.3324      0.0000      0.0254
         300      0.7507      1.4912      2.2167      0.0005      0.0448
         310      0.7878      1.5842      2.3322      0.0000      0.0226
         320      0.7286      1.5260      2.0846      0.0000      0.0323
         330      0.7261      1.4599      2.1399      0.0000      0.0309
         340      0.7833      1.6652      2.2250      0.0004      0.0254
         350      0.7377      1.4561      2.1355      0.0340      0.0291
         360      0.7457      1.5809      2.1008      0.0000      0.0466
         370      0.7374      1.5284      2.1092      0.0059      0.0374
         380      0.7573      1.5519      2.2046      0.0000      0.0298
         390      0.7566      1.5492      2.1868      0.0002      0.0469
         400      0.7909      1.5631      2.3366      0.0000      0.0546
         410      0.7674      1.5349      2.2145      0.0197      0.0482
         420      0.7385      1.5098      2.0984      0.0237      0.0369
         430      0.8154      1.7045      2.3115      0.0001      0.0610
         440      0.7466      1.5525      2.1444      0.0000      0.0360
         450      0.7369      1.5587      2.0851      0.0000      0.0409
         460      0.7149      1.5035      2.0451      0.0018      0.0226
         470      0.7567      1.5429      2.2097      0.0007      0.0296
         480      0.7390      1.4649      2.1599      0.0082      0.0538
         490      0.7199      1.4767      2.0815      0.0002      0.0410
         500      0.7204      1.4486      2.0950      0.0146      0.0293
         510      0.7710      1.6314      2.1610      0.0189      0.0246
         520      0.7480      1.5760      2.1272      0.0000      0.0366
         530      0.7817      1.5821      2.2825      0.0000      0.0439
         540      0.7355      1.5902      2.0718      0.0001      0.0156
         550      0.7537      1.5253      2.2081      0.0001      0.0352
         560      0.7811      1.5377      2.2511      0.0451      0.0264
         570      0.7959      1.6141      2.3344      0.0000      0.0309
         580      0.7772      1.5789      2.2694      0.0000      0.0377
         590      0.9540      1.5771      2.5196      0.3119      0.0495
         600      0.7297      1.4843      2.0912      0.0055      0.0619
       final      0.7017      1.5166      1.9644      0.0007      0.0264
best loss step: 598
Max CUDA memory: 1.2488G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_56: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_56 in 15.71 minutes.

Generating sh3_r1_57, length 82...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      2.7530      1.6736      2.9447      3.0416      3.0635
          10      0.9578      1.6674      2.9739      0.0656      0.0163
          20      0.9280      1.6656      2.9188      0.0183      0.0187
          30      0.9057      1.6514      2.8324      0.0011      0.0424
          40      0.8732      1.5473      2.7748      0.0000      0.0441
          50      0.8797      1.5044      2.8196      0.0000      0.0747
          60      0.9058      1.5407      2.7731      0.0646      0.0860
          70      0.8539      1.5752      2.6561      0.0000      0.0380
          80      1.1009      1.5429      2.7997      0.5697      0.0225
          90      2.4879      1.6278      2.8201      3.9858      0.0201
         100      0.8612      1.5837      2.6832      0.0000      0.0389
         110      0.9740      1.5822      2.6705      0.2903      0.0367
         120      0.8229      1.4898      2.5433      0.0000      0.0814
         130      0.8456      1.5175      2.6404      0.0000      0.0702
         140      0.9004      1.5961      2.6215      0.1142      0.0563
         150      0.8459      1.5258      2.6657      0.0000      0.0379
         160      0.8717      1.5538      2.6855      0.0366      0.0460
         170      0.8037      1.4128      2.4524      0.0475      0.0581
         180      0.7658      1.3835      2.3815      0.0000      0.0639
         190      0.7877      1.3961      2.4619      0.0024      0.0756
         200      0.7452      1.3436      2.3201      0.0000      0.0623
         210      1.4874      1.3877      2.6227      0.0000      3.4266
         220      0.7805      1.3586      2.4907      0.0000      0.0534
         230      0.8433      1.4901      2.6266      0.0000      0.0999
         240      0.8135      1.4247      2.5911      0.0000      0.0518
         250      0.7585      1.3809      2.3565      0.0000      0.0550
         260      0.7843      1.4023      2.4614      0.0013      0.0553
         270      0.8365      1.4446      2.6249      0.0000      0.1128
         280      0.8972      1.4470      2.4242      0.0000      0.6150
         290      0.8584      1.4126      2.5887      0.0000      0.2908
         300      0.7854      1.4144      2.2075      0.0000      0.3051
         310      3.2420      1.5260      2.6028      0.0000     12.0810
         320      0.8331      1.3961      2.4162      0.0000      0.3531
         330      0.8331      1.4110      2.4894      0.0000      0.2652
         340      0.8191      1.4561      2.3099      0.0000      0.3294
         350      0.7834      1.3648      2.2120      0.0001      0.3400
         360      0.7839      1.3374      2.2975      0.0000      0.2846
         370      0.7809      1.3951      2.2048      0.0000      0.3045
         380      0.7693      1.3637      2.1847      0.0001      0.2978
         390      0.7819      1.4335      2.1619      0.0000      0.3139
         400      0.8024      1.4441      2.2561      0.0000      0.3119
         410      0.7847      1.4297      2.1913      0.0000      0.3026
         420      0.7941      1.3504      2.2988      0.0000      0.3212
         430      0.7893      1.3714      2.2894      0.0000      0.2856
         440      0.7715      1.3831      2.1474      0.0000      0.3271
         450      0.7949      1.3427      2.3134      0.0005      0.3173
         460      0.7578      1.2770      2.1927      0.0010      0.3171
         470      0.7572      1.3054      2.1565      0.0000      0.3239
         480      0.8496      1.4394      2.4074      0.0678      0.2657
         490      0.7706      1.3560      2.1849      0.0007      0.3109
         500      0.7456      1.3257      2.0683      0.0000      0.3339
         510      0.7242      1.2288      2.0658      0.0000      0.3262
         520      0.7691      1.3184      2.1818      0.0000      0.3452
         530      0.7493      1.3255      2.0959      0.0001      0.3249
         540      0.7483      1.3105      2.0931      0.0001      0.3376
         550      0.8184      1.4539      2.3379      0.0000      0.3000
         560      0.7803      1.4396      2.1726      0.0000      0.2892
         570      0.7711      1.4431      2.0890      0.0000      0.3234
         580      0.8041      1.5288      2.1879      0.0000      0.3037
         590      0.7708      1.3216      2.1788      0.0000      0.3536
         600      0.7801      1.3440      2.2547      0.0000      0.3019
       final      0.7242      1.2288      2.0658      0.0000      0.3262
best loss step: 510
Max CUDA memory: 1.2370G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_57: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_57 in 15.58 minutes.
