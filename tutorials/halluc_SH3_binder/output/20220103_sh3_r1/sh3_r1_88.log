/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[21:56:23] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 88, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_88, length 68...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      0.9932      1.7482      2.8923      0.0001      0.3255
          10      1.2582      1.6502      2.8025      0.9074      0.0232
          20      1.1287      1.6664      2.7720      0.5950      0.0151
          30      1.1016      1.6305      2.6838      0.5799      0.0338
          40      0.8442      1.5851      2.6095      0.0000      0.0265
          50      0.8323      1.5570      2.5854      0.0000      0.0192
          60      0.7834      1.5521      2.3485      0.0000      0.0164
          70      0.8005      1.5336      2.4570      0.0000      0.0117
          80      0.7536      1.5406      2.2127      0.0000      0.0146
          90      0.9662      1.5925      2.8052      0.1902      0.0529
         100      1.3862      1.6172      2.8963      0.0000      2.4176
         110      0.8771      1.5469      2.8329      0.0000      0.0057
         120      0.8579      1.5373      2.6688      0.0002      0.0831
         130      1.4200      1.5786      2.7700      1.3580      0.0350
         140      0.8519      1.5330      2.7175      0.0000      0.0087
         150      0.8531      1.5424      2.7128      0.0000      0.0105
         160      1.2706      1.5297      2.7135      1.0498      0.0103
         170      0.8744      1.5786      2.7485      0.0156      0.0136
         180      0.8599      1.5647      2.7085      0.0000      0.0263
         190      0.9117      1.6260      2.9285      0.0000      0.0039
         200      0.8430      1.5508      2.6502      0.0000      0.0141
         210      0.8388      1.5842      2.5917      0.0000      0.0180
         220      0.7988      1.5341      2.4376      0.0000      0.0221
         230      0.8628      1.5805      2.7161      0.0006      0.0164
         240      1.5185      1.6434      2.5812      1.3995      0.5690
         250      0.9110      1.7027      2.5993      0.0000      0.2528
         260      1.0868      1.6311      2.6128      0.0000      1.1900
         270      0.8962      1.6493      2.6023      0.0000      0.2293
         280      1.6787      1.6302      2.6044      1.9939      0.1712
         290      1.0549      1.5714      2.4086      0.6097      0.0754
         300      0.8141      1.5432      2.4323      0.0054      0.0844
         310      1.1936      1.5944      2.5286      0.8828      0.0792
         320      0.8459      1.5970      2.5825      0.0000      0.0500
         330      1.7305      1.5785      2.4656      2.2719      0.0648
         340      0.7936      1.5178      2.3943      0.0000      0.0557
         350      0.8217      1.5673      2.4813      0.0000      0.0600
         360      0.8061      1.5943      2.3783      0.0007      0.0565
         370      1.6484      1.5270      2.5884      2.0390      0.0485
         380      0.8915      1.5993      2.6476      0.0647      0.0813
         390      0.8305      1.5768      2.5156      0.0000      0.0600
         400      0.9087      1.5527      2.1921      0.2519      0.2950
         410      0.8576      1.5091      2.2121      0.2043      0.1582
         420      0.8874      1.5853      2.4651      0.1521      0.0826
         430      0.8728      1.5746      2.7128      0.0000      0.0769
         440      0.8007      1.5347      2.3932      0.0000      0.0758
         450      0.8053      1.5475      2.4197      0.0014      0.0567
         460      0.8071      1.5842      2.3865      0.0000      0.0650
         470      1.2980      1.5323      2.3220      1.0990      0.4377
         480      0.8078      1.4811      2.2109      0.0018      0.3433
         490      0.8117      1.4964      2.2247      0.1318      0.0740
         500      0.8222      1.5527      2.4868      0.0000      0.0715
         510      0.7646      1.5031      2.2711      0.0001      0.0487
         520      0.9299      1.5635      2.1120      0.4644      0.0454
         530      0.7981      1.4851      2.1158      0.1214      0.1471
         540      0.7750      1.5262      2.1194      0.0022      0.2253
         550      0.7467      1.5555      2.1311      0.0001      0.0464
         560      0.7569      1.5401      2.1977      0.0000      0.0464
         570      0.8147      1.4854      2.1461      0.1254      0.1909
         580      0.7639      1.5641      2.1579      0.0261      0.0453
         590      0.7756      1.5269      2.2864      0.0001      0.0644
         600      0.9810      1.5105      2.2022      0.5759      0.0405
       final      0.7235      1.5089      2.0538      0.0000      0.0551
best loss step: 561
Max CUDA memory: 0.9298G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_88: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_88 in 14.29 minutes.

Generating sh3_r1_89, length 91...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      2.1191      1.6750      2.9705      1.7751      2.3998
          10      1.9625      1.9186      2.8370      0.0092      5.0383
          20      0.9304      1.6869      2.7553      0.0000      0.2100
          30      0.9546      1.7900      2.8247      0.0551      0.0479
          40      0.9958      1.6488      2.8800      0.0511      0.3480
          50      1.4320      1.6155      2.7282      1.3761      0.0642
          60      0.9502      1.5496      2.6049      0.2536      0.0895
          70      0.8435      1.7052      2.4813      0.0000      0.0311
          80      0.8774      1.6385      2.6686      0.0000      0.0800
          90      1.9418      1.7512      2.7500      2.5946      0.0188
         100      0.8431      1.5707      2.5669      0.0000      0.0778
         110      0.7718      1.4145      2.3879      0.0000      0.0567
         120      0.8366      1.4673      2.3363      0.1695      0.0404
         130      0.7906      1.5069      2.4103      0.0000      0.0360
         140      0.7685      1.4632      2.3269      0.0000      0.0525
         150      0.7554      1.4068      2.3028      0.0002      0.0670
         160      1.0957      1.4295      2.4296      0.0000      1.6195
         170      0.7974      1.5020      2.4248      0.0000      0.0602
         180      0.7828      1.4415      2.3494      0.0413      0.0407
         190      0.7725      1.4815      2.2953      0.0000      0.0855
         200      0.7952      1.5141      2.4132      0.0000      0.0485
         210      1.0707      1.4940      2.4594      0.0000      1.4002
         220      0.8042      1.4407      2.4408      0.0000      0.1397
         230      0.7638      1.3962      2.3303      0.0000      0.0926
         240      0.7998      1.5164      2.4107      0.0000      0.0721
         250      0.7508      1.4219      2.2699      0.0000      0.0624
         260      0.7967      1.4134      2.4621      0.0264      0.0550
         270      0.9443      1.6344      2.6177      0.1195      0.2304
         280      1.1828      1.5689      2.4793      0.9155      0.0351
         290      0.7801      1.5033      2.3512      0.0000      0.0459
         300      0.7812      1.4906      2.3713      0.0015      0.0411
         310      0.7726      1.4069      2.3782      0.0000      0.0777
         320      0.7725      1.4214      2.3848      0.0000      0.0564
         330      0.7578      1.3743      2.3402      0.0043      0.0656
         340      0.7796      1.3739      2.3838      0.0482      0.0437
         350      0.7676      1.4014      2.3816      0.0035      0.0482
         360      0.8006      1.4168      2.5430      0.0056      0.0322
         370      0.8041      1.4851      2.4986      0.0000      0.0368
         380      0.7745      1.4234      2.3938      0.0000      0.0553
         390      0.7676      1.4588      2.3316      0.0000      0.0476
         400      0.7760      1.4256      2.4076      0.0001      0.0467
         410      0.7801      1.4357      2.4120      0.0000      0.0528
         420      1.3446      1.4792      2.5474      1.3344      0.0274
         430      0.7609      1.4669      2.2825      0.0000      0.0548
         440      0.7610      1.3977      2.3587      0.0001      0.0483
         450      0.8294      1.5126      2.5029      0.0011      0.1291
         460      0.8159      1.4142      2.5981      0.0038      0.0594
         470      0.8382      1.4082      2.1960      0.2477      0.0913
         480      0.7481      1.3982      2.2569      0.0004      0.0844
         490      0.7968      1.4510      2.4891      0.0003      0.0430
         500      0.7891      1.4535      2.4407      0.0000      0.0515
         510      0.7334      1.3875      2.2273      0.0011      0.0502
         520      0.7608      1.3786      2.3809      0.0000      0.0447
         530      0.7795      1.4148      2.4357      0.0006      0.0458
         540      0.7937      1.5989      2.3323      0.0000      0.0374
         550      0.7640      1.4599      2.2916      0.0000      0.0688
         560      0.8293      1.5546      2.5449      0.0001      0.0469
         570      0.7841      1.5188      2.3393      0.0001      0.0621
         580      0.8029      1.4650      2.5071      0.0004      0.0417
         590      0.7666      1.4728      2.3088      0.0000      0.0513
         600      0.7691      1.4685      2.3176      0.0000      0.0593
       final      0.7226      1.3450      2.2007      0.0000      0.0672
best loss step: 599
Max CUDA memory: 1.4603G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_89: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_89 in 15.69 minutes.
