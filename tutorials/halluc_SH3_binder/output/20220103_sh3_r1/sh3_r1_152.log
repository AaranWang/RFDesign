/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[23:33:50] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 152, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_152, length 90...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.1372      1.7365      2.9438      0.0000      1.0058
          10      0.8439      1.5794      2.5556      0.0000      0.0846
          20      0.7573      1.4840      2.2575      0.0000      0.0447
          30      0.7885      1.5655      2.3067      0.0112      0.0477
          40      0.8095      1.5604      2.4273      0.0000      0.0597
          50      0.7336      1.4399      2.1706      0.0000      0.0576
          60      0.7258      1.4576      2.1310      0.0003      0.0397
          70      0.7572      1.5820      2.1642      0.0000      0.0400
          80      0.7312      1.6084      2.0031      0.0000      0.0444
          90      0.7491      1.4861      2.2118      0.0001      0.0475
         100      0.7809      1.5220      2.3258      0.0000      0.0565
         110      0.7435      1.4912      2.1871      0.0000      0.0390
         120      0.8031      1.6473      2.3338      0.0005      0.0336
         130      0.7193      1.4489      2.1026      0.0000      0.0452
         140      0.7756      1.5124      2.3319      0.0000      0.0337
         150      0.7361      1.5350      2.1082      0.0005      0.0363
         160      0.7381      1.4529      2.1917      0.0000      0.0455
         170      0.7296      1.4818      2.1174      0.0000      0.0487
         180      0.7789      1.5336      2.3117      0.0000      0.0493
         190      0.7377      1.4561      2.1936      0.0000      0.0385
         200      1.0375      1.5317      2.5127      0.5472      0.0490
         210      0.7640      1.4576      2.3039      0.0001      0.0583
         220      0.7371      1.5681      2.0821      0.0001      0.0353
         230      0.7554      1.5017      2.2287      0.0000      0.0464
         240      0.7653      1.4882      2.2938      0.0001      0.0444
         250      0.7306      1.5278      2.0871      0.0002      0.0378
         260      0.7278      1.4753      2.1249      0.0000      0.0387
         270      0.7325      1.5177      2.1060      0.0000      0.0387
         280      0.7345      1.5368      2.0971      0.0000      0.0385
         290      0.7985      1.6842      2.2782      0.0000      0.0300
         300      0.7090      1.4850      2.0268      0.0000      0.0332
         310      0.7851      1.5622      1.9724      0.1765      0.0379
         320      1.1622      1.5088      2.2579      0.0000      2.0442
         330      0.7164      1.5223      2.0206      0.0000      0.0391
         340      0.7365      1.5391      2.0917      0.0002      0.0512
         350      0.7389      1.4932      2.1576      0.0000      0.0438
         360      0.7887      1.6613      2.2334      0.0001      0.0485
         370      0.7380      1.4737      2.1023      0.0352      0.0435
         380      0.7417      1.5286      2.1340      0.0000      0.0457
         390      0.7439      1.4778      2.1689      0.0165      0.0398
         400      0.7476      1.5134      2.1750      0.0000      0.0495
         410      0.7008      1.4060      2.0582      0.0000      0.0398
         420      0.7457      1.5137      2.1717      0.0001      0.0432
         430      0.7162      1.4759      2.0706      0.0000      0.0347
         440      0.7530      1.5223      2.1984      0.0000      0.0441
         450      0.7272      1.4763      2.1148      0.0000      0.0449
         460      0.7465      1.5223      2.1726      0.0000      0.0378
         470      0.7523      1.5115      2.2017      0.0000      0.0481
         480      0.7411      1.5482      2.1178      0.0001      0.0396
         490      0.7310      1.4991      2.1196      0.0000      0.0363
         500      0.7483      1.4713      2.2194      0.0000      0.0507
         510      0.7193      1.4706      2.0785      0.0000      0.0476
         520      0.7763      1.6322      2.2081      0.0000      0.0409
         530      0.7982      1.7104      2.2470      0.0001      0.0335
         540      0.7025      1.4485      2.0287      0.0000      0.0353
         550      0.7472      1.5091      2.1810      0.0000      0.0462
         560      0.7582      1.6119      2.1385      0.0001      0.0406
         570      0.7314      1.5388      2.0795      0.0000      0.0384
         580      0.7441      1.5391      2.1326      0.0000      0.0488
         590      0.7747      1.5540      2.2825      0.0000      0.0367
         600      0.7324      1.4799      2.1257      0.0002      0.0559
       final      0.6814      1.4126      1.9550      0.0001      0.0393
best loss step: 546
Max CUDA memory: 1.4333G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_152: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_152 in 14.99 minutes.

Generating sh3_r1_153, length 70...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.1329      1.7151      2.9643      0.4875      0.0100
          10      1.1285      1.6240      2.8926      0.5474      0.0313
          20      0.8820      1.5107      2.8545      0.0000      0.0448
          30      1.2657      1.5440      2.8297      0.9697      0.0154
          40      0.8586      1.5317      2.7127      0.0000      0.0485
          50      1.0374      1.5099      2.6880      0.4676      0.0541
          60      0.9893      1.4432      2.7294      0.3422      0.0894
          70      1.1706      1.5694      2.7187      0.7660      0.0331
          80      0.9015      1.5112      2.6697      0.1442      0.0380
          90      0.8490      1.5623      2.6581      0.0000      0.0245
         100      2.0267      1.4975      2.7706      0.0000      5.8652
         110      0.8421      1.5531      2.6154      0.0000      0.0420
         120      0.8624      1.5722      2.7135      0.0000      0.0261
         130      0.8388      1.5213      2.6464      0.0000      0.0265
         140      0.7704      1.5033      2.3106      0.0000      0.0379
         150      0.7703      1.4945      2.3301      0.0000      0.0270
         160      0.8801      1.5715      2.5122      0.1425      0.0320
         170      0.8454      1.5942      2.6132      0.0000      0.0194
         180      1.8582      1.5337      2.5571      0.0000      5.2004
         190      0.7840      1.4544      2.4430      0.0000      0.0225
         200      0.8132      1.5114      2.5103      0.0000      0.0444
         210      0.8061      1.4914      2.4903      0.0000      0.0489
         220      0.8177      1.4969      2.5287      0.0000      0.0626
         230      0.8032      1.4568      2.5022      0.0000      0.0570
         240      0.8682      1.4979      2.3715      0.2185      0.0344
         250      0.8342      1.5222      2.6293      0.0000      0.0193
         260      0.9246      1.5050      2.6583      0.0000      0.4599
         270      0.8577      1.5448      2.6253      0.0412      0.0358
         280      0.9944      1.4481      2.5911      0.4480      0.0371
         290      0.9414      1.4745      2.6268      0.3016      0.0026
         300      0.7868      1.5091      2.4079      0.0000      0.0171
         310      0.8437      1.5250      2.6614      0.0020      0.0281
         320      0.9898      1.5917      2.6432      0.0000      0.7138
         330      1.3384      1.4654      2.6159      1.2970      0.0167
         340      1.0067      1.4559      2.4894      0.5357      0.0169
         350      0.7992      1.4841      2.4601      0.0137      0.0245
         360      0.8144      1.4946      2.5372      0.0000      0.0402
         370      2.2308      1.5307      2.6067      0.0000      7.0166
         380      0.8255      1.4798      2.6162      0.0000      0.0314
         390      0.9021      1.5307      2.8073      0.0811      0.0103
         400      0.9774      1.5678      2.7813      0.2651      0.0078
         410      1.7038      1.5379      2.7284      0.0000      4.2527
         420      0.9048      1.5002      2.5268      0.0000      0.4967
         430      0.8581      1.6027      2.6336      0.0000      0.0545
         440      0.9494      1.5044      2.6489      0.0000      0.5940
         450      0.8092      1.4921      2.5066      0.0000      0.0475
         460      0.8695      1.5412      2.7586      0.0000      0.0476
         470      0.8033      1.4567      2.5046      0.0000      0.0550
         480      0.8369      1.5025      2.6201      0.0000      0.0619
         490      0.8108      1.5158      2.4181      0.0000      0.1203
         500      0.7785      1.4572      2.3573      0.0000      0.0781
         510      0.7964      1.4611      2.4379      0.0000      0.0830
         520      0.7423      1.4274      2.1988      0.0004      0.0844
         530      0.7636      1.4579      2.2759      0.0000      0.0842
         540      0.7346      1.4177      2.1844      0.0000      0.0710
         550      0.7463      1.4727      2.1823      0.0000      0.0766
         560      0.7132      1.3697      2.1097      0.0000      0.0865
         570      0.7242      1.4255      2.1111      0.0028      0.0787
         580      0.7258      1.4130      2.1370      0.0000      0.0792
         590      0.7089      1.3115      2.1340      0.0016      0.0961
         600      0.7352      1.4097      2.1688      0.0000      0.0976
       final      0.6989      1.3647      2.0410      0.0017      0.0855
best loss step: 585
Max CUDA memory: 0.9685G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_153: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_153 in 13.67 minutes.
