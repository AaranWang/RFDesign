/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[21:19:28] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 60, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_60, length 63...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.5694      1.6692      2.9665      0.0000      3.2110
          10      2.1837      1.9382      2.7651      3.0887      0.0379
          20      0.9754      1.7683      2.7087      0.1837      0.0328
          30      0.9020      1.6365      2.8181      0.0001      0.0553
          40      0.9386      1.6592      2.8390      0.0015      0.1920
          50      0.9230      1.7494      2.8245      0.0000      0.0411
          60      1.2003      1.5952      2.7436      0.4146      0.8335
          70      1.6218      1.6594      2.6945      0.0002      3.7549
          80      1.4872      1.7176      2.7274      1.4749      0.0415
          90      1.2474      1.6164      2.6708      0.0000      1.9497
         100      0.9525      1.6956      2.7618      0.0000      0.3048
         110      0.8779      1.6133      2.7290      0.0027      0.0417
         120      0.8808      1.6663      2.6777      0.0235      0.0132
         130      0.8821      1.6591      2.6627      0.0152      0.0583
         140      1.2188      1.5704      2.7211      0.8102      0.1818
         150      0.8783      1.6875      2.6829      0.0000      0.0208
         160      0.8696      1.6342      2.6760      0.0000      0.0379
         170      0.8741      1.5561      2.7405      0.0001      0.0737
         180      0.8795      1.5869      2.7759      0.0010      0.0328
         190      0.8620      1.5636      2.7127      0.0040      0.0259
         200      1.0379      1.6279      2.6628      0.0005      0.8982
         210      0.8451      1.6246      2.5778      0.0000      0.0233
         220      0.8555      1.6957      2.5313      0.0135      0.0234
         230      1.3568      1.6248      2.4385      1.3506      0.0197
         240      0.8537      1.6256      2.5807      0.0004      0.0616
         250      0.8261      1.6010      2.4837      0.0000      0.0456
         260      0.8279      1.7283      2.3854      0.0001      0.0253
         270      0.8111      1.5991      2.4196      0.0000      0.0371
         280      0.8138      1.5926      2.4437      0.0000      0.0326
         290      0.8101      1.5449      2.4655      0.0000      0.0401
         300      1.2109      1.5411      2.6470      0.0000      1.8665
         310      0.8490      1.6522      2.5693      0.0000      0.0233
         320      1.0497      1.5491      2.4114      0.6285      0.0310
         330      0.8341      1.6013      2.5149      0.0000      0.0544
         340      1.0148      1.6453      2.4301      0.4904      0.0178
         350      0.8178      1.6438      2.4204      0.0008      0.0232
         360      0.8307      1.5323      2.5219      0.0266      0.0462
         370      0.8522      1.6380      2.5866      0.0000      0.0364
         380      0.8727      1.5555      2.6521      0.0128      0.1304
         390      0.8254      1.6385      2.4331      0.0037      0.0482
         400      0.8397      1.6271      2.4786      0.0363      0.0201
         410      0.8903      1.6795      2.5887      0.0779      0.0276
         420      0.8021      1.5687      2.2774      0.0724      0.0194
         430      1.5963      1.6274      2.5581      0.0000      3.7958
         440      0.9249      1.6395      2.5581      0.2049      0.0171
         450      0.7905      1.6164      2.2984      0.0000      0.0378
         460      0.8241      1.6235      2.4633      0.0017      0.0303
         470      0.9004      1.5376      2.5607      0.1842      0.0350
         480      0.8527      1.6565      2.5792      0.0036      0.0208
         490      0.8329      1.7192      2.3896      0.0118      0.0323
         500      1.1718      1.5904      2.2740      0.9459      0.1030
         510      0.7900      1.6033      2.2997      0.0000      0.0471
         520      0.8043      1.6576      2.3383      0.0000      0.0255
         530      0.7988      1.6455      2.3096      0.0000      0.0389
         540      0.8067      1.5823      2.4080      0.0000      0.0430
         550      0.8009      1.6096      2.3743      0.0000      0.0206
         560      0.8154      1.6446      2.3815      0.0000      0.0509
         570      0.8262      1.6031      2.4267      0.0000      0.1013
         580      0.9225      1.5544      2.2223      0.3959      0.0440
         590      0.8167      1.6151      2.4440      0.0017      0.0211
         600      0.8024      1.6224      2.3597      0.0000      0.0298
       final      0.7619      1.5278      2.2370      0.0000      0.0448
best loss step: 583
Max CUDA memory: 0.8328G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_60: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_60 in 13.52 minutes.

Generating sh3_r1_61, length 78...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      0.9665      1.8597      2.9618      0.0009      0.0092
          10      1.7182      1.6377      2.8495      1.6772      0.7493
          20      1.4355      1.6825      2.9156      1.2796      0.0201
          30      0.8975      1.6597      2.8199      0.0003      0.0074
          40      1.1081      1.5799      2.7691      0.5715      0.0486
          50      0.8460      1.4612      2.7114      0.0228      0.0117
          60      0.9858      1.4986      2.5529      0.4283      0.0212
          70      0.8692      1.5802      2.7310      0.0000      0.0344
          80      0.8575      1.5052      2.7062      0.0041      0.0682
          90      0.9022      1.5002      2.7892      0.1042      0.0134
         100      0.8812      1.5624      2.7760      0.0241      0.0192
         110      1.6887      1.5857      2.8199      2.0078      0.0226
         120      1.1324      1.5724      2.6477      0.7119      0.0179
         130      0.9385      1.5487      2.4956      0.3193      0.0098
         140      0.7795      1.5611      2.3238      0.0001      0.0126
         150      0.7657      1.4822      2.3335      0.0000      0.0127
         160      0.8146      1.5536      2.5105      0.0003      0.0084
         170      0.7091      1.4998      2.0331      0.0003      0.0119
         180      1.4147      1.5666      2.5079      0.0000      2.9987
         190      1.2412      1.5026      2.5001      0.1061      1.9911
         200      1.2131      1.5062      2.5706      0.0000      1.9886
         210      1.7142      1.5236      2.4754      0.0265      4.5191
         220      1.8869      1.4965      2.3854      0.5099      4.5327
         230      1.2606      1.5110      2.4928      0.0000      2.2992
         240      0.8778      1.5444      2.5658      0.0000      0.2788
         250      0.8357      1.5688      2.4652      0.0001      0.1446
         260      0.8615      1.5814      2.5501      0.0000      0.1760
         270      0.8672      1.5912      2.6634      0.0001      0.0814
         280      0.8738      1.5667      2.6069      0.0497      0.0958
         290      1.0562      1.5541      2.6289      0.5261      0.0459
         300      0.8278      1.5598      2.4901      0.0001      0.0888
         310      0.8401      1.5385      2.5550      0.0192      0.0685
         320      0.8291      1.5764      2.5279      0.0018      0.0377
         330      0.8747      1.5926      2.3319      0.1980      0.0529
         340      0.7850      1.5242      2.3691      0.0000      0.0317
         350      0.7482      1.5444      2.1582      0.0018      0.0346
         360      0.7442      1.5341      2.1384      0.0000      0.0484
         370      0.7228      1.4537      2.1236      0.0000      0.0365
         380      0.8475      1.6059      2.4936      0.0599      0.0183
         390      0.7373      1.4672      2.1872      0.0000      0.0322
         400      0.7113      1.5061      2.0214      0.0000      0.0292
         410      0.7187      1.4388      2.1196      0.0000      0.0353
         420      0.7548      1.5047      2.2331      0.0080      0.0203
         430      0.7033      1.4175      2.0500      0.0000      0.0492
         440      0.7736      1.5892      2.2428      0.0000      0.0360
         450      0.7192      1.4436      2.1192      0.0000      0.0331
         460      0.7557      1.4814      2.2537      0.0000      0.0431
         470      0.7207      1.4410      2.1274      0.0000      0.0350
         480      0.7046      1.4426      2.0474      0.0000      0.0328
         490      0.7043      1.4270      2.0474      0.0000      0.0470
         500      0.6900      1.4021      2.0099      0.0000      0.0381
         510      0.7494      1.4825      2.2259      0.0000      0.0388
         520      0.7231      1.4628      2.1151      0.0006      0.0363
         530      0.7047      1.4357      2.0311      0.0000      0.0567
         540      0.6990      1.4272      2.0286      0.0000      0.0390
         550      0.7661      1.4305      2.3682      0.0000      0.0318
         560      0.6855      1.4545      1.9335      0.0000      0.0396
         570      0.6995      1.4563      2.0013      0.0000      0.0399
         580      1.8808      1.4335      2.5131      0.0000      5.4575
         590      0.8258      1.6167      2.3857      0.0000      0.1268
         600      0.7206      1.5025      2.0385      0.0000      0.0618
       final      0.6796      1.3902      1.9746      0.0000      0.0330
best loss step: 471
Max CUDA memory: 1.1384G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_61: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_61 in 13.92 minutes.
