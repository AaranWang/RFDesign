/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[22:45:43] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 122, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_122, length 69...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.1692      1.6329      2.7948      0.0000      1.4181
          10      1.2129      1.7641      2.9250      0.6788      0.0179
          20      1.0797      1.6835      2.8188      0.2457      0.4046
          30      0.8848      1.6707      2.7209      0.0000      0.0323
          40      0.8865      1.6382      2.7817      0.0002      0.0123
          50      0.8950      1.5737      2.6596      0.0009      0.2400
          60      0.8581      1.6634      2.6172      0.0000      0.0098
          70      1.1829      1.6196      2.5144      0.8854      0.0097
          80      0.8207      1.6164      2.3868      0.0426      0.0150
          90      0.7730      1.5134      2.3289      0.0000      0.0225
         100      0.7824      1.4565      2.4200      0.0036      0.0280
         110      0.7820      1.4870      2.3578      0.0000      0.0653
         120      0.8227      1.5495      2.3731      0.0005      0.1900
         130      0.7665      1.4692      2.2089      0.0704      0.0134
         140      0.7776      1.5158      2.3518      0.0000      0.0206
         150      0.8253      1.5964      2.4003      0.0358      0.0580
         160      0.9870      1.5168      2.2600      0.5689      0.0205
         170      1.1928      1.5669      2.3777      0.9979      0.0233
         180      0.7478      1.5492      2.1762      0.0000      0.0137
         190      0.7529      1.5211      2.2286      0.0000      0.0150
         200      0.7399      1.5399      2.1060      0.0175      0.0186
         210      0.7916      1.5137      2.4166      0.0000      0.0276
         220      0.7632      1.6392      2.1510      0.0013      0.0232
         230      0.8298      1.6873      2.4266      0.0001      0.0350
         240      0.7771      1.6011      2.2583      0.0000      0.0259
         250      1.2635      1.5686      2.2445      1.2479      0.0087
         260      0.7121      1.4017      1.9920      0.0723      0.0223
         270      0.6837      1.3293      2.0316      0.0183      0.0211
         280      0.8033      1.3936      2.1910      0.2090      0.0139
         290      0.8287      1.6449      2.4874      0.0000      0.0112
         300      0.7017      1.4269      2.0540      0.0059      0.0157
         310      0.7225      1.5393      2.0126      0.0182      0.0243
         320      0.7117      1.4901      2.0469      0.0000      0.0216
         330      0.8959      1.6603      2.3729      0.2188      0.0086
         340      0.7906      1.5715      2.0432      0.1626      0.0133
         350      0.6904      1.4348      1.9972      0.0000      0.0199
         360      0.7551      1.5469      2.2171      0.0000      0.0114
         370      0.7319      1.5035      2.1467      0.0000      0.0095
         380      0.8110      1.5528      2.4590      0.0126      0.0180
         390      0.7285      1.4006      2.1643      0.0336      0.0103
         400      0.6941      1.4706      1.9887      0.0000      0.0114
         410      0.7418      1.3571      2.2068      0.0513      0.0427
         420      1.1324      1.4969      2.2093      0.9720      0.0115
         430      0.6817      1.4361      1.9542      0.0024      0.0133
         440      0.9486      1.4458      2.4611      0.4128      0.0103
         450      0.7758      1.5537      2.3069      0.0004      0.0178
         460      0.7468      1.4893      2.2281      0.0000      0.0163
         470      0.7674      1.5163      2.2563      0.0000      0.0644
         480      0.8027      1.7469      2.2365      0.0000      0.0301
         490      1.2501      1.5770      1.8443      1.4107      0.0080
         500      0.8684      1.6042      2.5220      0.0000      0.2159
         510      0.7558      1.5243      2.2360      0.0000      0.0188
         520      0.8117      1.5338      2.4102      0.0498      0.0147
         530      1.0965      1.5526      2.4996      0.5223      0.3858
         540      0.8481      1.5754      2.5984      0.0000      0.0666
         550      0.7415      1.6134      2.0838      0.0000      0.0104
         560      0.7936      1.5939      2.3034      0.0000      0.0705
         570      0.7377      1.5353      2.1398      0.0000      0.0133
         580      0.7411      1.4998      2.0099      0.0921      0.0115
         590      0.7656      1.4944      2.1538      0.0824      0.0151
         600      0.8325      1.7960      2.3560      0.0000      0.0102
       final      0.6681      1.4429      1.8835      0.0001      0.0139
best loss step: 503
Max CUDA memory: 0.9441G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_122: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_122 in 13.72 minutes.

Generating sh3_r1_123, length 72...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.7413      1.8431      2.9343      1.8276      0.2738
          10      1.8353      1.6361      2.9086      0.7536      3.1245
          20      2.5197      1.5558      2.8717      4.0744      0.0224
          30      1.4905      1.5319      2.8880      1.5036      0.0254
          40      1.0333      1.4736      2.9171      0.3545      0.0668
          50      1.0352      1.4722      2.8289      0.4225      0.0298
          60      0.8936      1.6005      2.8442      0.0003      0.0227
          70      1.3706      1.4713      2.7244      1.3241      0.0089
          80      0.7759      1.4603      2.3706      0.0000      0.0483
          90      0.8706      1.5449      2.6240      0.0000      0.1842
         100      0.8169      1.5325      2.5140      0.0000      0.0379
         110      0.7549      1.4806      2.2561      0.0000      0.0380
         120      0.8023      1.5010      2.4360      0.0000      0.0746
         130      0.7438      1.4793      2.1915      0.0000      0.0481
         140      0.7734      1.4881      2.3500      0.0000      0.0286
         150      0.7936      1.4846      2.4492      0.0000      0.0344
         160      0.7106      1.4125      2.0986      0.0013      0.0395
         170      0.7395      1.4015      2.2254      0.0000      0.0707
         180      0.9128      1.5758      2.1904      0.3915      0.0147
         190      0.7406      1.4812      2.1955      0.0000      0.0264
         200      0.7575      1.4452      2.3062      0.0000      0.0358
         210      0.7608      1.4388      2.3421      0.0000      0.0232
         220      0.7283      1.4390      2.1709      0.0000      0.0315
         230      0.8401      1.5599      2.3062      0.0928      0.1488
         240      0.7351      1.4289      2.2230      0.0000      0.0236
         250      0.7677      1.5002      2.2994      0.0000      0.0387
         260      0.7656      1.4392      2.3448      0.0000      0.0439
         270      0.7435      1.4578      2.2263      0.0000      0.0332
         280      0.7634      1.5077      2.2626      0.0011      0.0443
         290      0.7529      1.4927      2.2461      0.0000      0.0254
         300      0.7326      1.4568      2.1732      0.0000      0.0329
         310      0.7226      1.4348      2.1412      0.0000      0.0370
         320      0.7598      1.5002      2.2740      0.0000      0.0247
         330      0.7405      1.5049      2.1645      0.0000      0.0330
         340      0.7437      1.4816      2.2064      0.0000      0.0304
         350      0.7387      1.4518      2.2059      0.0001      0.0357
         360      0.7461      1.5036      2.1944      0.0010      0.0305
         370      0.7842      1.4650      2.3145      0.0000      0.1415
         380      0.7479      1.4013      2.3111      0.0000      0.0270
         390      0.7115      1.4099      2.1268      0.0003      0.0205
         400      0.7538      1.4950      2.2507      0.0000      0.0234
         410      0.7778      1.4781      2.3782      0.0000      0.0326
         420      0.7196      1.3680      2.1868      0.0049      0.0334
         430      0.8276      1.5176      2.2802      0.1584      0.0233
         440      0.7218      1.4262      2.1557      0.0000      0.0270
         450      0.7061      1.4006      2.1062      0.0004      0.0228
         460      0.7488      1.4107      2.3082      0.0000      0.0251
         470      0.7877      1.4065      2.1410      0.1842      0.0225
         480      0.8195      1.4569      2.3655      0.1157      0.0436
         490      1.0561      1.4855      2.2712      0.6758      0.1721
         500      0.7737      1.4238      2.3171      0.0000      0.1278
         510      0.7753      1.4210      2.2951      0.0000      0.1602
         520      0.7966      1.4686      2.3791      0.0000      0.1353
         530      0.7733      1.4373      2.2983      0.0000      0.1309
         540      0.7927      1.5093      2.3254      0.0000      0.1287
         550      0.7606      1.4599      2.1970      0.0000      0.1459
         560      0.7513      1.4022      2.2052      0.0000      0.1489
         570      0.7371      1.3972      2.1676      0.0000      0.1208
         580      0.7821      1.4374      2.2855      0.0000      0.1875
         590      0.7839      1.4978      2.2658      0.0000      0.1561
         600      0.7578      1.4085      2.2299      0.0000      0.1503
       final      0.6899      1.3442      2.0714      0.0000      0.0338
best loss step: 358
Max CUDA memory: 1.0046G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_123: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_123 in 13.86 minutes.
