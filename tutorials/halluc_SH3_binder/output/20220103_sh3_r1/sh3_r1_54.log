/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[20:59:27] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 54, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_54, length 73...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      0.9593      1.7764      2.9641      0.0197      0.0168
          10      0.9078      1.6992      2.7258      0.0017      0.1107
          20      0.9089      1.7395      2.7675      0.0000      0.0376
          30      0.8828      1.6176      2.7726      0.0003      0.0230
          40      0.8549      1.5892      2.6646      0.0040      0.0129
          50      0.7821      1.4495      2.4079      0.0000      0.0532
          60      0.7436      1.3555      2.1215      0.0725      0.0957
          70      0.7662      1.4247      2.3154      0.0000      0.0911
          80      0.7202      1.3182      2.1863      0.0075      0.0814
          90      0.7309      1.3567      2.2216      0.0000      0.0761
         100      0.7893      1.4180      2.4341      0.0001      0.0943
         110      0.7237      1.4446      2.0881      0.0000      0.0859
         120      0.7192      1.3104      2.2060      0.0003      0.0789
         130      0.8544      1.5537      2.5831      0.0043      0.1264
         140      0.8328      1.4617      2.4514      0.0824      0.0858
         150      0.7635      1.3547      2.1827      0.0875      0.1051
         160      0.7307      1.4338      2.1354      0.0000      0.0846
         170      0.7561      1.3971      2.1849      0.0637      0.0713
         180      0.7543      1.4317      2.2700      0.0000      0.0698
         190      0.7612      1.4474      2.2843      0.0000      0.0743
         200      0.8091      1.4610      2.4433      0.0003      0.1408
         210      0.7404      1.4302      2.2034      0.0001      0.0681
         220      0.7103      1.3889      2.0784      0.0000      0.0844
         230      0.7899      1.4121      2.1831      0.1437      0.0668
         240      0.7269      1.3526      2.2071      0.0000      0.0748
         250      0.8055      1.6764      2.2845      0.0000      0.0665
         260      0.7801      1.4422      2.3538      0.0007      0.1032
         270      0.8143      1.4473      2.3208      0.1085      0.0863
         280      0.7871      1.5287      2.3426      0.0000      0.0642
         290      0.7319      1.4481      2.1390      0.0000      0.0726
         300      0.7728      1.3798      2.2636      0.0751      0.0702
         310      0.7399      1.3661      2.2434      0.0000      0.0899
         320      0.7629      1.4822      2.2008      0.0249      0.0820
         330      0.7597      1.4798      2.2322      0.0000      0.0863
         340      0.7496      1.5054      2.1529      0.0000      0.0897
         350      0.7482      1.4495      2.0590      0.0758      0.0809
         360      0.7458      1.5043      2.1418      0.0032      0.0765
         370      1.5328      1.5200      2.2691      0.0001      3.8750
         380      0.7679      1.4740      2.3001      0.0002      0.0651
         390      0.7178      1.4607      2.0505      0.0005      0.0768
         400      0.7429      1.5016      2.1321      0.0053      0.0699
         410      0.7356      1.5076      2.0898      0.0000      0.0808
         420      0.9514      1.4074      2.2858      0.5007      0.0623
         430      0.7046      1.3850      2.0598      0.0012      0.0756
         440      0.6984      1.3789      2.0373      0.0000      0.0755
         450      0.7455      1.4556      2.1914      0.0000      0.0804
         460      0.7194      1.3826      2.0775      0.0322      0.0725
         470      0.7620      1.4123      2.1809      0.0638      0.0892
         480      0.7022      1.4390      1.9927      0.0000      0.0795
         490      0.7322      1.4273      2.1570      0.0000      0.0769
         500      0.7283      1.4602      2.0948      0.0000      0.0866
         510      0.7612      1.4288      2.2632      0.0231      0.0677
         520      0.8689      1.6185      2.2002      0.2267      0.0724
         530      0.7346      1.4341      2.1646      0.0000      0.0743
         540      0.7007      1.4000      2.0172      0.0000      0.0862
         550      0.7293      1.4932      2.0585      0.0000      0.0948
         560      0.7237      1.3993      2.1288      0.0000      0.0905
         570      0.7228      1.3833      2.1565      0.0001      0.0742
         580      0.7487      1.5710      2.0889      0.0000      0.0839
         590      0.7353      1.4731      2.1199      0.0000      0.0837
         600      0.9826      1.5334      2.5753      0.0091      0.7858
       final      0.6770      1.2857      2.0227      0.0001      0.0766
best loss step: 244
Max CUDA memory: 1.0327G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_54: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_54 in 15.44 minutes.

Generating sh3_r1_55, length 81...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.2520      1.7194      2.9679      0.7739      0.0249
          10      0.8430      1.5929      2.5681      0.0000      0.0542
          20      0.8131      1.5866      2.3830      0.0000      0.0956
          30      0.7982      1.5743      2.3904      0.0000      0.0265
          40      0.8041      1.5820      2.4118      0.0000      0.0265
          50      1.0150      1.5485      2.4020      0.0000      1.1247
          60      0.7594      1.4831      2.1966      0.0466      0.0241
          70      0.7475      1.5487      2.1570      0.0001      0.0317
          80      1.1368      1.5144      2.4475      0.0000      1.7219
          90      0.7713      1.5299      2.1667      0.0000      0.1602
         100      1.1411      1.4987      2.4788      0.7186      0.2909
         110      0.8666      1.5189      2.4513      0.1358      0.0913
         120      0.8318      1.5927      2.5176      0.0000      0.0485
         130      0.7788      1.5267      2.3028      0.0000      0.0644
         140      0.9266      1.5032      2.3659      0.0080      0.7481
         150      0.8022      1.5244      2.4387      0.0000      0.0480
         160      0.7574      1.4540      2.2987      0.0000      0.0341
         170      0.7778      1.5386      2.2958      0.0000      0.0546
         180      0.7332      1.5203      2.1158      0.0003      0.0295
         190      0.7315      1.4677      2.1390      0.0000      0.0508
         200      0.7445      1.5032      2.1598      0.0000      0.0596
         210      0.7377      1.5434      2.0983      0.0000      0.0467
         220      0.7296      1.5088      2.1030      0.0000      0.0361
         230      0.8290      1.5158      2.2200      0.0000      0.4093
         240      0.8490      1.4907      2.2632      0.0000      0.4909
         250      0.7978      1.5489      2.3098      0.0486      0.0333
         260      0.7529      1.5008      2.2303      0.0048      0.0238
         270      0.7478      1.5763      2.1258      0.0000      0.0370
         280      0.7263      1.5829      2.0010      0.0000      0.0478
         290      0.7527      1.5162      2.2200      0.0000      0.0272
         300      0.8398      1.5518      2.5147      0.0284      0.0758
         310      0.7857      1.5219      2.1837      0.0854      0.0521
         320      0.7244      1.5270      2.0503      0.0000      0.0448
         330      0.7498      1.4785      2.2353      0.0000      0.0350
         340      1.0788      1.4933      2.3230      0.0000      1.5777
         350      0.7595      1.5665      2.2013      0.0000      0.0299
         360      1.0008      1.4894      2.2761      0.0000      1.2387
         370      0.8724      1.4994      2.3106      0.0026      0.5469
         380      0.7098      1.4843      2.0160      0.0000      0.0485
         390      0.7820      1.5124      2.2023      0.0000      0.1952
         400      0.7334      1.5615      2.0636      0.0000      0.0417
         410      0.7212      1.4800      2.0013      0.0465      0.0317
         420      0.7446      1.5617      2.1257      0.0000      0.0354
         430      0.7243      1.4975      2.0663      0.0000      0.0576
         440      0.7269      1.5023      2.1010      0.0000      0.0314
         450      1.0808      1.4846      2.3174      0.0000      1.6022
         460      0.7081      1.5004      2.0011      0.0000      0.0392
         470      0.7225      1.4743      2.0883      0.0000      0.0501
         480      0.7318      1.4811      2.1111      0.0000      0.0666
         490      0.7139      1.4500      2.0355      0.0000      0.0841
         500      1.5490      1.4902      2.3723      0.0000      3.8823
         510      0.7367      1.5253      2.1092      0.0000      0.0490
         520      0.7819      1.5379      2.0889      0.1260      0.0307
         530      0.7454      1.5431      2.1618      0.0000      0.0221
         540      0.7234      1.5252      2.0258      0.0000      0.0661
         550      0.7435      1.4434      2.2047      0.0000      0.0694
         560      0.7673      1.5362      2.2673      0.0000      0.0330
         570      0.7371      1.4917      2.1568      0.0017      0.0336
         580      0.7035      1.4827      1.9781      0.0000      0.0565
         590      1.2263      1.5163      2.2915      0.0000      2.3236
         600      0.7427      1.5618      2.1223      0.0041      0.0213
       final      0.6889      1.4665      1.9445      0.0000      0.0337
best loss step: 574
Max CUDA memory: 1.2109G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_55: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_55 in 15.30 minutes.
