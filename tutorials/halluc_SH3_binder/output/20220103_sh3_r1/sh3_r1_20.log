/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[20:22:54] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 20, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_20, length 86...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.8517      1.7243      2.9013      0.0534      4.5263
          10      1.2086      1.7054      2.9470      0.6884      0.0140
          20      0.9647      1.7108      2.9946      0.0003      0.1174
          30      1.3871      1.6842      2.9539      1.1299      0.0377
          40      1.0451      1.5721      2.9253      0.0256      0.6771
          50      0.9137      1.6168      2.9408      0.0000      0.0109
          60      0.9333      1.5360      2.9060      0.1070      0.0103
          70      0.9616      1.5719      2.9450      0.1409      0.0094
          80      1.1497      1.5088      2.9401      0.6381      0.0232
          90      0.8588      1.4517      2.7987      0.0000      0.0437
         100      1.5465      1.4491      2.8497      1.4936      0.4464
         110      1.2084      1.4858      2.9175      0.7417      0.1552
         120      0.9578      1.5480      2.9380      0.0200      0.2628
         130      1.2027      1.5147      2.8920      0.6601      0.2865
         140      0.9917      1.6002      2.8951      0.0852      0.2928
         150      0.9598      1.5848      2.9294      0.0001      0.2848
         160      2.1405      1.5905      2.9437      3.0593      0.0496
         170      1.2138      1.5932      2.9364      0.7431      0.0533
         180      0.9594      1.7614      2.9333      0.0473      0.0076
         190      0.9819      1.6651      2.8978      0.1402      0.0665
         200      0.9631      1.7368      2.9345      0.0694      0.0054
         210      0.9264      1.5925      2.9543      0.0317      0.0216
         220      0.9458      1.5288      2.9114      0.1399      0.0090
         230      1.1498      1.5975      2.9290      0.6048      0.0129
         240      0.9178      1.6160      2.9445      0.0101      0.0086
         250      1.0590      1.6067      2.8995      0.3813      0.0260
         260      1.0182      1.5885      2.9479      0.2747      0.0051
         270      1.1602      1.6116      2.9709      0.5954      0.0279
         280      0.9284      1.6212      2.9127      0.0396      0.0290
         290      1.8130      1.6724      2.9828      2.2021      0.0055
         300      1.3976      1.7497      2.9735      1.1303      0.0040
         310      1.3254      1.6950      2.9382      0.9918      0.0100
         320      1.0967      1.6470      2.9435      0.4402      0.0127
         330      0.8964      1.5389      2.9267      0.0000      0.0163
         340      1.4717      1.4936      2.8990      1.4786      0.0089
         350      0.9103      1.4474      2.9071      0.0826      0.0316
         360      0.8909      1.5154      2.9074      0.0000      0.0316
         370      1.0850      1.5100      2.8732      0.5154      0.0109
         380      1.0150      1.5295      2.7628      0.3458      0.0911
         390      1.2435      1.5672      2.8615      0.8883      0.0122
         400      0.8488      1.4742      2.7404      0.0000      0.0294
         410      1.0343      1.5250      2.5747      0.5211      0.0296
         420      0.9474      1.4536      2.6132      0.3203      0.0295
         430      1.1511      1.5371      2.6610      0.7659      0.0255
         440      0.8550      1.5156      2.7358      0.0002      0.0231
         450      0.8113      1.4336      2.5851      0.0000      0.0380
         460      0.8711      1.4765      2.8538      0.0020      0.0213
         470      0.8466      1.5331      2.6800      0.0000      0.0200
         480      1.5902      1.4963      2.7314      1.8462      0.0309
         490      0.8509      1.6252      2.5897      0.0054      0.0286
         500      0.8705      1.4031      2.7850      0.0000      0.1644
         510      0.8344      1.3980      2.7013      0.0000      0.0726
         520      0.8191      1.3978      2.6710      0.0000      0.0265
         530      1.0949      1.4692      2.6327      0.6715      0.0296
         540      0.7414      1.4281      2.2396      0.0000      0.0395
         550      0.8747      1.5145      2.7028      0.0023      0.1517
         560      0.7888      1.4057      2.5121      0.0000      0.0259
         570      0.7484      1.3992      2.3138      0.0000      0.0292
         580      0.8189      1.4289      2.6373      0.0000      0.0283
         590      0.8711      1.4858      2.6497      0.0002      0.2198
         600      0.8014      1.4361      2.5403      0.0000      0.0305
       final      0.7407      1.3422      2.3300      0.0000      0.0314
best loss step: 529
Max CUDA memory: 1.3285G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_20: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_20 in 14.51 minutes.

Generating sh3_r1_21, length 77...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.5275      1.6796      2.9854      0.0099      2.9528
          10      0.9760      1.7425      2.9461      0.0899      0.0114
          20      0.9058      1.6505      2.8675      0.0000      0.0111
          30      0.9392      1.6733      2.8324      0.0001      0.1904
          40      1.0941      1.5720      2.7560      0.5401      0.0620
          50      0.8049      1.6035      2.3768      0.0001      0.0438
          60      0.7914      1.5351      2.3969      0.0000      0.0250
          70      0.7918      1.5218      2.4224      0.0000      0.0149
          80      0.7383      1.4754      2.1997      0.0000      0.0165
          90      0.7566      1.5499      2.2232      0.0000      0.0100
         100      0.7280      1.4102      2.2113      0.0000      0.0185
         110      0.7451      1.4869      2.2141      0.0000      0.0244
         120      0.7371      1.4412      2.1943      0.0000      0.0500
         130      0.8016      1.5182      2.3803      0.0000      0.1096
         140      0.7884      1.5427      2.3667      0.0000      0.0326
         150      0.7578      1.4711      2.2598      0.0000      0.0580
         160      0.7538      1.5291      2.2223      0.0000      0.0178
         170      0.8190      1.5176      2.5653      0.0000      0.0121
         180      0.7593      1.5625      2.2120      0.0033      0.0152
         190      0.7788      1.5816      2.2921      0.0000      0.0203
         200      0.7994      1.5475      2.4379      0.0000      0.0116
         210      0.7634      1.5143      2.2582      0.0000      0.0445
         220      0.7343      1.5051      2.1425      0.0000      0.0240
         230      0.8117      1.5993      2.3726      0.0365      0.0133
         240      0.7525      1.4495      2.2614      0.0002      0.0509
         250      0.7838      1.5937      2.2787      0.0000      0.0467
         260      1.0363      1.5762      2.4409      0.0485      1.0672
         270      0.7882      1.5827      2.2925      0.0000      0.0655
         280      0.7491      1.5338      2.1745      0.0000      0.0372
         290      0.8275      1.5820      2.4606      0.0429      0.0093
         300      0.7847      1.5683      2.3357      0.0000      0.0195
         310      0.7590      1.5556      2.1968      0.0000      0.0425
         320      0.7572      1.4844      2.2812      0.0009      0.0186
         330      0.9350      1.6057      2.5404      0.0000      0.5288
         340      0.8532      1.6247      2.5778      0.0000      0.0637
         350      0.7868      1.5451      2.3753      0.0000      0.0136
         360      0.7612      1.5160      2.2825      0.0000      0.0073
         370      0.8028      1.5597      2.3985      0.0000      0.0557
         380      0.7305      1.4832      2.1451      0.0000      0.0241
         390      0.7493      1.5146      2.2178      0.0000      0.0140
         400      0.7995      1.5000      2.3801      0.0327      0.0520
         410      0.7478      1.5259      2.2020      0.0000      0.0110
         420      0.8014      1.5659      2.4123      0.0000      0.0288
         430      0.7754      1.5961      2.2660      0.0000      0.0149
         440      0.7756      1.5453      2.3213      0.0000      0.0113
         450      0.7798      1.5570      2.3164      0.0000      0.0258
         460      0.7830      1.5493      2.3291      0.0000      0.0368
         470      0.7839      1.5160      2.3820      0.0001      0.0212
         480      0.7839      1.5665      2.3070      0.0000      0.0460
         490      0.8133      1.6257      2.4254      0.0001      0.0149
         500      0.7606      1.5328      2.2545      0.0000      0.0156
         510      0.7761      1.5788      2.2394      0.0000      0.0622
         520      0.7859      1.6264      2.2798      0.0000      0.0232
         530      0.7686      1.5207      2.2715      0.0000      0.0510
         540      0.7753      1.5555      2.3084      0.0000      0.0125
         550      0.8612      1.6311      2.6282      0.0000      0.0465
         560      0.8317      1.5988      2.3790      0.0000      0.1805
         570      2.0547      1.5310      2.6088      0.0000      6.1336
         580      0.7335      1.5203      2.1269      0.0000      0.0205
         590      0.8056      1.5751      2.2992      0.0672      0.0195
         600      0.7539      1.5691      2.1916      0.0000      0.0086
       final      0.7142      1.4479      2.1022      0.0000      0.0208
best loss step: 186
Max CUDA memory: 1.1165G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_21: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_21 in 13.90 minutes.
