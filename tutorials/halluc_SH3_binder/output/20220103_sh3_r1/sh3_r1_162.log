/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[23:47:09] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 162, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_162, length 98...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      3.0510      1.9873      2.9091      5.1644      0.0296
          10      1.1494      1.7135      2.9290      0.0000      1.1044
          20      2.0721      1.5941      2.8537      1.3301      3.2524
          30      2.1759      1.6854      2.9228      3.1103      0.0509
          40      1.9196      1.6702      2.9219      2.3544      0.2969
          50      1.7269      1.6754      2.8977      2.0154      0.0304
          60      1.0706      1.7772      2.8175      0.2426      0.2729
          70      1.1937      1.6525      2.8287      0.5836      0.3202
          80      0.9445      1.6228      2.8666      0.0001      0.2332
          90      1.5722      1.6737      2.9598      1.5978      0.0317
         100      1.2879      1.7295      2.9550      0.8521      0.0509
         110      0.9927      1.6224      2.9564      0.1079      0.1691
         120      1.0166      1.6559      2.9305      0.2326      0.0314
         130      1.6188      1.7455      2.9456      1.6973      0.0083
         140      0.9341      1.6605      2.9058      0.0402      0.0237
         150      0.9040      1.6572      2.8393      0.0000      0.0232
         160      0.8974      1.5949      2.8510      0.0000      0.0412
         170      0.8950      1.5953      2.7491      0.0527      0.0251
         180      1.2848      1.5339      2.7810      1.0458      0.0175
         190      0.9509      1.6199      2.8480      0.1320      0.0228
         200      0.9037      1.6654      2.8361      0.0001      0.0168
         210      1.2427      1.6009      2.8293      0.8851      0.0134
         220      0.9611      1.5365      2.6711      0.1566      0.2847
         230      1.2015      1.5881      2.7801      0.6517      0.3360
         240      0.8694      1.5883      2.6955      0.0192      0.0251
         250      0.8677      1.5246      2.7656      0.0000      0.0484
         260      0.9289      1.5555      2.7694      0.1506      0.0186
         270      0.9074      1.5193      2.8147      0.0000      0.2030
         280      1.1716      1.5543      2.8724      0.7106      0.0100
         290      0.8757      1.5705      2.7857      0.0000      0.0222
         300      0.8967      1.5304      2.7898      0.0592      0.0448
         310      0.8786      1.5391      2.8057      0.0000      0.0482
         320      0.8997      1.5433      2.8791      0.0000      0.0761
         330      2.1330      1.5199      2.8474      3.1426      0.0125
         340      0.9430      1.5636      2.8119      0.1489      0.0415
         350      0.8599      1.5658      2.6410      0.0257      0.0413
         360      0.9644      1.5663      2.7670      0.2278      0.0330
         370      1.2074      1.5692      2.7344      0.8503      0.0325
         380      0.9890      1.5261      2.7035      0.3368      0.0418
         390      1.1349      1.5815      2.8145      0.6229      0.0324
         400      0.8318      1.5609      2.5479      0.0000      0.0504
         410      1.1063      1.6015      2.8745      0.5173      0.0210
         420      0.8919      1.6745      2.7711      0.0002      0.0133
         430      0.8818      1.5771      2.7885      0.0000      0.0433
         440      0.8513      1.4621      2.6637      0.0458      0.0392
         450      0.8172      1.5076      2.5388      0.0000      0.0397
         460      0.8049      1.5322      2.4499      0.0014      0.0397
         470      0.8341      1.5597      2.5641      0.0000      0.0465
         480      0.8014      1.5683      2.4071      0.0016      0.0281
         490      0.7836      1.4769      2.3995      0.0000      0.0417
         500      0.7849      1.5013      2.3941      0.0000      0.0288
         510      0.7905      1.4342      2.4888      0.0001      0.0293
         520      0.7993      1.4676      2.5140      0.0000      0.0147
         530      0.8804      1.5607      2.5534      0.1334      0.0213
         540      0.7477      1.4141      2.2971      0.0002      0.0268
         550      0.7981      1.4597      2.4891      0.0000      0.0417
         560      0.7663      1.5178      2.2634      0.0000      0.0500
         570      0.7885      1.5189      2.3990      0.0000      0.0248
         580      0.7450      1.3727      2.3067      0.0003      0.0452
         590      1.1121      1.4111      2.5142      0.7917      0.0515
         600      0.7837      1.4646      2.3982      0.0000      0.0557
       final      0.7238      1.4621      2.1190      0.0000      0.0381
best loss step: 543
Max CUDA memory: 1.6447G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_162: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_162 in 16.35 minutes.

Generating sh3_r1_163, length 85...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      2.3945      1.7549      2.9654      2.1760      2.9002
          10      2.1991      1.9416      2.8248      3.1046      0.0202
          20      1.7779      1.7011      2.8330      0.0003      4.3548
          30      1.3495      1.9818      2.7576      0.9884      0.0315
          40      0.9462      1.8245      2.8798      0.0027      0.0215
          50      2.6646      1.6903      2.8453      4.3878      0.0115
          60      0.8979      1.6637      2.8203      0.0001      0.0054
          70      0.9008      1.7722      2.7135      0.0001      0.0178
          80      0.8901      1.6815      2.7242      0.0001      0.0447
          90      1.0460      1.5858      2.7773      0.4296      0.0074
         100      1.0423      1.5461      2.8505      0.3978      0.0195
         110      0.8941      1.4818      2.8214      0.0000      0.1675
         120      0.8923      1.5686      2.8844      0.0001      0.0082
         130      1.2688      1.4996      2.6771      1.0754      0.0162
         140      0.9739      1.5701      2.7749      0.2516      0.0211
         150      0.8334      1.5361      2.6000      0.0000      0.0310
         160      0.8650      1.6603      2.6511      0.0001      0.0135
         170      1.0273      1.4885      2.7569      0.4405      0.0101
         180      0.8000      1.4711      2.4701      0.0000      0.0588
         190      0.7622      1.4741      2.2633      0.0161      0.0415
         200      0.7575      1.3835      2.3625      0.0001      0.0416
         210      0.7675      1.5201      2.2634      0.0000      0.0539
         220      0.7371      1.4116      2.2251      0.0006      0.0475
         230      0.7363      1.4123      2.2205      0.0026      0.0435
         240      0.7551      1.3945      2.2470      0.0003      0.1335
         250      0.7330      1.4243      2.1985      0.0000      0.0420
         260      0.7557      1.4755      2.2574      0.0000      0.0456
         270      0.7731      1.5341      2.2881      0.0004      0.0426
         280      1.3202      1.5216      2.7102      1.1790      0.0109
         290      0.7543      1.4403      2.2887      0.0000      0.0422
         300      0.7372      1.4356      2.2096      0.0001      0.0406
         310      0.7156      1.3291      2.2114      0.0000      0.0374
         320      0.7253      1.3947      2.1880      0.0021      0.0397
         330      0.7561      1.4284      2.3162      0.0000      0.0360
         340      0.7918      1.4946      2.4176      0.0096      0.0274
         350      0.8160      1.3949      2.6526      0.0078      0.0167
         360      0.7330      1.4482      2.1752      0.0004      0.0411
         370      0.8160      1.5192      2.4497      0.0448      0.0212
         380      1.0046      1.5000      2.5052      0.4981      0.0216
         390      0.7248      1.4820      2.1016      0.0002      0.0402
         400      1.4574      1.3990      2.6791      0.0118      3.1852
         410      2.0913      1.5512      2.8666      1.9933      2.0521
         420      1.2966      1.5490      2.7334      0.0001      2.2008
         430      1.6195      1.5824      2.7698      1.8679      0.0096
         440      0.8603      1.6607      2.6306      0.0004      0.0093
         450      0.8794      1.6612      2.6444      0.0410      0.0093
         460      0.9046      1.6338      2.6523      0.1122      0.0126
         470      0.8588      1.4514      2.5781      0.1186      0.0274
         480      0.7719      1.4718      2.3455      0.0015      0.0393
         490      0.7570      1.4087      2.3389      0.0006      0.0360
         500      0.9058      1.4857      2.6450      0.0809      0.2365
         510      0.7411      1.4461      2.1987      0.0095      0.0416
         520      0.8017      1.4751      2.5020      0.0004      0.0307
         530      0.7425      1.4045      2.2560      0.0068      0.0384
         540      0.7476      1.4373      2.2673      0.0000      0.0335
         550      0.7857      1.5051      2.3902      0.0035      0.0259
         560      0.7798      1.4524      2.4177      0.0017      0.0256
         570      0.7514      1.3801      2.3324      0.0022      0.0400
         580      0.8128      1.5061      2.4823      0.0000      0.0755
         590      0.7366      1.4555      2.1853      0.0001      0.0419
         600      0.7435      1.4506      2.2259      0.0001      0.0408
       final      0.6937      1.3121      2.1154      0.0000      0.0409
best loss step: 331
Max CUDA memory: 1.3118G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_163: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_163 in 14.73 minutes.
