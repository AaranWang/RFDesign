/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[22:07:14] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 98, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_98, length 98...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.0449      1.6526      2.9898      0.0000      0.5821
          10      1.5886      1.7686      2.9744      1.5542      0.0916
          20      0.9129      1.6143      2.9142      0.0092      0.0178
          30      1.4833      1.6924      2.8848      1.4137      0.0118
          40      0.9405      1.6010      2.9391      0.0701      0.0222
          50      1.3180      1.6355      2.8457      1.0518      0.0053
          60      0.8890      1.6074      2.8238      0.0031      0.0076
          70      0.9475      1.6685      2.8607      0.0961      0.0162
          80      2.7534      1.7065      2.8113      4.6187      0.0117
          90      1.1363      1.7353      2.8399      0.5456      0.0150
         100      0.9384      1.6423      2.9051      0.0650      0.0144
         110      0.9223      1.7220      2.8631      0.0009      0.0245
         120      1.0588      1.6520      2.8924      0.3657      0.0182
         130      1.1499      1.6215      2.9167      0.6021      0.0068
         140      0.9401      1.5521      2.8945      0.1200      0.0139
         150      0.9113      1.6086      2.9324      0.0000      0.0155
         160      0.9257      1.6197      2.9328      0.0357      0.0043
         170      1.5549      1.4947      2.8980      0.0000      3.3817
         180      0.9084      1.6213      2.8591      0.0000      0.0617
         190      2.4458      1.5684      2.8648      3.8777      0.0402
         200      0.9168      1.5751      2.8593      0.0000      0.1496
         210      0.8753      1.5244      2.8015      0.0146      0.0216
         220      0.8582      1.5457      2.7151      0.0007      0.0286
         230      0.9353      1.5469      2.7553      0.1732      0.0279
         240      1.4139      1.5115      2.6993      0.6475      1.5639
         250      0.8692      1.5768      2.7125      0.0000      0.0567
         260      1.0651      1.6010      2.7345      0.4880      0.0139
         270      1.6618      1.4971      2.7017      2.0459      0.0183
         280      0.8468      1.5467      2.5988      0.0347      0.0191
         290      2.8116      1.5663      2.6564      2.3679      5.0994
         300      0.8404      1.5238      2.6168      0.0000      0.0613
         310      0.8530      1.5212      2.4773      0.1217      0.0230
         320      0.8055      1.5594      2.4257      0.0045      0.0335
         330      0.7870      1.5858      2.3171      0.0022      0.0279
         340      0.8434      1.6204      2.4842      0.0001      0.1124
         350      0.8403      1.5712      2.5686      0.0003      0.0608
         360      0.7908      1.5266      2.3099      0.0000      0.1176
         370      1.1289      1.4919      2.6252      0.6934      0.1407
         380      0.8392      1.5361      2.5593      0.0000      0.1004
         390      0.9054      1.5481      2.6283      0.1517      0.0472
         400      0.8490      1.5201      2.6525      0.0000      0.0722
         410      1.3472      1.5781      2.6553      1.2143      0.0737
         420      0.9854      1.5431      2.6769      0.3404      0.0262
         430      0.8538      1.5125      2.7091      0.0000      0.0475
         440      0.8846      1.6391      2.5576      0.0989      0.0284
         450      0.8647      1.6370      2.6342      0.0014      0.0496
         460      0.8148      1.5205      2.4990      0.0017      0.0513
         470      1.0730      1.4888      2.6190      0.0000      1.2571
         480      0.9947      1.5945      2.5177      0.4049      0.0517
         490      0.8623      1.5708      2.5869      0.0591      0.0358
         500      0.8069      1.5205      2.4578      0.0000      0.0562
         510      0.8492      1.5691      2.5693      0.0000      0.1076
         520      0.8152      1.4861      2.4187      0.0586      0.0540
         530      0.8067      1.5355      2.4214      0.0000      0.0765
         540      0.8118      1.5094      2.4808      0.0018      0.0653
         550      0.8335      1.5133      2.5412      0.0002      0.1128
         560      0.8205      1.5002      2.4272      0.0642      0.0468
         570      0.7702      1.4970      2.1929      0.0000      0.1613
         580      0.8121      1.5046      2.4512      0.0000      0.1048
         590      0.7942      1.5155      2.2670      0.0000      0.1883
         600      0.8306      1.5444      2.4287      0.0357      0.1084
       final      0.7562      1.4922      2.2423      0.0000      0.0464
best loss step: 567
Max CUDA memory: 1.6447G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_98: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_98 in 16.64 minutes.

Generating sh3_r1_99, length 77...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.8066      1.7407      2.6958      2.2719      0.0529
          10      0.8676      1.5865      2.3495      0.1766      0.0488
          20      0.7998      1.5472      2.3664      0.0000      0.0854
          30      0.7085      1.3924      2.0509      0.0001      0.0991
          40      0.7104      1.4374      2.0408      0.0000      0.0738
          50      0.7158      1.4061      2.0940      0.0000      0.0788
          60      0.7174      1.4253      2.0687      0.0072      0.0783
          70      2.6281      1.5090      2.3372      0.0000      9.2942
          80      0.7930      1.6111      2.2767      0.0000      0.0770
          90      0.7036      1.4174      2.0140      0.0000      0.0865
         100      0.7254      1.4191      2.1131      0.0000      0.0946
         110      0.7154      1.4861      2.0086      0.0000      0.0820
         120      0.6885      1.3963      1.9706      0.0000      0.0755
         130      0.7771      1.4598      2.3527      0.0000      0.0730
         140      0.6796      1.3325      1.9695      0.0000      0.0960
         150      0.7340      1.4600      2.1287      0.0000      0.0812
         160      0.7455      1.4831      2.1620      0.0000      0.0826
         170      0.7089      1.4337      2.0433      0.0000      0.0673
         180      0.7404      1.4864      2.1408      0.0000      0.0749
         190      0.7714      1.4722      2.3019      0.0000      0.0830
         200      0.6995      1.3979      2.0213      0.0000      0.0785
         210      0.6910      1.3393      2.0335      0.0000      0.0822
         220      0.7130      1.4429      2.0528      0.0002      0.0688
         230      0.7337      1.4067      2.1845      0.0000      0.0776
         240      0.6838      1.3517      1.9756      0.0000      0.0915
         250      0.7438      1.4512      2.1854      0.0001      0.0821
         260      0.7258      1.4371      2.1213      0.0000      0.0708
         270      0.7237      1.4140      2.1243      0.0000      0.0801
         280      0.6983      1.3855      2.0313      0.0000      0.0746
         290      0.7707      1.5406      2.2409      0.0000      0.0722
         300      0.6840      1.3543      1.9893      0.0000      0.0762
         310      0.7329      1.4501      2.1332      0.0000      0.0813
         320      0.7113      1.3910      2.0831      0.0000      0.0825
         330      0.6949      1.3868      1.9995      0.0000      0.0881
         340      0.7179      1.3794      2.1386      0.0000      0.0716
         350      0.6778      1.3950      1.9154      0.0000      0.0785
         360      0.6833      1.3641      1.9648      0.0000      0.0877
         370      0.7104      1.4039      2.0676      0.0000      0.0807
         380      0.7088      1.3790      2.0992      0.0000      0.0659
         390      0.7282      1.4293      2.1381      0.0013      0.0709
         400      0.6995      1.3954      2.0270      0.0000      0.0752
         410      0.7177      1.4162      2.0997      0.0000      0.0727
         420      0.7403      1.4358      2.1948      0.0000      0.0709
         430      0.7039      1.4704      1.9845      0.0000      0.0648
         440      0.6920      1.3378      2.0334      0.0000      0.0891
         450      0.7294      1.4550      2.1139      0.0000      0.0780
         460      0.7077      1.4183      2.0346      0.0000      0.0856
         470      0.6996      1.3756      2.0460      0.0000      0.0766
         480      0.7201      1.3806      2.1525      0.0000      0.0675
         490      0.7150      1.3905      2.1123      0.0000      0.0723
         500      0.7260      1.4981      2.0652      0.0000      0.0666
         510      0.7150      1.4091      2.0978      0.0001      0.0679
         520      0.7206      1.4094      2.1221      0.0000      0.0717
         530      0.6773      1.3918      1.9229      0.0000      0.0718
         540      0.7407      1.4488      2.1875      0.0000      0.0673
         550      0.7437      1.4567      2.2063      0.0000      0.0553
         560      0.7268      1.4394      2.1230      0.0000      0.0718
         570      2.5039      1.5969      2.3113      0.0000      8.6111
         580      0.7165      1.4976      2.0167      0.0022      0.0635
         590      0.6788      1.3538      1.9702      0.0000      0.0702
         600      0.7108      1.3895      2.0946      0.0000      0.0697
       final      0.6603      1.2720      1.9375      0.0000      0.0922
best loss step: 395
Max CUDA memory: 1.1208G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_99: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_99 in 14.28 minutes.
