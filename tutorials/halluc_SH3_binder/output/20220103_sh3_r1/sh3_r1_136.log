/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[23:06:22] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 136, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_136, length 78...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.0354      1.7640      2.9783      0.0001      0.4346
          10      0.9071      1.6683      2.8354      0.0095      0.0129
          20      1.2559      1.5684      2.7605      0.9671      0.0164
          30      0.8811      1.6298      2.7659      0.0000      0.0095
          40      0.8966      1.5162      2.7974      0.0004      0.1685
          50      0.8279      1.5557      2.5434      0.0000      0.0405
          60      0.8763      1.7174      2.6451      0.0001      0.0189
          70      0.8326      1.5972      2.5378      0.0000      0.0278
          80      0.8464      1.5616      2.6045      0.0147      0.0366
          90      0.8289      1.4858      2.6301      0.0000      0.0289
         100      0.8606      1.5467      2.7344      0.0000      0.0219
         110      0.8474      1.5483      2.6630      0.0000      0.0256
         120      0.8166      1.5518      2.5084      0.0000      0.0227
         130      0.7746      1.4696      2.3795      0.0001      0.0237
         140      0.7717      1.4964      2.3242      0.0001      0.0378
         150      1.0351      1.5541      2.6699      0.4676      0.0162
         160      0.8190      1.6119      2.4523      0.0001      0.0307
         170      0.8109      1.5286      2.5073      0.0000      0.0185
         180      0.7439      1.4840      2.1986      0.0000      0.0371
         190      0.7820      1.5140      2.3662      0.0000      0.0296
         200      0.8507      1.5438      2.6835      0.0003      0.0256
         210      0.7585      1.5185      2.2476      0.0000      0.0264
         220      0.7755      1.5104      2.3396      0.0002      0.0273
         230      0.7541      1.4587      2.2721      0.0020      0.0355
         240      0.7809      1.4499      2.4183      0.0015      0.0332
         250      0.8298      1.5943      2.5364      0.0000      0.0182
         260      0.8709      1.6214      2.7272      0.0001      0.0058
         270      0.7729      1.4630      2.3773      0.0001      0.0243
         280      0.7761      1.4556      2.3937      0.0000      0.0314
         290      0.8183      1.5174      2.5528      0.0002      0.0208
         300      0.7425      1.4551      2.2328      0.0000      0.0247
         310      0.7750      1.5045      2.3072      0.0000      0.0632
         320      0.7125      1.4265      2.1058      0.0000      0.0304
         330      0.7996      1.4801      2.4624      0.0002      0.0550
         340      0.7805      1.4516      2.4208      0.0000      0.0299
         350      0.8261      1.5079      2.5999      0.0000      0.0229
         360      0.7705      1.4894      2.3255      0.0001      0.0376
         370      0.7857      1.4796      2.4195      0.0001      0.0290
         380      0.7605      1.4245      2.3454      0.0001      0.0326
         390      0.7471      1.4580      2.2405      0.0001      0.0368
         400      0.7537      1.4358      2.3088      0.0000      0.0237
         410      0.7820      1.5150      2.3689      0.0000      0.0259
         420      0.8019      1.5305      2.4227      0.0018      0.0528
         430      0.7322      1.4766      2.1555      0.0001      0.0287
         440      0.8406      1.5737      2.5976      0.0000      0.0316
         450      0.7486      1.4601      2.2512      0.0000      0.0318
         460      0.7788      1.5130      2.3485      0.0038      0.0250
         470      0.8269      1.5378      2.5859      0.0000      0.0107
         480      0.7648      1.4830      2.3200      0.0000      0.0211
         490      0.7796      1.4426      2.4303      0.0003      0.0243
         500      0.7580      1.4461      2.3134      0.0000      0.0302
         510      1.8926      1.5641      2.5288      0.0001      5.3700
         520      0.7444      1.4879      2.1851      0.0076      0.0337
         530      0.7359      1.3884      2.2641      0.0000      0.0269
         540      0.7895      1.4657      2.4482      0.0000      0.0335
         550      0.7553      1.4530      2.2662      0.0156      0.0263
         560      0.7388      1.4509      2.2208      0.0000      0.0225
         570      0.7476      1.4558      2.2576      0.0000      0.0245
         580      0.7615      1.4334      2.3414      0.0019      0.0289
         590      0.7652      1.5349      2.2616      0.0000      0.0295
         600      0.7896      1.5102      2.3926      0.0002      0.0447
       final      0.7087      1.4331      2.0818      0.0001      0.0282
best loss step: 499
Max CUDA memory: 1.1405G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_136: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_136 in 13.95 minutes.

Generating sh3_r1_137, length 55...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.0036      1.7322      2.9706      0.1366      0.0422
          10      1.0647      1.7612      2.6792      0.0000      0.8829
          20      0.8901      1.7522      2.6783      0.0000      0.0199
          30      1.2417      1.6494      2.5872      0.0000      1.9719
          40      0.8406      1.7839      2.4133      0.0008      0.0044
          50      0.8327      1.6960      2.4299      0.0000      0.0374
          60      0.8593      1.7648      2.5247      0.0007      0.0057
          70      1.3365      1.6811      2.5658      0.0001      2.4355
          80      0.8361      1.6845      2.4910      0.0002      0.0047
          90      0.7999      1.6542      2.3001      0.0000      0.0453
         100      1.7132      1.7396      2.4244      0.0000      4.4019
         110      0.9508      1.6248      2.4503      0.0000      0.6787
         120      0.8174      1.6726      2.4051      0.0001      0.0090
         130      0.8111      1.6686      2.3656      0.0000      0.0212
         140      0.8588      1.6718      2.5124      0.0000      0.1099
         150      0.8224      1.6801      2.4234      0.0002      0.0081
         160      0.8436      1.7799      2.4073      0.0000      0.0309
         170      0.8199      1.6686      2.4021      0.0000      0.0286
         180      0.8766      1.6443      2.6548      0.0000      0.0841
         190      0.8216      1.7039      2.3968      0.0021      0.0029
         200      0.8196      1.7002      2.3620      0.0001      0.0354
         210      0.8587      1.7707      2.4881      0.0000      0.0343
         220      0.7814      1.7658      2.1364      0.0007      0.0036
         230      0.8358      1.7286      2.4367      0.0002      0.0135
         240      0.8412      1.6668      2.4102      0.0000      0.1287
         250      0.7857      1.6502      2.2729      0.0002      0.0050
         260      0.8192      1.6801      2.2770      0.0000      0.1387
         270      0.8525      1.7467      2.4985      0.0000      0.0172
         280      0.8075      1.6578      2.3765      0.0001      0.0030
         290      0.8329      1.6551      2.4827      0.0000      0.0266
         300      0.8065      1.6256      2.2812      0.0000      0.1259
         310      0.8572      1.7456      2.5277      0.0001      0.0128
         320      0.8091      1.6529      2.3877      0.0005      0.0041
         330      0.8062      1.6852      2.3399      0.0001      0.0057
         340      1.2510      1.6015      2.3891      1.1312      0.0021
         350      0.8365      1.6014      2.4862      0.0000      0.0947
         360      0.8060      1.6894      2.3354      0.0002      0.0051
         370      0.8258      1.6564      2.3474      0.0000      0.1251
         380      0.8272      1.8044      2.3202      0.0031      0.0052
         390      0.8116      1.6782      2.3634      0.0000      0.0162
         400      0.8396      1.6538      2.4003      0.0000      0.1439
         410      0.8124      1.7080      2.3427      0.0001      0.0111
         420      0.7892      1.5687      2.3460      0.0000      0.0312
         430      0.8389      1.7220      2.4388      0.0000      0.0335
         440      0.7973      1.6503      2.2606      0.0000      0.0757
         450      0.8017      1.6582      2.3222      0.0000      0.0281
         460      0.8615      1.6823      2.5161      0.0000      0.1091
         470      0.8102      1.7691      2.2678      0.0002      0.0135
         480      0.9589      1.7174      2.4495      0.0003      0.6270
         490      0.8326      1.6453      2.4983      0.0000      0.0194
         500      0.7954      1.4813      2.4587      0.0000      0.0367
         510      0.8289      1.7311      2.4104      0.0001      0.0027
         520      0.8400      1.7197      2.4751      0.0001      0.0051
         530      0.8190      1.7219      2.3675      0.0006      0.0042
         540      0.8475      1.8367      2.3961      0.0006      0.0036
         550      0.8238      1.6195      2.4788      0.0000      0.0207
         560      0.7801      1.6831      2.2087      0.0001      0.0086
         570      0.8023      1.7347      2.2682      0.0003      0.0081
         580      0.8280      1.7619      2.3732      0.0004      0.0042
         590      0.8165      1.7169      2.3587      0.0010      0.0046
         600      0.7949      1.6261      2.3402      0.0002      0.0077
       final      0.7655      1.5976      2.2143      0.0000      0.0156
best loss step: 528
Max CUDA memory: 0.7037G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_137: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_137 in 13.16 minutes.
