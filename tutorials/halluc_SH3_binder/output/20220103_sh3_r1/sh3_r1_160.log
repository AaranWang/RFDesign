/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[23:42:04] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 160, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_160, length 100...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.4274      1.6380      2.8623      0.0000      2.6368
          10      0.9472      1.7545      2.8823      0.0189      0.0614
          20      1.2726      1.5765      2.9139      0.8556      0.1611
          30      2.6542      1.7639      2.9213      3.2709      2.0438
          40      1.6137      1.7962      2.9559      1.0786      1.1592
          50      2.3215      1.6932      2.9367      0.0000      6.9778
          60      2.2418      1.7624      2.9461      3.2021      0.0965
          70      0.9823      1.7488      2.9507      0.0037      0.2047
          80      1.4109      1.8650      2.9298      1.1208      0.0181
          90      0.9348      1.7127      2.9512      0.0001      0.0102
         100      1.4328      1.6998      2.9626      1.2399      0.0219
         110      1.0803      1.6947      2.8822      0.3963      0.0320
         120      1.0281      1.7234      2.9390      0.2307      0.0168
         130      1.9521      1.6749      2.9102      1.8879      1.3994
         140      1.2929      1.6158      2.8952      0.0001      1.9533
         150      0.9203      1.6319      2.8917      0.0154      0.0470
         160      0.9312      1.6995      2.9372      0.0001      0.0193
         170      0.9322      1.6502      2.9286      0.0000      0.0821
         180      1.0899      1.7395      2.9030      0.3746      0.0577
         190      1.0125      1.6949      2.9084      0.2014      0.0565
         200      1.0311      1.6350      2.9378      0.2867      0.0093
         210      0.9104      1.6575      2.8480      0.0157      0.0151
         220      0.9109      1.6451      2.9010      0.0000      0.0085
         230      0.8597      1.5531      2.7182      0.0000      0.0271
         240      0.8836      1.5592      2.8476      0.0009      0.0095
         250      0.9007      1.6493      2.7807      0.0000      0.0734
         260      0.8744      1.5717      2.7369      0.0231      0.0173
         270      0.9529      1.5403      2.8120      0.2010      0.0102
         280      0.8782      1.5584      2.8225      0.0015      0.0070
         290      0.8935      1.5911      2.8564      0.0000      0.0199
         300      0.8828      1.5881      2.8200      0.0000      0.0059
         310      0.8590      1.6549      2.6193      0.0000      0.0209
         320      0.8545      1.5814      2.6270      0.0014      0.0614
         330      1.0201      1.8241      2.4740      0.3835      0.0354
         340      0.8146      1.6486      2.4063      0.0008      0.0165
         350      0.8039      1.6395      2.3596      0.0000      0.0203
         360      0.7854      1.5959      2.3114      0.0000      0.0198
         370      0.8025      1.5502      2.4459      0.0000      0.0166
         380      0.7837      1.5716      2.3280      0.0000      0.0188
         390      1.0099      1.6019      2.4514      0.0000      0.9961
         400      1.0127      1.4801      2.1896      0.6814      0.0310
         410      0.8756      1.5285      2.3369      0.2373      0.0382
         420      0.7464      1.5142      2.1831      0.0000      0.0347
         430      0.7323      1.5411      2.0777      0.0000      0.0427
         440      0.7462      1.4351      2.2568      0.0000      0.0391
         450      0.7607      1.5892      2.1685      0.0000      0.0460
         460      0.7437      1.5287      2.1616      0.0000      0.0283
         470      0.7322      1.5177      2.1072      0.0000      0.0360
         480      0.7465      1.5122      2.1927      0.0000      0.0274
         490      0.7113      1.4445      2.0812      0.0000      0.0308
         500      0.7550      1.5048      2.2373      0.0000      0.0330
         510      0.7308      1.5448      2.0612      0.0000      0.0480
         520      0.7569      1.4810      2.2665      0.0000      0.0372
         530      0.7090      1.4565      2.0459      0.0000      0.0428
         540      0.7063      1.4463      2.0474      0.0000      0.0377
         550      0.7257      1.4381      2.1529      0.0000      0.0377
         560      0.7676      1.4983      2.3021      0.0000      0.0376
         570      0.7350      1.4920      2.1451      0.0001      0.0378
         580      0.7346      1.5411      2.0928      0.0000      0.0390
         590      0.7492      1.5398      2.1534      0.0113      0.0305
         600      0.7142      1.4642      2.0664      0.0000      0.0402
       final      0.6863      1.4375      1.9541      0.0000      0.0401
best loss step: 599
Max CUDA memory: 1.7038G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_160: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_160 in 18.36 minutes.

Generating sh3_r1_161, length 99...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      2.6045      1.7289      2.9577      0.3057      7.7245
          10      1.1520      1.6300      2.8784      0.6154      0.0209
          20      0.9177      1.5997      2.9389      0.0000      0.0497
          30      1.5695      1.5754      2.9057      0.0000      3.3663
          40      1.0320      1.5846      2.7837      0.0000      0.7919
          50      0.9466      1.6746      2.7964      0.0000      0.2620
          60      2.4342      1.5303      2.7751      3.0322      1.8012
          70      0.9800      1.5709      2.8455      0.0403      0.4030
          80      1.8162      1.6632      2.8773      1.9964      0.5477
          90      1.1452      1.6268      2.8632      0.3872      0.4615
         100      0.9200      1.6629      2.9014      0.0000      0.0354
         110      0.9457      1.7432      2.9048      0.0000      0.0806
         120      0.9478      1.7960      2.9231      0.0000      0.0198
         130      0.9095      1.6665      2.8530      0.0000      0.0278
         140      1.5539      1.5781      2.9545      1.5998      0.0372
         150      1.8160      1.5887      2.8466      2.3084      0.0275
         160      0.9341      1.6001      2.9624      0.0486      0.0110
         170      1.0788      1.6654      2.9219      0.3986      0.0092
         180      1.1984      1.6068      2.9100      0.7302      0.0151
         190      0.9216      1.7083      2.8742      0.0028      0.0196
         200      1.0494      1.6297      2.9728      0.3195      0.0055
         210      0.9189      1.6324      2.9345      0.0000      0.0277
         220      0.9635      1.5495      2.8637      0.1532      0.0977
         230      1.9755      1.5587      2.8607      2.7073      0.0438
         240      1.4490      1.6282      2.9504      1.3166      0.0331
         250      2.3913      1.6001      2.9459      3.7011      0.0082
         260      1.9967      1.5559      2.9078      2.7510      0.0181
         270      2.1909      1.6192      2.9281      3.1973      0.0127
         280      1.3553      1.6109      2.9597      0.6703      0.8655
         290      1.2164      1.6060      2.9773      0.7427      0.0132
         300      2.1349      1.6168      2.9391      3.0464      0.0257
         310      0.9270      1.5890      2.9430      0.0000      0.1031
         320      1.4948      1.5893      2.9657      1.4433      0.0325
         330      1.5925      1.5908      2.9461      0.0000      3.4255
         340      1.0365      1.5747      2.9576      0.1662      0.3179
         350      0.9715      1.5829      2.9700      0.0000      0.3044
         360      1.0315      1.5560      2.9736      0.3047      0.0185
         370      1.3731      1.5758      2.9742      0.7657      0.7842
         380      1.4502      1.5203      2.9623      0.8166      1.1354
         390      0.9810      1.5579      2.9159      0.0734      0.2845
         400      1.0130      1.5247      2.9011      0.0000      0.6391
         410      0.9132      1.6134      2.9325      0.0000      0.0198
         420      0.9552      1.5991      2.9577      0.0950      0.0291
         430      1.5816      1.6423      2.9802      1.6224      0.0408
         440      1.0558      1.5785      2.9917      0.3387      0.0317
         450      1.1011      1.6241      2.9834      0.4248      0.0485
         460      1.0182      1.5489      2.9674      0.2757      0.0234
         470      1.2389      1.6084      2.9848      0.7944      0.0124
         480      1.9057      1.6655      2.9505      2.4446      0.0235
         490      0.9584      1.6309      2.9389      0.0004      0.2216
         500      0.9378      1.5736      2.9552      0.0000      0.1600
         510      0.9721      1.5734      2.9661      0.1113      0.0985
         520      0.9173      1.5900      2.9467      0.0000      0.0497
         530      0.9349      1.6625      2.9725      0.0000      0.0396
         540      1.6023      1.5957      2.9304      1.1012      1.2829
         550      0.9182      1.5646      2.9468      0.0000      0.0797
         560      0.9131      1.6047      2.9548      0.0000      0.0062
         570      1.1833      1.5546      2.8912      0.7073      0.0558
         580      1.0369      1.5746      2.9288      0.3337      0.0136
         590      1.0078      1.6168      2.9061      0.2396      0.0369
         600      1.0453      1.5650      2.9479      0.3360      0.0415
       final      0.8666      1.5661      2.7143      0.0000      0.0527
best loss step: 172
Max CUDA memory: 1.6895G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_161: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_161 in 18.18 minutes.
