/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[23:51:28] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 166, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_166, length 98...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      2.8414      1.5812      2.8814      4.5993      0.5457
          10      1.3715      1.6577      2.8664      1.1569      0.0196
          20      1.0022      1.7085      2.8124      0.2297      0.0306
          30      1.4832      1.8660      2.8829      1.3172      0.0328
          40      0.9675      1.7120      2.7924      0.0001      0.3331
          50      1.5722      1.6258      2.6869      1.7371      0.0742
          60      0.9306      1.7436      2.8364      0.0011      0.0709
          70      0.8559      1.5468      2.6370      0.0000      0.0958
          80      0.8284      1.4630      2.3622      0.1168      0.0831
          90      0.8119      1.4941      2.4939      0.0000      0.0713
         100      0.7935      1.5120      2.3686      0.0000      0.0867
         110      0.7445      1.4734      2.1582      0.0000      0.0908
         120      0.8125      1.4737      2.5248      0.0000      0.0642
         130      0.7856      1.5647      2.1993      0.0301      0.1037
         140      0.7946      1.5616      2.2920      0.0000      0.1192
         150      0.8944      1.5607      2.5996      0.0000      0.3115
         160      0.7627      1.4616      2.2209      0.0188      0.0931
         170      0.7940      1.5442      2.2973      0.0000      0.1286
         180      0.7628      1.5710      2.1507      0.0000      0.0923
         190      0.8086      1.5472      2.3608      0.0000      0.1349
         200      0.7980      1.6289      2.2630      0.0000      0.0982
         210      0.7573      1.5017      2.1769      0.0029      0.1018
         220      0.7797      1.4890      2.2377      0.0174      0.1368
         230      0.7716      1.5126      2.1987      0.0263      0.0939
         240      0.7239      1.4773      2.0506      0.0000      0.0914
         250      0.7395      1.4963      2.0943      0.0000      0.1070
         260      0.7328      1.4201      2.1497      0.0000      0.0942
         270      0.7319      1.4876      2.0856      0.0000      0.0864
         280      0.9963      1.4459      2.1341      0.6605      0.0804
         290      0.9682      1.5652      2.4741      0.3542      0.0931
         300      0.9347      1.4763      2.5544      0.0043      0.6341
         310      0.7533      1.4734      2.1896      0.0000      0.1037
         320      0.8972      1.4695      2.2324      0.3440      0.0959
         330      0.7488      1.4424      2.2091      0.0000      0.0923
         340      0.7911      1.4883      2.3998      0.0000      0.0674
         350      0.7215      1.4540      2.0651      0.0000      0.0883
         360      0.7512      1.4940      2.1493      0.0000      0.1128
         370      2.8284      1.5243      2.5749      0.7548      8.5333
         380      0.7468      1.4365      2.2055      0.0021      0.0877
         390      0.7750      1.5173      2.2611      0.0000      0.0964
         400      2.6325      1.4882      2.4546      0.0015      9.2169
         410      0.7824      1.5355      2.2417      0.0000      0.1348
         420      0.7706      1.4646      2.2751      0.0038      0.1057
         430      0.7937      1.5757      2.3108      0.0000      0.0821
         440      0.7417      1.4842      2.1327      0.0000      0.0914
         450      1.5121      1.5161      2.4166      1.6957      0.2363
         460      0.9818      1.4747      2.1364      0.6033      0.0915
         470      0.7169      1.4527      2.0286      0.0000      0.1033
         480      0.7489      1.5105      2.1299      0.0000      0.1043
         490      0.7428      1.4509      2.1656      0.0080      0.0814
         500      0.7169      1.4286      2.0585      0.0000      0.0974
         510      0.7310      1.4577      2.1117      0.0000      0.0858
         520      0.7461      1.4172      2.2167      0.0000      0.0966
         530      0.8341      1.4895      2.1911      0.1987      0.0922
         540      0.7897      1.5562      2.3129      0.0000      0.0793
         550      0.7406      1.4524      2.1683      0.0000      0.0825
         560      0.7564      1.4801      2.2125      0.0000      0.0893
         570      0.7740      1.4880      2.2877      0.0000      0.0941
         580      0.7542      1.4691      2.2129      0.0004      0.0879
         590      0.7960      1.4971      2.2668      0.0649      0.0862
         600      0.7285      1.3974      2.1681      0.0000      0.0767
       final      0.7081      1.4192      2.0350      0.0000      0.0862
best loss step: 534
Max CUDA memory: 1.6447G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_166: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_166 in 17.04 minutes.

Generating sh3_r1_167, length 75...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.2470      1.7656      2.9845      0.5437      0.3975
          10      0.8936      1.6560      2.6874      0.0000      0.1247
          20      0.7709      1.6195      2.2205      0.0000      0.0143
          30      0.8541      1.4271      2.3045      0.0156      0.5078
          40      0.8231      1.4766      2.5203      0.0000      0.1188
          50      0.7948      1.5608      2.2755      0.0000      0.1375
          60      0.7942      1.5503      2.2818      0.0000      0.1388
          70      0.8879      1.5613      2.6860      0.0000      0.1923
          80      0.7611      1.5398      2.1280      0.0164      0.1048
          90      0.8536      1.5069      2.5182      0.0002      0.2423
         100      1.0210      1.4549      2.3180      0.6069      0.1182
         110      0.8204      1.4750      2.4188      0.0000      0.2083
         120      0.7683      1.4565      2.2180      0.0000      0.1670
         130      0.7594      1.5075      2.1480      0.0000      0.1413
         140      0.7556      1.4660      2.1908      0.0000      0.1210
         150      0.7505      1.4670      2.0517      0.0595      0.1148
         160      0.7716      1.4464      2.2539      0.0147      0.1283
         170      0.7764      1.5515      2.2115      0.0000      0.1191
         180      0.7738      1.5369      2.0595      0.0767      0.1191
         190      1.9103      1.5716      2.5716      0.0000      5.4082
         200      0.8174      1.4369      2.2327      0.1722      0.0730
         210      0.7597      1.5227      2.1333      0.0001      0.1422
         220      0.7842      1.5287      2.2656      0.0000      0.1267
         230      0.7837      1.5510      2.2547      0.0000      0.1127
         240      0.8034      1.5843      2.3376      0.0160      0.0632
         250      0.7722      1.4620      2.2448      0.0264      0.1013
         260      0.7122      1.4696      2.0106      0.0000      0.0810
         270      0.7593      1.4636      2.2500      0.0000      0.0828
         280      0.7542      1.4579      2.2314      0.0000      0.0818
         290      0.7315      1.5138      2.0834      0.0000      0.0604
         300      0.7217      1.4181      2.0979      0.0043      0.0839
         310      0.7290      1.4726      2.0819      0.0000      0.0907
         320      0.7431      1.4877      2.1599      0.0015      0.0648
         330      0.7160      1.4286      2.0751      0.0001      0.0761
         340      0.7474      1.4650      2.0373      0.0825      0.0696
         350      0.7040      1.4923      1.9460      0.0000      0.0816
         360      0.7192      1.4435      2.0763      0.0000      0.0765
         370      0.7292      1.4723      2.1037      0.0009      0.0682
         380      0.7733      1.4590      2.2229      0.0514      0.0816
         390      0.7006      1.3910      2.0427      0.0000      0.0693
         400      0.7081      1.4005      2.0603      0.0000      0.0797
         410      0.7568      1.4825      2.2340      0.0000      0.0676
         420      0.7234      1.4898      2.0554      0.0001      0.0715
         430      0.6943      1.4289      1.9738      0.0000      0.0686
         440      0.7116      1.4753      2.0073      0.0036      0.0683
         450      0.7347      1.4308      2.1709      0.0000      0.0718
         460      0.7020      1.4494      1.9992      0.0000      0.0614
         470      0.7278      1.4363      2.1294      0.0003      0.0726
         480      0.7342      1.4503      2.1498      0.0008      0.0694
         490      0.7189      1.4520      2.0696      0.0001      0.0729
         500      0.7109      1.4488      2.0418      0.0000      0.0639
         510      0.7030      1.3906      2.0520      0.0000      0.0722
         520      0.7268      1.4543      2.1015      0.0000      0.0781
         530      1.9194      1.5454      2.3132      0.0000      5.7382
         540      0.7245      1.4842      2.0596      0.0000      0.0786
         550      0.6914      1.4508      1.9417      0.0000      0.0643
         560      0.7486      1.4483      2.2278      0.0007      0.0653
         570      0.7006      1.3979      2.0260      0.0002      0.0787
         580      0.7605      1.4944      2.2378      0.0006      0.0691
         590      1.1917      1.5997      2.3960      0.0001      1.9629
         600      0.7234      1.4974      2.0485      0.0000      0.0710
       final      0.6770      1.3693      1.9489      0.0000      0.0668
best loss step: 559
Max CUDA memory: 1.0788G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_167: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_167 in 14.27 minutes.
