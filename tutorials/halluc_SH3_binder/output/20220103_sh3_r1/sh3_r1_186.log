/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[00:22:15] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 186, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_186, length 89...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      0.9987      1.7941      2.9324      0.0001      0.2667
          10      1.2678      1.5804      2.9832      0.8786      0.0183
          20      2.0112      1.5876      2.9590      2.6968      0.1157
          30      0.9618      1.5767      2.9886      0.0236      0.1963
          40      0.9236      1.6235      2.9828      0.0006      0.0105
          50      1.1293      1.6764      2.9892      0.4785      0.0239
          60      0.9353      1.6996      2.9735      0.0000      0.0031
          70      0.9164      1.5853      2.9899      0.0011      0.0047
          80      1.3900      1.5841      2.8806      1.2312      0.0228
          90      0.9433      1.6318      2.9116      0.0000      0.1733
         100      1.1095      1.6776      2.9015      0.0001      0.9681
         110      1.2561      1.5632      2.7973      0.9486      0.0227
         120      0.8944      1.5989      2.8544      0.0000      0.0185
         130      1.9109      1.6257      2.8292      0.4311      4.2377
         140      0.8860      1.5938      2.8304      0.0000      0.0059
         150      0.8482      1.5529      2.6642      0.0000      0.0237
         160      0.9230      1.5827      2.7511      0.1378      0.0054
         170      0.8572      1.5397      2.7306      0.0000      0.0156
         180      0.8993      1.5112      2.7884      0.0846      0.0277
         190      0.8770      1.5634      2.8024      0.0000      0.0193
         200      0.8135      1.5051      2.5384      0.0019      0.0202
         210      0.7926      1.5356      2.4083      0.0002      0.0189
         220      0.8412      1.5832      2.5977      0.0000      0.0251
         230      0.8002      1.5417      2.4346      0.0000      0.0245
         240      0.8108      1.5575      2.4645      0.0000      0.0320
         250      0.8635      1.5960      2.7114      0.0005      0.0089
         260      0.8639      1.5894      2.7239      0.0000      0.0063
         270      0.8106      1.4818      2.5456      0.0008      0.0241
         280      0.7920      1.5980      2.3335      0.0000      0.0282
         290      0.7862      1.4537      2.4480      0.0001      0.0289
         300      0.7573      1.4139      2.3466      0.0004      0.0249
         310      0.7419      1.4243      2.2598      0.0003      0.0246
         320      0.8270      1.5911      2.5228      0.0007      0.0199
         330      0.8014      1.4867      2.4984      0.0000      0.0220
         340      0.8581      1.4814      2.4076      0.1857      0.0301
         350      0.7893      1.6004      2.3188      0.0000      0.0273
         360      0.8306      1.6703      2.4634      0.0000      0.0192
         370      0.8441      1.6145      2.5808      0.0002      0.0246
         380      1.2066      1.5313      2.5018      0.9891      0.0219
         390      0.7415      1.4433      2.2390      0.0000      0.0252
         400      0.8349      1.4836      2.5994      0.0382      0.0153
         410      0.7970      1.4456      2.5271      0.0000      0.0121
         420      0.8440      1.5575      2.6480      0.0000      0.0144
         430      0.7897      1.4869      2.4378      0.0000      0.0240
         440      0.8361      1.5418      2.6192      0.0000      0.0197
         450      0.7683      1.4703      2.2745      0.0357      0.0254
         460      0.7763      1.4871      2.2567      0.0566      0.0247
         470      0.7410      1.5217      2.1649      0.0000      0.0184
         480      0.7239      1.4819      2.1250      0.0001      0.0126
         490      0.8637      1.5790      2.5278      0.0968      0.0178
         500      0.7868      1.5390      2.3683      0.0001      0.0263
         510      0.7391      1.5032      2.1732      0.0000      0.0189
         520      0.7275      1.5015      2.1165      0.0003      0.0191
         530      0.7764      1.4867      2.1619      0.1095      0.0143
         540      0.7739      1.4737      2.3766      0.0004      0.0185
         550      0.7381      1.4570      2.2167      0.0000      0.0167
         560      0.7281      1.4828      2.1361      0.0013      0.0190
         570      0.7853      1.4287      2.4455      0.0170      0.0183
         580      0.6948      1.4210      2.0351      0.0017      0.0146
         590      0.7507      1.4690      2.2698      0.0000      0.0147
         600      0.7331      1.4911      2.1537      0.0000      0.0208
       final      0.6948      1.4210      2.0351      0.0017      0.0146
best loss step: 580
Max CUDA memory: 1.4175G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_186: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_186 in 15.08 minutes.

Generating sh3_r1_187, length 76...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      2.2626      1.6457      2.8504      1.5506      3.7158
          10      0.8962      1.7124      2.6359      0.0000      0.1327
          20      0.8204      1.5946      2.4791      0.0073      0.0138
          30      1.4077      1.5867      2.4004      0.0000      3.0512
          40      0.7922      1.4514      2.3106      0.0839      0.0314
          50      0.8068      1.5560      2.4601      0.0000      0.0181
          60      0.7753      1.4802      2.3789      0.0000      0.0175
          70      0.6813      1.4139      1.9773      0.0000      0.0151
          80      0.7166      1.4651      2.0955      0.0000      0.0227
          90      0.7570      1.5160      2.2474      0.0000      0.0217
         100      0.9309      1.4419      2.2296      0.0010      0.9811
         110      0.8118      1.3565      2.1168      0.0000      0.5859
         120      0.7771      1.4333      2.1596      0.0040      0.2845
         130      0.7922      1.4499      2.4003      0.0000      0.1109
         140      0.7778      1.4092      2.4218      0.0000      0.0582
         150      0.7728      1.5078      2.2805      0.0000      0.0757
         160      0.7328      1.3587      2.2482      0.0000      0.0572
         170      0.7433      1.3860      2.2859      0.0000      0.0448
         180      1.1170      1.4793      2.3772      0.8330      0.0623
         190      1.5784      1.5357      2.3352      1.9911      0.0390
         200      0.7294      1.3907      2.2262      0.0000      0.0301
         210      0.7409      1.4106      2.2455      0.0000      0.0484
         220      0.7037      1.3515      2.1333      0.0021      0.0294
         230      0.7237      1.3945      2.2008      0.0000      0.0230
         240      0.6819      1.3782      2.0081      0.0000      0.0230
         250      0.9512      1.3996      2.2232      0.0325      1.0682
         260      0.7209      1.3496      2.2079      0.0131      0.0210
         270      0.9795      1.5255      2.2758      0.0000      1.0963
         280      0.7959      1.5410      2.3959      0.0000      0.0427
         290      2.0282      1.4266      2.4654      0.0000      6.2490
         300      0.8077      1.5222      2.4248      0.0000      0.0913
         310      0.7485      1.4231      2.2559      0.0000      0.0636
         320      0.7734      1.3821      2.4317      0.0000      0.0530
         330      0.8371      1.4117      2.5129      0.0000      0.2610
         340      0.7991      1.4209      2.4971      0.0000      0.0775
         350      0.7641      1.3838      2.3527      0.0000      0.0841
         360      0.7556      1.3794      2.3626      0.0000      0.0359
         370      0.7776      1.4813      2.3790      0.0000      0.0278
         380      0.7131      1.3917      2.1594      0.0000      0.0145
         390      0.7067      1.3719      2.1361      0.0002      0.0250
         400      0.7608      1.5376      2.2381      0.0000      0.0283
         410      0.7673      1.5292      2.2740      0.0000      0.0333
         420      0.7201      1.4147      2.1599      0.0000      0.0260
         430      0.7252      1.4143      2.1769      0.0053      0.0244
         440      0.7843      1.4276      2.2230      0.1210      0.0287
         450      0.6950      1.3867      2.0699      0.0000      0.0182
         460      0.8164      1.4918      2.5648      0.0000      0.0252
         470      0.7654      1.5387      2.2673      0.0000      0.0209
         480      0.6937      1.3909      2.0538      0.0015      0.0206
         490      0.7260      1.3813      2.2085      0.0116      0.0169
         500      0.6934      1.4286      2.0025      0.0081      0.0196
         510      0.9413      1.4090      2.3715      0.0000      0.9258
         520      0.8390      1.4267      2.4865      0.0000      0.2815
         530      0.8233      1.4628      2.3805      0.0000      0.2732
         540      0.7522      1.4217      2.1954      0.0000      0.1439
         550      0.7926      1.4325      2.3430      0.0000      0.1877
         560      0.8181      1.5590      2.4091      0.0000      0.1223
         570      0.7723      1.5000      2.2067      0.0000      0.1550
         580      0.7536      1.4892      2.1395      0.0000      0.1393
         590      0.7381      1.3559      2.1743      0.0000      0.1604
         600      0.7697      1.4504      2.2268      0.0000      0.1713
       final      0.6771      1.4097      1.9483      0.0017      0.0240
best loss step: 262
Max CUDA memory: 1.1063G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_187: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_187 in 14.33 minutes.
