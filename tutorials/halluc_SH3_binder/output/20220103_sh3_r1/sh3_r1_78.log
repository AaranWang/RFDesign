/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[21:33:14] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 78, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_78, length 95...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      2.2758      1.8026      2.9900      3.2916      0.0030
          10      2.7914      1.6408      2.9180      4.6819      0.0343
          20      1.8155      1.5448      2.8968      2.0262      0.5835
          30      3.2393      1.5462      2.8097      0.0000     11.8406
          40      0.8988      1.6074      2.8497      0.0000      0.0371
          50      0.8604      1.6042      2.6236      0.0199      0.0344
          60      0.8431      1.5868      2.5943      0.0000      0.0341
          70      0.8195      1.5771      2.4656      0.0000      0.0545
          80      0.8040      1.5084      2.4432      0.0000      0.0684
          90      0.7992      1.4779      2.4845      0.0000      0.0335
         100      0.7191      1.3604      2.2050      0.0000      0.0301
         110      0.7003      1.3611      2.1035      0.0003      0.0361
         120      0.7179      1.2808      2.2775      0.0008      0.0294
         130      0.7038      1.3149      2.1611      0.0000      0.0432
         140      0.7010      1.4080      2.0595      0.0000      0.0376
         150      0.7505      1.4487      2.2756      0.0000      0.0282
         160      0.6864      1.3129      2.0964      0.0000      0.0226
         170      0.6560      1.3580      1.8976      0.0000      0.0245
         180      0.6513      1.2955      1.9383      0.0009      0.0208
         190      0.7303      1.3679      2.2325      0.0000      0.0513
         200      0.6834      1.3809      2.0095      0.0000      0.0269
         210      0.6972      1.4143      2.0444      0.0000      0.0273
         220      0.6821      1.3695      2.0112      0.0001      0.0294
         230      0.6627      1.3758      1.9053      0.0039      0.0246
         240      0.6896      1.4004      2.0205      0.0000      0.0273
         250      0.6549      1.3519      1.8986      0.0000      0.0240
         260      0.7340      1.4505      2.1911      0.0000      0.0284
         270      0.6773      1.3588      1.9936      0.0000      0.0340
         280      0.6664      1.3784      1.9266      0.0001      0.0270
         290      0.6732      1.4118      1.9264      0.0000      0.0277
         300      0.6846      1.4342      1.9687      0.0000      0.0201
         310      0.6834      1.3883      1.9938      0.0000      0.0351
         320      0.6563      1.3549      1.9038      0.0000      0.0231
         330      0.6841      1.4833      1.9107      0.0000      0.0264
         340      0.6619      1.3731      1.9127      0.0000      0.0238
         350      0.6666      1.3874      1.9260      0.0000      0.0198
         360      0.6664      1.3830      1.9253      0.0000      0.0237
         370      0.6977      1.4061      2.0604      0.0000      0.0219
         380      0.6748      1.3700      1.9830      0.0000      0.0208
         390      0.6452      1.3046      1.8982      0.0000      0.0230
         400      0.6664      1.4047      1.8979      0.0000      0.0296
         410      0.6366      1.3013      1.8572      0.0000      0.0244
         420      0.6966      1.3328      2.1268      0.0000      0.0235
         430      0.6664      1.3780      1.9290      0.0000      0.0250
         440      0.6703      1.4046      1.9196      0.0000      0.0272
         450      0.6572      1.3684      1.8885      0.0000      0.0291
         460      0.6972      1.4124      2.0395      0.0000      0.0342
         470      0.6692      1.4172      1.9026      0.0000      0.0262
         480      0.6631      1.3654      1.9220      0.0000      0.0283
         490      0.6670      1.3775      1.9356      0.0000      0.0222
         500      0.6964      1.4670      1.9871      0.0000      0.0277
         510      0.6572      1.3580      1.9035      0.0000      0.0245
         520      0.6677      1.4153      1.8974      0.0000      0.0259
         530      0.6975      1.5119      1.9464      0.0000      0.0294
         540      0.6445      1.3071      1.8924      0.0000      0.0229
         550      0.6600      1.3804      1.8909      0.0000      0.0289
         560      0.6734      1.2934      2.0473      0.0000      0.0261
         570      0.6557      1.3494      1.9055      0.0000      0.0235
         580      0.6897      1.3710      2.0547      0.0000      0.0230
         590      0.7189      1.5203      2.0495      0.0000      0.0249
         600      0.6663      1.3161      1.9891      0.0000      0.0263
       final      0.6273      1.3415      1.7705      0.0000      0.0243
best loss step: 363
Max CUDA memory: 1.5754G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_78: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_78 in 16.93 minutes.

Generating sh3_r1_79, length 91...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.0138      1.7328      2.9523      0.1897      0.0047
          10      0.8873      1.6636      2.7440      0.0000      0.0291
          20      0.8694      1.6315      2.5612      0.0000      0.1540
          30      0.9595      1.5974      2.5755      0.0000      0.6247
          40      4.0759      1.6123      2.6264      0.0000     16.1408
          50      3.2870      1.6707      2.6372      2.1083      7.9105
          60      2.2574      1.6248      2.7012      0.0002      6.9608
          70      2.4981      1.6171      2.5104      0.0001      8.3629
          80      1.2217      1.6590      2.6267      0.8898      0.0433
          90      0.8845      1.6639      2.5763      0.0026      0.1770
         100      1.3912      1.6560      2.5549      1.2535      0.2380
         110      1.1189      1.6293      2.6417      0.6379      0.0476
         120      0.8720      1.6498      2.5623      0.0001      0.1475
         130      0.8371      1.6547      2.4460      0.0037      0.0773
         140      0.8458      1.6919      2.4354      0.0001      0.1014
         150      0.8276      1.6124      2.4117      0.0000      0.1140
         160      0.8242      1.6187      2.4496      0.0003      0.0521
         170      0.8729      1.6330      2.4216      0.1409      0.0284
         180      1.4409      1.6317      2.4756      1.5387      0.0200
         190      0.8467      1.5997      2.4900      0.0593      0.0252
         200      0.8297      1.6552      2.4619      0.0009      0.0295
         210      0.7855      1.5974      2.2756      0.0000      0.0545
         220      0.7966      1.6112      2.3160      0.0002      0.0552
         230      0.7918      1.5937      2.3041      0.0001      0.0609
         240      0.7891      1.5844      2.3091      0.0001      0.0519
         250      0.7531      1.5643      2.1244      0.0145      0.0475
         260      0.7334      1.5554      2.0436      0.0000      0.0681
         270      1.4966      1.6227      2.4925      0.0000      3.3678
         280      0.7781      1.5631      2.2821      0.0002      0.0449
         290      0.7523      1.5805      2.1325      0.0000      0.0483
         300      0.7564      1.6006      2.1142      0.0000      0.0673
         310      0.7437      1.5817      2.0843      0.0000      0.0523
         320      0.8472      1.5933      2.5405      0.0000      0.1020
         330      0.7232      1.5288      2.0347      0.0000      0.0526
         340      0.7345      1.5675      2.0526      0.0000      0.0526
         350      0.7201      1.5510      2.0051      0.0000      0.0442
         360      0.7502      1.5658      2.1340      0.0000      0.0512
         370      0.7471      1.5397      2.1426      0.0026      0.0480
         380      0.7631      1.5638      2.1968      0.0002      0.0545
         390      0.7264      1.5626      2.0196      0.0000      0.0497
         400      0.7553      1.5609      2.1668      0.0001      0.0486
         410      2.1941      1.5642      2.3840      0.0000      7.0222
         420      0.7649      1.5223      2.2608      0.0002      0.0408
         430      0.7678      1.5326      2.2524      0.0000      0.0541
         440      0.7269      1.5692      2.0013      0.0001      0.0637
         450      0.7126      1.5051      2.0037      0.0000      0.0543
         460      0.7257      1.5488      2.0316      0.0000      0.0482
         470      0.7336      1.5759      2.0389      0.0000      0.0530
         480      0.7400      1.5605      2.0805      0.0000      0.0590
         490      0.7315      1.5414      2.0625      0.0000      0.0537
         500      0.7045      1.5353      1.9110      0.0158      0.0446
         510      0.7595      1.5436      2.2171      0.0000      0.0366
         520      0.7221      1.5411      2.0226      0.0000      0.0468
         530      0.7228      1.5856      1.9580      0.0001      0.0704
         540      0.7211      1.5234      2.0252      0.0000      0.0568
         550      0.7068      1.5181      1.9649      0.0005      0.0500
         560      0.7332      1.5901      2.0164      0.0034      0.0529
         570      0.7541      1.5952      1.9611      0.0821      0.0500
         580      0.7052      1.5360      1.9395      0.0000      0.0505
         590      0.6893      1.5182      1.8832      0.0006      0.0439
         600      0.6956      1.5423      1.8917      0.0001      0.0437
       final      0.6893      1.5182      1.8832      0.0006      0.0439
best loss step: 590
Max CUDA memory: 1.4609G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_79: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_79 in 16.13 minutes.
