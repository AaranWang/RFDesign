/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[19:55:16] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 4, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_4, length 76...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.1079      1.6882      2.8999      0.0068      0.9375
          10      0.8605      1.8307      2.4248      0.0003      0.0467
          20      0.8439      1.7399      2.4574      0.0001      0.0222
          30      0.8190      1.7502      2.2160      0.0007      0.1273
          40      0.7766      1.6822      2.0847      0.0000      0.1160
          50      0.8026      1.7278      2.1924      0.0001      0.0925
          60      0.8599      1.7467      2.4294      0.0080      0.1072
          70      0.8233      1.7507      2.2969      0.0000      0.0688
          80      0.8327      1.6583      2.4284      0.0000      0.0767
          90      0.7935      1.7095      2.1773      0.0001      0.0805
         100      0.7939      1.6864      2.1999      0.0000      0.0834
         110      0.8136      1.6591      2.3302      0.0000      0.0787
         120      2.5177      1.8210      2.4425      0.0497      8.2258
         130      1.5038      1.7028      2.5531      1.5962      0.0709
         140      0.8239      1.6546      2.3942      0.0000      0.0708
         150      0.8204      1.6348      2.3283      0.0000      0.1389
         160      0.8031      1.7130      2.2320      0.0001      0.0703
         170      2.8880      1.6035      2.5948      0.0000     10.2416
         180      0.7763      1.5968      2.1792      0.0000      0.1055
         190      0.8366      1.6713      2.3953      0.0000      0.1165
         200      0.8548      1.7082      2.4928      0.0002      0.0725
         210      2.1820      1.6646      2.5800      0.0000      6.6654
         220      0.8772      1.7240      2.1829      0.2074      0.0643
         230      1.0156      1.7235      2.3623      0.4304      0.1312
         240      0.8527      1.6793      2.5122      0.0000      0.0720
         250      0.8131      1.6500      2.3924      0.0000      0.0229
         260      0.7986      1.6570      2.3085      0.0000      0.0275
         270      0.8006      1.7151      2.2634      0.0000      0.0246
         280      0.7938      1.6210      2.3047      0.0000      0.0433
         290      0.8150      1.6293      2.3948      0.0000      0.0508
         300      0.7823      1.6636      2.2071      0.0000      0.0409
         310      0.7482      1.6344      2.0611      0.0000      0.0452
         320      0.7977      1.6123      2.3381      0.0000      0.0382
         330      0.7309      1.5599      2.0419      0.0000      0.0525
         340      0.7419      1.5352      2.0915      0.0000      0.0829
         350      0.7820      1.5539      2.3109      0.0000      0.0451
         360      0.7683      1.6878      2.1062      0.0000      0.0475
         370      0.7391      1.5060      2.1198      0.0000      0.0697
         380      0.7160      1.5351      1.9876      0.0000      0.0574
         390      0.7193      1.4148      2.1128      0.0000      0.0690
         400      0.7305      1.5683      2.0321      0.0000      0.0522
         410      0.7489      1.6083      2.0888      0.0000      0.0474
         420      0.7609      1.5622      2.1791      0.0000      0.0629
         430      0.7402      1.5347      2.1083      0.0000      0.0581
         440      0.7289      1.5504      2.0450      0.0000      0.0490
         450      1.9520      1.5760      2.4050      0.0000      5.7790
         460      0.7452      1.5525      2.1076      0.0000      0.0657
         470      0.7426      1.5229      2.1243      0.0000      0.0657
         480      0.7218      1.5293      2.0051      0.0000      0.0744
         490      0.8722      1.5855      2.0018      0.3427      0.0884
         500      0.7307      1.5429      2.0471      0.0000      0.0637
         510      0.7469      1.5643      2.1104      0.0000      0.0597
         520      0.7249      1.5268      2.0526      0.0000      0.0453
         530      0.7159      1.4562      2.0506      0.0000      0.0728
         540      1.9605      1.5427      2.4793      0.0000      5.7807
         550      1.9625      1.5997      2.3974      0.0000      5.8154
         560      0.7877      1.5470      2.3190      0.0000      0.0726
         570      0.7402      1.5103      2.0970      0.0000      0.0935
         580      0.7415      1.5737      2.0739      0.0000      0.0601
         590      0.7365      1.5212      2.1033      0.0000      0.0580
         600      0.7761      1.5461      2.2654      0.0062      0.0564
       final      0.7057      1.4938      1.9732      0.0000      0.0614
best loss step: 392
Max CUDA memory: 1.0909G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_4: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_4 in 15.06 minutes.

Generating sh3_r1_5, length 74...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      2.7311      1.8384      2.8560      4.4728      0.0152
          10      0.8216      1.5080      2.2624      0.0000      0.3375
          20      0.8665      1.4650      2.4703      0.1435      0.1104
          30      0.8150      1.5428      2.4008      0.0000      0.1314
          40      0.7857      1.4599      2.3053      0.0000      0.1635
          50      0.7589      1.5276      2.1298      0.0000      0.1370
          60      0.7741      1.5203      2.2356      0.0000      0.1148
          70      0.7791      1.5601      2.2143      0.0000      0.1209
          80      0.7527      1.4064      2.2281      0.0001      0.1287
          90      0.7138      1.3824      2.0858      0.0013      0.0980
         100      0.7753      1.5467      2.2233      0.0000      0.1067
         110      2.2179      1.4316      2.4424      0.0000      7.2154
         120      0.7598      1.5426      2.1554      0.0000      0.1012
         130      0.7413      1.3414      2.2335      0.0002      0.1310
         140      1.9841      1.4364      2.5120      0.0000      5.9722
         150      0.7151      1.3928      2.0812      0.0002      0.1013
         160      0.7602      1.4973      2.2151      0.0018      0.0850
         170      0.7321      1.3898      2.1395      0.0013      0.1286
         180      0.7404      1.4093      2.1865      0.0000      0.1062
         190      0.7880      1.4266      2.3386      0.0000      0.1749
         200      0.7614      1.4776      2.2423      0.0000      0.0870
         210      0.7547      1.4714      2.1591      0.0238      0.0956
         220      0.7298      1.4609      2.0923      0.0000      0.0956
         230      0.7663      1.5430      2.2081      0.0002      0.0800
         240      0.7173      1.3624      2.1387      0.0000      0.0853
         250      0.7245      1.4886      2.0404      0.0000      0.0936
         260      0.7659      1.4723      2.2731      0.0005      0.0830
         270      0.7329      1.4121      2.1659      0.0000      0.0866
         280      0.7147      1.4334      2.0495      0.0000      0.0907
         290      0.6969      1.3684      2.0260      0.0001      0.0896
         300      0.7243      1.3866      2.1566      0.0013      0.0757
         310      0.7116      1.3950      2.0724      0.0006      0.0892
         320      0.7092      1.3939      2.0585      0.0010      0.0915
         330      0.7040      1.3948      2.0305      0.0000      0.0948
         340      0.6890      1.3572      1.9987      0.0000      0.0891
         350      0.7369      1.3818      2.2142      0.0001      0.0885
         360      0.7181      1.4101      2.0726      0.0139      0.0803
         370      0.7118      1.3699      2.1017      0.0000      0.0874
         380      0.7104      1.4381      2.0191      0.0001      0.0946
         390      0.6903      1.3809      1.9871      0.0008      0.0820
         400      0.7334      1.3836      2.1273      0.0401      0.0760
         410      0.7224      1.3821      2.1509      0.0009      0.0775
         420      0.7352      1.4527      2.1196      0.0000      0.1035
         430      0.7825      1.5104      2.3197      0.0001      0.0820
         440      0.7122      1.3655      2.1136      0.0000      0.0818
         450      0.7115      1.3708      2.0950      0.0001      0.0915
         460      0.7148      1.3995      2.0871      0.0003      0.0868
         470      0.7215      1.4201      2.0837      0.0000      0.1038
         480      0.7482      1.4139      2.2355      0.0077      0.0762
         490      0.6898      1.3780      1.9854      0.0012      0.0830
         500      0.7475      1.3781      2.2773      0.0002      0.0817
         510      0.8490      1.3902      2.4851      0.0786      0.2127
         520      0.7111      1.3273      2.1419      0.0000      0.0860
         530      0.6866      1.3688      1.9851      0.0000      0.0789
         540      0.6858      1.3458      2.0070      0.0001      0.0760
         550      0.7202      1.4414      2.0637      0.0001      0.0960
         560      0.7278      1.4364      2.1091      0.0000      0.0936
         570      0.7554      1.4281      2.2550      0.0000      0.0941
         580      0.7127      1.4287      2.0533      0.0006      0.0803
         590      0.7528      1.4300      2.2313      0.0000      0.1026
         600      0.7043      1.3747      2.0427      0.0000      0.1040
       final      0.6637      1.2810      1.9544      0.0002      0.0826
best loss step: 332
Max CUDA memory: 1.0466G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_5: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_5 in 16.10 minutes.
