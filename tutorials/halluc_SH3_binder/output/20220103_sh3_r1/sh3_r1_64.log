/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[21:24:22] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 64, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_64, length 86...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      0.9307      1.7311      2.8962      0.0084      0.0096
          10      0.9298      1.7954      2.6200      0.0005      0.2327
          20      0.9003      1.8093      2.6314      0.0000      0.0610
          30      0.8652      1.7131      2.5585      0.0033      0.0478
          40      1.1954      1.5361      2.3221      1.0362      0.0463
          50      1.4555      1.5469      2.4534      1.6141      0.0489
          60      1.1982      1.4664      2.3728      1.0585      0.0350
          70      0.8136      1.4955      2.2879      0.1070      0.0705
          80      0.7680      1.4737      2.2613      0.0000      0.1048
          90      0.7306      1.3674      2.1758      0.0348      0.0403
         100      0.7327      1.4155      2.1941      0.0020      0.0496
         110      0.7667      1.4334      2.3671      0.0001      0.0328
         120      0.7397      1.4019      2.1296      0.0627      0.0416
         130      1.3839      1.5210      2.1696      1.5899      0.0489
         140      0.7261      1.4091      2.1711      0.0077      0.0351
         150      0.7124      1.4076      2.0746      0.0199      0.0400
         160      0.7089      1.3615      2.1001      0.0215      0.0401
         170      0.7192      1.3571      2.1876      0.0003      0.0508
         180      0.7477      1.3715      2.2428      0.0420      0.0400
         190      0.7526      1.4014      2.0987      0.1132      0.0367
         200      0.7392      1.5263      2.1256      0.0000      0.0443
         210      1.4072      1.4353      2.1482      1.7045      0.0438
         220      0.7531      1.4196      2.2830      0.0000      0.0628
         230      0.7042      1.3284      2.1196      0.0052      0.0625
         240      0.7208      1.4056      2.0592      0.0486      0.0420
         250      0.7238      1.4135      2.1605      0.0000      0.0449
         260      0.7491      1.3477      2.0831      0.1347      0.0452
         270      0.7337      1.3100      2.0538      0.1298      0.0451
         280      0.7146      1.3361      2.1926      0.0002      0.0440
         290      0.7244      1.3615      2.1955      0.0083      0.0484
         300      0.6851      1.3165      2.0394      0.0016      0.0661
         310      0.6829      1.3542      2.0184      0.0004      0.0408
         320      0.6847      1.3581      2.0091      0.0023      0.0515
         330      0.7426      1.5124      2.1566      0.0000      0.0442
         340      0.6833      1.3161      1.9754      0.0303      0.0645
         350      0.6847      1.2856      2.0360      0.0264      0.0489
         360      0.6725      1.2851      2.0249      0.0004      0.0518
         370      0.7281      1.4814      2.1002      0.0000      0.0586
         380      0.6735      1.3062      2.0005      0.0003      0.0600
         390      0.7356      1.4545      2.1754      0.0000      0.0483
         400      0.6922      1.3726      2.0443      0.0000      0.0440
         410      0.7123      1.4238      2.0627      0.0181      0.0388
         420      0.6815      1.3226      1.9737      0.0249      0.0612
         430      0.6924      1.3626      2.0549      0.0000      0.0446
         440      0.7276      1.4309      2.0764      0.0443      0.0421
         450      0.7134      1.3582      2.1503      0.0000      0.0583
         460      0.7219      1.4243      2.1380      0.0000      0.0474
         470      0.6972      1.3870      2.0369      0.0000      0.0619
         480      0.6689      1.3291      1.9341      0.0182      0.0450
         490      0.6971      1.3703      2.0516      0.0000      0.0638
         500      0.6908      1.3174      2.0781      0.0002      0.0580
         510      0.7419      1.5997      2.0639      0.0000      0.0459
         520      0.6859      1.4131      1.9631      0.0000      0.0533
         530      0.7406      1.3708      2.2429      0.0025      0.0842
         540      0.7453      1.3608      2.1009      0.0928      0.0794
         550      0.6981      1.3557      2.0492      0.0000      0.0854
         560      0.7437      1.4499      2.1557      0.0000      0.1127
         570      0.7184      1.4902      2.0297      0.0134      0.0453
         580      1.2781      1.3700      2.3821      0.0000      2.6380
         590      0.7019      1.3859      2.0577      0.0123      0.0415
         600      0.7585      1.5134      2.2186      0.0000      0.0605
       final      0.6582      1.2520      1.9496      0.0192      0.0509
best loss step: 383
Max CUDA memory: 1.3285G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_64: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_64 in 15.01 minutes.

Generating sh3_r1_65, length 76...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.7889      1.7476      2.9795      2.0804      0.0568
          10      0.9119      1.6376      2.8953      0.0000      0.0264
          20      0.8761      1.6163      2.7337      0.0000      0.0304
          30      0.8883      1.7819      2.6183      0.0001      0.0412
          40      0.8234      1.4895      2.5794      0.0073      0.0335
          50      0.8348      1.5491      2.5873      0.0000      0.0375
          60      0.8201      1.4808      2.4815      0.0498      0.0387
          70      0.8392      1.6447      2.4931      0.0001      0.0581
          80      0.7933      1.4786      2.4415      0.0008      0.0448
          90      0.7923      1.4557      2.3835      0.0434      0.0354
         100      0.7997      1.5118      2.4453      0.0001      0.0415
         110      0.7994      1.5688      2.3832      0.0000      0.0448
         120      0.7984      1.4956      2.4454      0.0000      0.0512
         130      0.8102      1.5181      2.4482      0.0000      0.0849
         140      0.9209      1.5515      2.5955      0.0028      0.4521
         150      0.7954      1.4230      2.5037      0.0001      0.0502
         160      0.7713      1.4471      2.3022      0.0277      0.0518
         170      0.8610      1.4032      2.4968      0.0214      0.3622
         180      0.7584      1.4675      2.2819      0.0001      0.0427
         190      0.7956      1.6472      2.2960      0.0000      0.0347
         200      0.7930      1.4270      2.3625      0.0651      0.0455
         210      0.7547      1.4707      2.2618      0.0000      0.0408
         220      0.7353      1.4222      2.1750      0.0147      0.0501
         230      0.7371      1.3846      2.1449      0.0532      0.0495
         240      0.7175      1.3971      2.1461      0.0001      0.0439
         250      0.7263      1.4678      2.1064      0.0034      0.0506
         260      0.7230      1.4421      2.1131      0.0044      0.0512
         270      0.7150      1.4142      2.0881      0.0099      0.0531
         280      0.7672      1.4479      2.2276      0.0571      0.0461
         290      0.7137      1.4023      2.1146      0.0001      0.0513
         300      0.7335      1.5132      2.1097      0.0003      0.0439
         310      0.7291      1.3396      2.2439      0.0051      0.0517
         320      0.7340      1.5216      2.1033      0.0000      0.0448
         330      0.7288      1.3640      2.2202      0.0033      0.0532
         340      0.7525      1.4876      2.2132      0.0054      0.0510
         350      0.7328      1.4527      2.1666      0.0001      0.0444
         360      0.7529      1.4404      2.2457      0.0149      0.0486
         370      0.7717      1.3636      2.2981      0.0686      0.0596
         380      0.9758      1.4092      2.5320      0.0057      0.9262
         390      0.7229      1.4223      2.1413      0.0027      0.0458
         400      0.7804      1.4712      2.3907      0.0000      0.0404
         410      0.7408      1.4856      2.1472      0.0136      0.0441
         420      0.7038      1.4053      2.0661      0.0021      0.0437
         430      0.7274      1.4372      2.1414      0.0045      0.0492
         440      0.7331      1.4869      2.1335      0.0000      0.0451
         450      0.7973      1.3824      2.4949      0.0205      0.0683
         460      0.7323      1.4361      2.1744      0.0039      0.0431
         470      0.7037      1.4087      2.0576      0.0008      0.0505
         480      0.7414      1.4420      2.2114      0.0000      0.0536
         490      0.7449      1.5166      2.1607      0.0000      0.0470
         500      0.7473      1.4311      2.2436      0.0077      0.0464
         510      0.7342      1.3745      2.1785      0.0354      0.0473
         520      0.7808      1.4450      2.3324      0.0408      0.0452
         530      0.7264      1.3921      2.1856      0.0027      0.0490
         540      0.7609      1.4886      2.2713      0.0000      0.0447
         550      0.7109      1.3870      2.0961      0.0117      0.0479
         560      0.7693      1.3838      2.3308      0.0467      0.0383
         570      0.7258      1.4064      2.1837      0.0001      0.0390
         580      0.7183      1.3437      2.1896      0.0042      0.0497
         590      0.7221      1.3728      2.1917      0.0014      0.0432
         600      0.7268      1.4271      2.1556      0.0030      0.0452
       final      0.6871      1.3794      1.9982      0.0073      0.0434
best loss step: 586
Max CUDA memory: 1.1012G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_65: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_65 in 14.33 minutes.
