/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[21:00:11] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 58, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_58, length 56...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      0.9437      1.5739      2.7817      0.0000      0.3630
          10      1.0291      1.7376      2.6781      0.3631      0.0035
          20      0.8206      1.6762      2.4138      0.0000      0.0132
          30      1.1478      1.5544      2.6120      0.4939      0.5850
          40      0.8310      1.7083      2.3432      0.0000      0.1036
          50      1.7160      1.6272      2.4984      0.0000      4.4545
          60      0.8458      1.5712      2.4792      0.0000      0.1787
          70      0.7605      1.5571      2.0868      0.0000      0.1585
          80      0.7647      1.5403      2.1782      0.0000      0.1049
          90      0.8086      1.4575      2.4497      0.0000      0.1360
         100      0.7432      1.5214      2.0564      0.0000      0.1381
         110      0.7713      1.4788      2.2768      0.0000      0.1010
         120      0.7573      1.5082      2.1973      0.0000      0.0810
         130      0.7672      1.4414      2.2865      0.0000      0.1081
         140      0.7801      1.5406      2.2667      0.0000      0.0930
         150      0.7247      1.4187      2.0514      0.0031      0.1474
         160      0.7513      1.4519      2.1511      0.0000      0.1537
         170      0.7721      1.5543      2.2076      0.0000      0.0986
         180      0.7329      1.4468      2.1192      0.0004      0.0979
         190      0.7610      1.5586      2.1048      0.0200      0.1013
         200      0.7778      1.4791      2.2883      0.0000      0.1218
         210      0.7370      1.4328      2.1431      0.0000      0.1089
         220      0.8163      1.4681      2.4151      0.0000      0.1983
         230      0.8067      1.5693      2.3447      0.0000      0.1193
         240      0.7338      1.4475      2.1241      0.0000      0.0974
         250      0.7389      1.4850      2.0983      0.0000      0.1112
         260      0.7131      1.4192      2.0625      0.0000      0.0838
         270      0.7970      1.6089      2.0477      0.1208      0.0866
         280      0.7287      1.4855      2.0548      0.0000      0.1031
         290      0.7330      1.5050      2.0749      0.0000      0.0852
         300      0.7540      1.4766      2.1761      0.0000      0.1175
         310      0.7353      1.5247      2.0868      0.0000      0.0650
         320      0.7417      1.4597      2.1819      0.0000      0.0668
         330      0.7274      1.4337      2.0952      0.0000      0.1083
         340      0.7149      1.4404      2.0082      0.0061      0.1139
         350      0.7348      1.4114      2.1660      0.0000      0.0965
         360      0.7324      1.4758      2.0949      0.0000      0.0912
         370      0.7949      1.6220      2.2303      0.0011      0.1201
         380      0.8217      1.4745      2.5043      0.0000      0.1297
         390      0.7257      1.4669      2.0927      0.0000      0.0687
         400      0.7277      1.4586      2.0738      0.0020      0.1020
         410      0.7163      1.4183      2.0652      0.0000      0.0979
         420      0.7494      1.4413      2.1655      0.0132      0.1138
         430      0.7103      1.3927      2.0732      0.0000      0.0855
         440      0.7767      1.5218      2.2922      0.0000      0.0693
         450      0.7408      1.5434      2.0652      0.0000      0.0954
         460      0.7491      1.5135      2.1227      0.0000      0.1093
         470      0.7492      1.4691      2.1872      0.0001      0.0896
         480      0.7442      1.4955      2.1413      0.0021      0.0802
         490      0.7595      1.5286      2.1723      0.0000      0.0966
         500      0.7306      1.4613      2.0931      0.0000      0.0983
         510      0.7260      1.4897      2.0499      0.0000      0.0903
         520      0.7654      1.5225      2.1790      0.0163      0.0930
         530      0.7288      1.4666      2.0803      0.0000      0.0969
         540      0.7535      1.4455      2.1744      0.0147      0.1183
         550      0.7818      1.6116      2.1777      0.0000      0.1195
         560      0.8022      1.5068      2.4040      0.0000      0.1001
         570      0.7149      1.4392      2.0548      0.0000      0.0806
         580      0.7570      1.5076      2.1745      0.0029      0.0970
         590      0.7358      1.4528      2.1367      0.0000      0.0896
         600      0.7914      1.5446      2.3749      0.0000      0.0377
       final      0.7001      1.3585      2.0372      0.0000      0.1049
best loss step: 161
Max CUDA memory: 0.7116G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_58: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_58 in 14.73 minutes.

Generating sh3_r1_59, length 99...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.0561      1.7594      2.9197      0.0001      0.6014
          10      0.9069      1.6024      2.8484      0.0018      0.0799
          20      0.8999      1.5925      2.8798      0.0000      0.0272
          30      0.9957      1.5930      2.8543      0.1149      0.3016
          40      1.6980      1.6241      2.7991      2.0307      0.0056
          50      1.3891      1.6492      2.8992      1.1954      0.0063
          60      1.3428      1.6838      2.8785      1.0729      0.0061
          70      0.9254      1.6847      2.9300      0.0001      0.0120
          80      1.3582      1.6209      2.9116      1.1248      0.0090
          90      1.2592      1.6132      2.8683      0.8972      0.0197
         100      1.0588      1.6195      2.8729      0.2873      0.2271
         110      0.9132      1.5977      2.8146      0.0000      0.1537
         120      0.9265      1.6208      2.8119      0.0654      0.0691
         130      1.9963      1.5982      2.8016      2.7781      0.0257
         140      0.8861      1.6275      2.7725      0.0000      0.0303
         150      0.8839      1.6286      2.7767      0.0001      0.0137
         160      0.9161      1.5621      2.8015      0.0000      0.2170
         170      0.8900      1.5644      2.7479      0.0171      0.1031
         180      0.8796      1.6029      2.7846      0.0000      0.0107
         190      1.5998      1.7571      2.6669      1.7791      0.0169
         200      0.8799      1.6433      2.7185      0.0000      0.0377
         210      0.8943      1.6221      2.7901      0.0000      0.0595
         220      1.1092      1.6018      2.7861      0.0925      0.9733
         230      0.8827      1.6479      2.7471      0.0049      0.0087
         240      0.8927      1.6584      2.7677      0.0001      0.0372
         250      0.8834      1.6024      2.7839      0.0000      0.0308
         260      1.0223      1.5250      2.7210      0.0000      0.8656
         270      0.9295      1.6173      2.8170      0.0000      0.2134
         280      0.8603      1.6252      2.6517      0.0000      0.0248
         290      0.8114      1.6419      2.3909      0.0000      0.0242
         300      1.5729      1.6289      2.6195      1.4339      0.7481
         310      0.9040      1.6120      2.7043      0.0000      0.2040
         320      0.9272      1.5974      2.5803      0.0000      0.4581
         330      0.8291      1.6163      2.5051      0.0000      0.0241
         340      0.7623      1.5297      2.2606      0.0000      0.0214
         350      0.7627      1.5187      2.2727      0.0000      0.0221
         360      0.8037      1.6769      2.2867      0.0000      0.0551
         370      0.7895      1.5647      2.3634      0.0000      0.0195
         380      0.7552      1.5111      2.2456      0.0000      0.0193
         390      0.7503      1.4660      2.2641      0.0000      0.0216
         400      0.7024      1.4235      2.0716      0.0000      0.0170
         410      0.8291      1.5714      2.5591      0.0000      0.0148
         420      0.7641      1.5346      2.2636      0.0000      0.0226
         430      0.7588      1.4992      2.2672      0.0000      0.0278
         440      0.7950      1.4568      2.4580      0.0000      0.0600
         450      0.7790      1.5472      2.3261      0.0000      0.0217
         460      0.8103      1.6364      2.3849      0.0002      0.0299
         470      0.8374      1.6424      2.5291      0.0000      0.0153
         480      0.7087      1.4512      2.0727      0.0000      0.0198
         490      0.8966      1.6082      2.6268      0.1177      0.0126
         500      0.7611      1.5007      2.2849      0.0000      0.0196
         510      0.8049      1.5514      2.4590      0.0000      0.0140
         520      0.8236      1.5685      2.5298      0.0008      0.0182
         530      0.8284      1.5812      2.5368      0.0000      0.0237
         540      0.8218      1.6208      2.4581      0.0045      0.0211
         550      0.7527      1.5057      2.2297      0.0000      0.0283
         560      0.7478      1.5322      2.1804      0.0000      0.0262
         570      0.7609      1.5583      2.2253      0.0009      0.0191
         580      0.7267      1.5222      2.0879      0.0002      0.0231
         590      0.8002      1.5590      2.4103      0.0050      0.0216
         600      1.2849      1.5821      2.5007      0.0000      2.3419
       final      0.7024      1.4235      2.0716      0.0000      0.0170
best loss step: 400
Max CUDA memory: 1.6758G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_59: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_59 in 17.75 minutes.
