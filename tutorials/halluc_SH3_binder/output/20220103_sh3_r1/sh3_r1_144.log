/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[23:21:26] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 144, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_144, length 63...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.9530      1.7727      2.9660      0.0000      5.0264
          10      1.0178      1.6032      2.8085      0.0000      0.6776
          20      1.0053      1.6592      2.8590      0.2529      0.0026
          30      0.9548      1.6470      2.7912      0.1630      0.0097
          40      0.9380      1.6135      2.7487      0.1601      0.0076
          50      0.8700      1.6007      2.7357      0.0016      0.0105
          60      0.8523      1.6920      2.5620      0.0001      0.0073
          70      0.8153      1.6121      2.4513      0.0002      0.0129
          80      0.8866      1.5324      2.5220      0.1851      0.0083
          90      0.7857      1.4668      2.4410      0.0000      0.0205
         100      0.8442      1.6439      2.5536      0.0000      0.0236
         110      0.8032      1.5369      2.4414      0.0000      0.0379
         120      0.8193      1.5219      2.5255      0.0000      0.0490
         130      0.7422      1.4213      2.2618      0.0000      0.0276
         140      0.7447      1.4308      2.2733      0.0000      0.0194
         150      0.7769      1.4601      2.4028      0.0000      0.0216
         160      0.8071      1.5408      2.4542      0.0000      0.0405
         170      0.8739      1.5565      2.7697      0.0000      0.0434
         180      2.1866      1.4110      2.6695      0.0000      6.8524
         190      0.8498      1.4610      2.7453      0.0093      0.0243
         200      0.7657      1.4544      2.3418      0.0000      0.0323
         210      0.7985      1.5049      2.4684      0.0000      0.0190
         220      0.8961      1.5738      2.6852      0.0000      0.2215
         230      1.2588      1.5718      2.6636      1.0197      0.0191
         240      0.8484      1.5137      2.5734      0.0000      0.1549
         250      0.8721      1.4443      2.2972      0.2841      0.0510
         260      0.8000      1.4809      2.3898      0.0369      0.0553
         270      0.8352      1.5109      2.4188      0.0881      0.0701
         280      0.7594      1.4650      2.2747      0.0000      0.0576
         290      0.7850      1.4891      2.3907      0.0000      0.0453
         300      0.8181      1.5009      2.5219      0.0013      0.0649
         310      0.7800      1.4380      2.3944      0.0000      0.0675
         320      0.7976      1.4818      2.4449      0.0007      0.0597
         330      0.7779      1.4201      2.1229      0.1369      0.0726
         340      0.7932      1.5217      2.3707      0.0000      0.0737
         350      0.7171      1.3346      2.1819      0.0000      0.0690
         360      0.7886      1.5389      2.3391      0.0006      0.0635
         370      0.7064      1.3736      2.1200      0.0004      0.0376
         380      0.7509      1.4183      2.3009      0.0000      0.0354
         390      0.7754      1.4263      2.3559      0.0181      0.0588
         400      0.7554      1.4713      2.2670      0.0000      0.0385
         410      0.7977      1.4952      2.4182      0.0000      0.0749
         420      0.7515      1.4346      2.2615      0.0000      0.0612
         430      0.8050      1.4871      2.4628      0.0000      0.0751
         440      0.7943      1.5313      2.3397      0.0000      0.1005
         450      0.8132      1.5279      2.3617      0.0000      0.1766
         460      0.7300      1.4318      2.1490      0.0001      0.0690
         470      0.8425      1.5315      2.4366      0.0000      0.2443
         480      0.7444      1.4217      2.2349      0.0076      0.0504
         490      0.7610      1.4390      2.2851      0.0001      0.0806
         500      0.7568      1.4509      2.2867      0.0038      0.0388
         510      0.7734      1.4321      2.1846      0.0848      0.0809
         520      0.7639      1.4687      2.2860      0.0002      0.0645
         530      0.7837      1.4806      2.3331      0.0000      0.1046
         540      0.7206      1.3741      2.1580      0.0001      0.0707
         550      0.7500      1.4245      2.2443      0.0022      0.0767
         560      0.7391      1.3685      2.2024      0.0286      0.0673
         570      0.8610      1.5239      2.5809      0.0000      0.2002
         580      0.8034      1.5251      2.3361      0.0322      0.0916
         590      0.7424      1.4439      2.1982      0.0000      0.0699
         600      0.7970      1.4929      2.3997      0.0000      0.0921
       final      0.7017      1.3323      2.1127      0.0116      0.0401
best loss step: 371
Max CUDA memory: 0.8328G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_144: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_144 in 14.05 minutes.

Generating sh3_r1_145, length 91...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.9494      1.7628      2.8855      0.0000      5.0985
          10      0.9860      1.6805      2.9316      0.0000      0.3180
          20      0.9246      1.6717      2.9238      0.0000      0.0277
          30      0.9031      1.6314      2.8769      0.0000      0.0071
          40      0.8745      1.5310      2.8285      0.0000      0.0131
          50      0.9241      1.5388      2.9079      0.0810      0.0115
          60      0.9057      1.6136      2.9068      0.0000      0.0083
          70      1.0542      1.5953      2.8641      0.0000      0.8117
          80      1.6736      1.5992      2.9176      0.6736      2.5038
          90      0.9009      1.6120      2.8780      0.0000      0.0146
         100      1.3352      1.5591      2.8649      1.1135      0.0253
         110      0.8929      1.5620      2.7891      0.0427      0.0280
         120      1.2411      1.5372      2.8360      0.8994      0.0335
         130      0.8445      1.5195      2.6631      0.0103      0.0194
         140      0.8970      1.5976      2.8115      0.0083      0.0595
         150      1.0398      1.5585      2.7419      0.4383      0.0223
         160      0.9335      1.5899      2.7356      0.1412      0.0598
         170      0.8323      1.5751      2.5461      0.0001      0.0403
         180      0.8087      1.5538      2.4392      0.0000      0.0505
         190      0.7776      1.4259      2.3285      0.0044      0.1251
         200      0.8094      1.5574      2.4445      0.0000      0.0453
         210      0.8895      1.5399      2.6269      0.0161      0.2486
         220      0.7675      1.5250      2.2018      0.0260      0.0584
         230      0.7797      1.5331      2.3120      0.0000      0.0535
         240      0.7623      1.4895      2.2246      0.0000      0.0975
         250      0.8400      1.5942      2.1631      0.1953      0.0522
         260      0.9533      1.4673      2.2672      0.4841      0.0637
         270      0.8419      1.5902      2.4571      0.0588      0.0444
         280      0.8034      1.4970      2.4760      0.0000      0.0441
         290      0.7365      1.3779      2.2522      0.0041      0.0444
         300      0.6969      1.4146      2.0273      0.0000      0.0428
         310      0.7388      1.4985      2.1425      0.0000      0.0530
         320      0.7206      1.4799      2.0590      0.0007      0.0628
         330      0.6952      1.3695      2.0639      0.0000      0.0424
         340      0.7288      1.4257      2.1718      0.0000      0.0465
         350      0.7037      1.4028      2.0654      0.0005      0.0490
         360      0.9375      1.4731      2.2226      0.4729      0.0463
         370      0.7948      1.4232      2.2823      0.1077      0.0531
         380      0.7650      1.4797      2.2869      0.0000      0.0583
         390      0.7153      1.3992      2.1314      0.0000      0.0462
         400      0.7188      1.4564      2.0859      0.0000      0.0517
         410      0.6968      1.3659      2.0701      0.0000      0.0482
         420      0.7199      1.4266      2.1171      0.0000      0.0558
         430      0.7146      1.4510      2.0623      0.0000      0.0598
         440      0.6712      1.3311      1.9736      0.0000      0.0514
         450      0.6626      1.3162      1.9519      0.0000      0.0449
         460      0.7329      1.4685      2.1451      0.0000      0.0507
         470      0.7148      1.3675      2.1627      0.0000      0.0437
         480      0.7018      1.4313      2.0296      0.0000      0.0483
         490      0.6942      1.4191      2.0002      0.0000      0.0518
         500      0.7245      1.4337      2.1337      0.0010      0.0529
         510      0.7063      1.3950      2.0817      0.0000      0.0550
         520      0.7072      1.3547      2.1247      0.0000      0.0565
         530      0.7310      1.4509      2.1569      0.0000      0.0472
         540      0.7453      1.5117      2.1589      0.0000      0.0559
         550      0.6797      1.3378      2.0145      0.0000      0.0464
         560      0.7621      1.4882      2.2475      0.0045      0.0657
         570      0.7081      1.4037      2.0872      0.0000      0.0494
         580      0.7078      1.4133      2.0782      0.0000      0.0478
         590      0.7298      1.4846      2.1138      0.0000      0.0505
         600      0.7224      1.4548      2.1112      0.0000      0.0457
       final      0.6626      1.3162      1.9519      0.0000      0.0449
best loss step: 450
Max CUDA memory: 1.4583G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_145: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_145 in 15.62 minutes.
