/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[23:36:07] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 154, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_154, length 61...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.5032      1.7704      2.9501      1.3706      0.0541
          10      1.0346      1.6625      2.8510      0.0138      0.6319
          20      1.0893      1.6826      2.8234      0.0000      0.9405
          30      0.8659      1.6410      2.6806      0.0000      0.0081
          40      0.9427      1.6325      2.8283      0.0000      0.2526
          50      1.0652      1.6007      2.7786      0.4070      0.1329
          60      0.9314      1.7590      2.8802      0.0064      0.0051
          70      1.6358      1.6072      2.8621      1.8340      0.0416
          80      0.8614      1.5071      2.7641      0.0000      0.0358
          90      0.8154      1.5568      2.4591      0.0000      0.0610
         100      0.8155      1.6498      2.4195      0.0000      0.0083
         110      0.8488      1.6410      2.5634      0.0005      0.0386
         120      1.1802      1.5567      2.5511      0.0000      1.7931
         130      1.4482      1.6513      2.6331      0.0000      2.9567
         140      0.9467      1.6704      2.3470      0.3534      0.0093
         150      0.9016      1.5881      2.3897      0.2605      0.0089
         160      0.8341      1.5722      2.4329      0.0790      0.0076
         170      1.4470      1.6178      2.3799      1.6150      0.0072
         180      0.8220      1.6989      2.4046      0.0000      0.0063
         190      0.8396      1.6164      2.4955      0.0229      0.0405
         200      0.8199      1.5564      2.5153      0.0000      0.0277
         210      0.8144      1.5766      2.4847      0.0000      0.0106
         220      0.7783      1.5138      2.3554      0.0000      0.0222
         230      0.8072      1.5370      2.3730      0.0565      0.0129
         240      0.7883      1.6237      2.2885      0.0003      0.0290
         250      0.7696      1.6040      2.2271      0.0001      0.0165
         260      0.7871      1.5499      2.3471      0.0101      0.0186
         270      0.7893      1.5659      2.3694      0.0000      0.0110
         280      0.7766      1.6291      2.2334      0.0001      0.0205
         290      0.7758      1.4999      2.3557      0.0000      0.0235
         300      0.7893      1.5568      2.3395      0.0173      0.0156
         310      0.7973      1.6081      2.3402      0.0008      0.0366
         320      1.1132      1.5437      2.3986      0.7847      0.0540
         330      0.7877      1.5898      2.3364      0.0000      0.0121
         340      1.0454      1.5587      2.5574      0.0000      1.1107
         350      1.1118      1.5825      2.4767      0.0000      1.4999
         360      1.0598      1.5929      2.5454      0.0000      1.1604
         370      0.9783      1.5177      2.5102      0.0000      0.8637
         380      0.9707      1.6379      2.6017      0.0001      0.6139
         390      0.8977      1.5512      2.5156      0.0001      0.4217
         400      0.8814      1.6380      2.6142      0.0000      0.1549
         410      0.9637      1.6508      2.6323      0.0000      0.5353
         420      0.9355      1.6546      2.6339      0.0000      0.3891
         430      0.9165      1.6715      2.5534      0.0000      0.3577
         440      0.8553      1.6483      2.4533      0.0000      0.1750
         450      0.9412      1.6771      2.5495      0.0000      0.4796
         460      0.9579      1.7263      2.5509      0.0000      0.5123
         470      0.8913      1.7666      2.5052      0.0000      0.1848
         480      0.9126      1.7228      2.5820      0.0000      0.2580
         490      0.8921      1.7224      2.5495      0.0000      0.1883
         500      0.8940      1.8338      2.4989      0.0001      0.1372
         510      0.8520      1.7642      2.3343      0.0003      0.1608
         520      0.9128      1.7184      2.5815      0.0000      0.2642
         530      0.8690      1.7515      2.3990      0.0307      0.1330
         540      0.8832      1.7210      2.4873      0.0000      0.2077
         550      0.9312      1.6004      2.4586      0.0001      0.5968
         560      0.9348      1.7500      2.7542      0.0002      0.1692
         570      0.8635      1.6769      2.6085      0.0001      0.0320
         580      0.8841      1.6959      2.4901      0.0218      0.1908
         590      0.8497      1.6531      2.4116      0.0001      0.1837
         600      0.8837      1.6796      2.5487      0.0002      0.1901
       final      0.7281      1.4796      2.1391      0.0000      0.0216
best loss step: 312
Max CUDA memory: 0.7923G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_154: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_154 in 14.25 minutes.

Generating sh3_r1_155, length 92...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.6165      1.6758      2.9422      1.4541      0.5563
          10      1.4792      1.7558      2.9051      1.3502      0.0347
          20      0.9508      1.7999      2.8367      0.0017      0.1137
          30      0.9207      1.7416      2.8442      0.0001      0.0174
          40      1.1871      1.6478      2.7415      0.2943      0.9576
          50      1.7795      1.5812      2.5396      0.0000      4.7770
          60      0.7747      1.4641      2.3604      0.0000      0.0491
          70      0.9646      1.5174      2.6748      0.0000      0.6310
          80      0.7322      1.4216      2.1824      0.0000      0.0571
          90      0.7509      1.4282      2.2854      0.0000      0.0409
         100      0.7353      1.3803      2.1793      0.0000      0.1169
         110      0.7354      1.4272      2.2017      0.0000      0.0480
         120      2.4661      1.3916      2.3816      0.0007      8.5561
         130      0.7618      1.4684      2.2675      0.0000      0.0730
         140      0.7258      1.3994      2.1597      0.0004      0.0693
         150      0.7201      1.4034      2.1334      0.0000      0.0638
         160      0.6747      1.3636      1.9375      0.0000      0.0724
         170      0.7177      1.3924      2.0831      0.0188      0.0754
         180      0.7065      1.4372      2.0124      0.0007      0.0812
         190      0.7223      1.4479      2.0710      0.0171      0.0586
         200      0.6839      1.3630      1.9873      0.0000      0.0693
         210      0.6833      1.3258      2.0121      0.0000      0.0787
         220      0.7217      1.4186      2.0881      0.0139      0.0741
         230      0.7574      1.4346      2.2867      0.0002      0.0650
         240      0.7162      1.4534      2.0461      0.0067      0.0684
         250      0.8179      1.6082      2.3853      0.0002      0.0959
         260      0.7212      1.4341      2.0942      0.0004      0.0768
         270      0.7063      1.4340      2.0261      0.0015      0.0681
         280      0.7329      1.4633      2.1214      0.0078      0.0640
         290      0.7203      1.4769      2.0308      0.0075      0.0786
         300      0.9825      1.5840      2.4147      0.0000      0.9137
         310      0.7294      1.4370      2.1437      0.0000      0.0665
         320      0.7190      1.4158      2.1025      0.0000      0.0767
         330      0.7087      1.3806      2.0436      0.0247      0.0701
         340      0.7841      1.4870      2.0751      0.1395      0.0795
         350      0.7254      1.5358      2.0252      0.0000      0.0661
         360      0.6867      1.3801      1.9851      0.0000      0.0685
         370      0.7234      1.4789      1.9190      0.0829      0.0535
         380      2.6704      1.4542      2.4876      0.1127      9.1848
         390      0.7052      1.4264      2.0249      0.0000      0.0748
         400      0.7191      1.4337      1.9585      0.0759      0.0515
         410      0.8925      1.6199      2.4039      0.0011      0.4365
         420      0.7092      1.3901      2.0873      0.0000      0.0686
         430      0.7100      1.4228      2.0533      0.0002      0.0734
         440      0.7016      1.3751      2.0821      0.0000      0.0510
         450      0.7387      1.3768      2.0533      0.1040      0.0554
         460      0.7265      1.3794      2.1918      0.0000      0.0614
         470      0.7361      1.4350      2.1808      0.0000      0.0645
         480      0.6884      1.3835      1.9900      0.0000      0.0686
         490      0.6874      1.4194      1.9413      0.0023      0.0719
         500      0.7166      1.4234      2.0845      0.0103      0.0544
         510      0.6956      1.3686      2.0461      0.0000      0.0634
         520      0.7396      1.5065      2.1223      0.0000      0.0693
         530      0.6961      1.4058      2.0047      0.0010      0.0680
         540      0.7150      1.4518      2.0582      0.0000      0.0651
         550      0.7199      1.5329      1.9992      0.0000      0.0675
         560      0.7013      1.4125      2.0231      0.0000      0.0707
         570      0.7091      1.3625      2.0971      0.0000      0.0858
         580      0.7057      1.3820      2.0493      0.0142      0.0687
         590      0.7229      1.4577      2.0891      0.0000      0.0676
         600      0.7082      1.3596      2.1099      0.0052      0.0612
       final      0.6645      1.3347      1.9226      0.0000      0.0651
best loss step: 501
Max CUDA memory: 1.4863G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_155: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_155 in 15.76 minutes.
