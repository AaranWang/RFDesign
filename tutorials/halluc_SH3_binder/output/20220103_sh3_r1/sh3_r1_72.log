/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[21:30:39] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 72, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_72, length 93...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.0496      1.8599      2.9786      0.0001      0.4095
          10      1.2185      1.5517      2.9178      0.7487      0.1255
          20      1.0239      1.6671      2.9339      0.0000      0.5186
          30      1.2578      1.5717      2.9187      0.7775      0.2435
          40      0.9949      1.6195      2.8839      0.2260      0.0193
          50      1.5048      1.5763      2.8780      1.5269      0.0160
          60      0.9020      1.6319      2.8664      0.0000      0.0116
          70      1.2108      1.5934      2.8563      0.7955      0.0135
          80      1.0550      1.5704      2.8367      0.4272      0.0134
          90      1.5259      1.6574      2.8451      1.5612      0.0046
         100      1.4362      1.6376      2.7731      1.3790      0.0122
         110      1.3401      1.6009      2.8720      1.1013      0.0251
         120      0.9194      1.5741      2.7905      0.1018      0.0285
         130      1.0321      1.5605      2.8317      0.3797      0.0092
         140      1.3147      1.7198      2.8341      0.9928      0.0339
         150      1.8183      1.7161      2.8063      2.2804      0.0081
         160      1.2831      1.7101      2.7720      0.9601      0.0133
         170      1.6844      1.6418      2.8443      1.9655      0.0047
         180      0.9188      1.6780      2.9093      0.0006      0.0057
         190      1.3666      1.6155      2.9096      1.1491      0.0099
         200      0.9990      1.5762      2.7582      0.3272      0.0061
         210      0.9000      1.5991      2.7263      0.0796      0.0153
         220      0.8357      1.5528      2.5499      0.0178      0.0403
         230      0.8310      1.5838      2.5296      0.0000      0.0414
         240      0.7623      1.4717      2.2832      0.0000      0.0568
         250      0.8714      1.5752      2.5867      0.0821      0.0310
         260      0.7608      1.4231      2.3197      0.0000      0.0613
         270      0.7143      1.4105      2.1048      0.0000      0.0563
         280      0.7468      1.4433      2.2289      0.0000      0.0615
         290      0.7281      1.3767      2.1979      0.0028      0.0604
         300      0.7672      1.4337      2.3316      0.0011      0.0684
         310      0.7187      1.4268      2.1080      0.0009      0.0570
         320      0.7681      1.3728      2.4093      0.0000      0.0584
         330      0.7067      1.3575      2.1105      0.0001      0.0655
         340      0.7393      1.3114      2.3065      0.0056      0.0673
         350      0.7879      1.3577      2.5111      0.0178      0.0349
         360      0.8346      1.5030      2.5737      0.0236      0.0490
         370      0.7348      1.4049      2.2013      0.0006      0.0665
         380      0.7693      1.3740      2.3700      0.0172      0.0679
         390      0.7721      1.4493      2.2574      0.0437      0.0662
         400      0.6936      1.3512      2.0387      0.0106      0.0571
         410      0.7953      1.4246      2.4687      0.0144      0.0541
         420      0.7642      1.3911      2.3773      0.0002      0.0523
         430      0.7191      1.4407      2.1091      0.0000      0.0458
         440      0.7641      1.4372      2.3478      0.0000      0.0354
         450      0.7205      1.4076      2.1319      0.0026      0.0578
         460      0.7084      1.4168      2.0742      0.0000      0.0507
         470      0.7251      1.3834      2.1878      0.0000      0.0544
         480      0.8006      1.5200      2.3769      0.0347      0.0371
         490      0.7872      1.5098      2.3714      0.0001      0.0547
         500      0.7397      1.4103      2.2010      0.0201      0.0470
         510      0.7414      1.4433      2.2233      0.0000      0.0404
         520      0.7123      1.4015      2.1052      0.0000      0.0547
         530      0.7112      1.3096      2.1564      0.0202      0.0494
         540      0.7951      1.5609      2.3216      0.0009      0.0914
         550      0.7385      1.4070      2.2115      0.0099      0.0542
         560      0.7081      1.3878      2.1129      0.0010      0.0379
         570      0.7462      1.4509      2.2368      0.0003      0.0425
         580      0.8133      1.5294      2.5044      0.0000      0.0327
         590      0.7081      1.4003      2.0915      0.0005      0.0474
         600      0.7126      1.3461      2.1580      0.0002      0.0584
       final      0.6852      1.2523      2.1116      0.0007      0.0609
best loss step: 577
Max CUDA memory: 1.5123G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_72: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_72 in 15.99 minutes.

Generating sh3_r1_73, length 62...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      2.5673      1.7854      2.8346      0.0000      8.2165
          10      0.8107      1.5230      2.5124      0.0000      0.0179
          20      0.8416      1.5759      2.5878      0.0000      0.0441
          30      0.9905      1.5394      2.6834      0.3260      0.0779
          40      0.8751      1.5924      2.7463      0.0000      0.0370
          50      0.8415      1.5193      2.6681      0.0000      0.0198
          60      0.8393      1.5274      2.5839      0.0000      0.0852
          70      0.8417      1.4366      2.6486      0.0037      0.1159
          80      0.8243      1.4859      2.4989      0.0000      0.1368
          90      0.8692      1.5633      2.6787      0.0000      0.1041
         100      0.8215      1.5601      2.5246      0.0000      0.0229
         110      0.8679      1.6319      2.6828      0.0000      0.0248
         120      0.8009      1.4567      2.5309      0.0000      0.0168
         130      0.8085      1.4943      2.5309      0.0000      0.0176
         140      0.8013      1.5844      2.4025      0.0001      0.0194
         150      0.8049      1.5269      2.4791      0.0000      0.0184
         160      0.7797      1.5032      2.3767      0.0000      0.0188
         170      0.8576      1.6222      2.6511      0.0000      0.0147
         180      0.8386      1.5464      2.5383      0.0000      0.1085
         190      1.9915      1.6970      2.5464      0.0000      5.7140
         200      0.7779      1.4965      2.2794      0.0000      0.1136
         210      0.8198      1.5431      2.4582      0.0000      0.0977
         220      0.8477      1.6054      2.4945      0.0000      0.1388
         230      0.8326      1.5394      2.5264      0.0002      0.0969
         240      0.8642      1.6411      2.5738      0.0000      0.1060
         250      0.8460      1.6865      2.4287      0.0000      0.1147
         260      0.8052      1.5270      2.3994      0.0000      0.0994
         270      0.8564      1.6340      2.5236      0.0000      0.1243
         280      1.0497      1.6598      2.6051      0.0000      0.9836
         290      0.7978      1.5425      2.3479      0.0000      0.0989
         300      0.8257      1.5120      2.5095      0.0000      0.1070
         310      0.7941      1.5534      2.3104      0.0000      0.1064
         320      0.7655      1.4845      2.2608      0.0000      0.0821
         330      0.8118      1.5477      2.4376      0.0012      0.0714
         340      0.7999      1.5293      2.3723      0.0000      0.0979
         350      0.8114      1.5077      2.4481      0.0000      0.1014
         360      0.7878      1.4893      2.3424      0.0000      0.1072
         370      0.8032      1.4982      2.4230      0.0000      0.0947
         380      0.8068      1.5379      2.3902      0.0000      0.1059
         390      0.8125      1.5173      2.3735      0.0443      0.0830
         400      0.7843      1.5121      2.3041      0.0000      0.1054
         410      0.8132      1.5243      2.4381      0.0019      0.0999
         420      0.8134      1.4793      2.3193      0.0915      0.0850
         430      0.8106      1.5531      2.4150      0.0000      0.0849
         440      0.8043      1.5260      2.3978      0.0000      0.0976
         450      0.8090      1.5358      2.4056      0.0008      0.1019
         460      0.7822      1.5075      2.3166      0.0001      0.0869
         470      0.8229      1.5170      2.3958      0.0576      0.0864
         480      0.8148      1.4906      2.2843      0.0976      0.1041
         490      0.7855      1.5212      2.3233      0.0000      0.0830
         500      0.7576      1.4212      2.2157      0.0235      0.1043
         510      0.7824      1.5376      2.2442      0.0176      0.0949
         520      0.7893      1.5093      2.3476      0.0005      0.0887
         530      0.8096      1.5128      2.3116      0.0574      0.1087
         540      0.7804      1.4563      2.3469      0.0012      0.0964
         550      0.7815      1.4611      2.3253      0.0003      0.1203
         560      0.7671      1.4491      2.2833      0.0010      0.1011
         570      0.7764      1.4888      2.3065      0.0000      0.0868
         580      0.8147      1.5209      2.4521      0.0000      0.1007
         590      0.7733      1.5130      2.2613      0.0000      0.0924
         600      0.7655      1.4439      2.2553      0.0052      0.1179
       final      0.7402      1.4404      2.2410      0.0000      0.0195
best loss step: 131
Max CUDA memory: 0.8219G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_73: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_73 in 14.10 minutes.
