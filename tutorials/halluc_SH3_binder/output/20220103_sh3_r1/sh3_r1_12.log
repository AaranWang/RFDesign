/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[19:56:32] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 12, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_12, length 93...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.9443      1.5885      2.9484      2.5739      0.0367
          10      0.9310      1.7627      2.8031      0.0001      0.0892
          20      0.9132      1.6726      2.7617      0.0295      0.0727
          30      0.9611      1.7245      2.6839      0.0000      0.3972
          40      0.8646      1.7336      2.5467      0.0000      0.0427
          50      0.9143      1.8502      2.4356      0.1217      0.0425
          60      1.0911      1.5721      2.6484      0.0000      1.2347
          70      0.9563      1.6717      2.6705      0.1859      0.0676
          80      1.2090      1.5898      2.7020      0.0000      1.7533
          90      0.9220      1.6151      2.7531      0.0000      0.2420
         100      0.8649      1.6235      2.6470      0.0000      0.0541
         110      0.8913      1.7362      2.7058      0.0005      0.0134
         120      0.8707      1.6203      2.4924      0.1089      0.0231
         130      0.8288      1.5937      2.5261      0.0000      0.0242
         140      1.6195      1.6797      2.6559      1.8330      0.0958
         150      1.1956      1.6021      2.6246      0.8530      0.0453
         160      0.8437      1.5057      2.5284      0.0677      0.0491
         170      0.8536      1.5810      2.5834      0.0000      0.1035
         180      0.7656      1.5334      2.2537      0.0000      0.0412
         190      0.8179      1.5997      2.4167      0.0291      0.0149
         200      0.8115      1.5360      2.4564      0.0000      0.0650
         210      0.7853      1.5279      2.3486      0.0000      0.0502
         220      0.7613      1.4958      2.2251      0.0276      0.0304
         230      0.7746      1.5309      2.3007      0.0000      0.0416
         240      0.8172      1.6336      2.4317      0.0001      0.0207
         250      0.7557      1.4913      2.2577      0.0055      0.0185
         260      0.7531      1.4762      2.1861      0.0343      0.0344
         270      0.7958      1.6435      2.2935      0.0000      0.0418
         280      0.7820      1.6376      2.2273      0.0000      0.0451
         290      0.7737      1.5366      2.2574      0.0192      0.0363
         300      0.7332      1.4985      2.1411      0.0000      0.0265
         310      0.7782      1.5711      2.2935      0.0000      0.0266
         320      0.8190      1.5132      2.4754      0.0417      0.0227
         330      0.8035      1.5469      2.4510      0.0000      0.0198
         340      0.7840      1.5880      2.3075      0.0000      0.0246
         350      0.7682      1.6274      2.1873      0.0000      0.0264
         360      0.7503      1.5195      2.2039      0.0000      0.0280
         370      0.7499      1.5524      2.1658      0.0004      0.0303
         380      0.7503      1.5275      2.1758      0.0000      0.0482
         390      0.7631      1.6439      2.1398      0.0000      0.0318
         400      0.7211      1.4971      2.0803      0.0001      0.0278
         410      0.7463      1.5523      2.1474      0.0000      0.0320
         420      0.7486      1.5535      2.1485      0.0030      0.0352
         430      0.7512      1.5389      2.1851      0.0000      0.0322
         440      0.7070      1.4514      2.0498      0.0000      0.0338
         450      0.7503      1.5269      2.1977      0.0000      0.0268
         460      0.7464      1.5585      2.1457      0.0002      0.0275
         470      0.7420      1.4345      2.2460      0.0000      0.0295
         480      0.7743      1.6123      2.2263      0.0000      0.0330
         490      0.7393      1.5528      2.1177      0.0001      0.0259
         500      0.7396      1.4705      2.1752      0.0000      0.0524
         510      0.7804      1.5382      2.3325      0.0000      0.0310
         520      0.7620      1.4957      2.2758      0.0000      0.0385
         530      0.7194      1.4645      2.1024      0.0000      0.0300
         540      1.9309      1.5444      2.4937      0.0000      5.6166
         550      0.7471      1.5070      2.1925      0.0000      0.0359
         560      0.7934      1.6247      2.3138      0.0013      0.0258
         570      0.7534      1.5480      2.1813      0.0000      0.0378
         580      0.7324      1.5512      2.0617      0.0108      0.0276
         590      0.7777      1.6089      2.2105      0.0224      0.0242
         600      1.1097      1.5097      2.1805      0.9175      0.0233
       final      0.6942      1.3915      2.0528      0.0023      0.0221
best loss step: 307
Max CUDA memory: 1.5123G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_12: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_12 in 15.87 minutes.

Generating sh3_r1_13, length 92...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      0.9375      1.6958      2.9012      0.0000      0.0908
          10      0.9972      1.5458      2.6018      0.0000      0.8385
          20      0.8791      1.6269      2.6643      0.0001      0.1041
          30      0.8639      1.5891      2.7053      0.0000      0.0249
          40      0.7950      1.5913      2.3501      0.0001      0.0337
          50      0.8068      1.5319      2.2875      0.0000      0.2147
          60      0.8001      1.5994      2.3624      0.0000      0.0386
          70      0.7524      1.5290      2.1817      0.0000      0.0516
          80      0.7763      1.5787      2.2610      0.0011      0.0396
          90      0.8662      1.5158      2.6043      0.0710      0.0690
         100      0.8330      1.5306      2.6001      0.0000      0.0344
         110      0.8181      1.5108      2.5542      0.0000      0.0258
         120      0.7988      1.5719      2.3659      0.0205      0.0152
         130      0.7578      1.5906      2.1734      0.0000      0.0249
         140      1.2792      1.5190      2.5917      0.0000      2.2854
         150      0.7748      1.4586      2.3921      0.0000      0.0233
         160      0.7076      1.4283      2.0816      0.0000      0.0280
         170      1.1215      1.5303      2.4460      0.0000      1.6314
         180      0.7405      1.5222      2.1430      0.0000      0.0376
         190      0.7683      1.4969      2.3101      0.0000      0.0343
         200      0.7173      1.4920      2.0639      0.0000      0.0306
         210      0.7467      1.5023      2.1935      0.0000      0.0378
         220      1.2061      1.4922      2.5239      0.0000      2.0143
         230      0.7209      1.4876      2.0877      0.0000      0.0289
         240      0.7683      1.4835      2.3079      0.0000      0.0501
         250      0.7296      1.4560      2.1600      0.0000      0.0321
         260      0.7807      1.4955      2.3837      0.0000      0.0244
         270      0.7432      1.4606      2.2206      0.0000      0.0347
         280      0.7138      1.4270      2.1104      0.0000      0.0317
         290      0.7640      1.5079      2.2647      0.0000      0.0472
         300      0.7409      1.4643      2.2018      0.0000      0.0383
         310      0.7354      1.4337      2.2132      0.0000      0.0299
         320      2.2072      1.5369      2.4225      0.0000      7.0766
         330      1.2789      1.4640      2.3736      0.0000      2.5567
         340      0.7427      1.5132      2.1490      0.0000      0.0514
         350      0.9212      1.5550      2.3407      0.0000      0.7101
         360      0.6947      1.4788      1.9532      0.0000      0.0416
         370      0.7403      1.4954      2.1736      0.0000      0.0323
         380      1.1148      1.5173      2.5147      0.0000      1.5419
         390      0.7203      1.4952      2.0660      0.0000      0.0402
         400      0.8110      1.5305      2.2974      0.0000      0.2272
         410      0.7336      1.4970      2.1336      0.0000      0.0373
         420      0.7300      1.4630      2.1576      0.0000      0.0295
         430      0.7561      1.5307      2.2238      0.0003      0.0254
         440      0.7635      1.5011      2.2832      0.0000      0.0331
         450      0.6764      1.3641      1.9883      0.0000      0.0295
         460      0.7574      1.4881      2.2657      0.0000      0.0331
         470      1.8974      1.5249      2.6050      1.2545      2.8482
         480      0.8418      1.4540      2.2951      0.2094      0.0413
         490      0.7492      1.4534      2.2461      0.0000      0.0466
         500      0.7271      1.4844      2.1183      0.0003      0.0322
         510      0.7801      1.4906      2.3665      0.0000      0.0432
         520      0.7368      1.4675      2.1902      0.0000      0.0265
         530      0.7457      1.5119      2.1842      0.0000      0.0322
         540      0.7776      1.4391      2.4170      0.0000      0.0317
         550      0.7264      1.4688      2.1323      0.0000      0.0307
         560      0.7885      1.4826      2.2034      0.1138      0.0290
         570      0.7534      1.4854      2.2447      0.0000      0.0369
         580      0.7260      1.4362      2.1536      0.0000      0.0401
         590      0.7109      1.4545      2.0635      0.0000      0.0364
         600      0.7254      1.4435      2.1434      0.0000      0.0400
       final      0.6764      1.3641      1.9883      0.0000      0.0295
best loss step: 450
Max CUDA memory: 1.4884G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_13: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_13 in 15.72 minutes.
