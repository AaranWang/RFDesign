/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[20:24:59] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 26, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_26, length 94...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.2444      1.6990      2.9304      0.0537      1.4853
          10      0.9753      1.7021      2.9803      0.0001      0.1937
          20      0.9882      1.6275      2.9738      0.1207      0.0982
          30      0.9560      1.6803      2.9926      0.0404      0.0266
          40      1.2796      1.5902      2.9689      0.9106      0.0179
          50      1.2129      1.5806      2.9447      0.7527      0.0339
          60      1.4383      1.6285      2.9554      1.2618      0.0841
          70      0.9111      1.5884      2.9387      0.0000      0.0286
          80      0.9192      1.5803      2.9786      0.0000      0.0370
          90      1.1772      1.5442      2.9820      0.6723      0.0151
         100      1.2969      1.6267      2.9725      0.0000      1.8851
         110      0.9316      1.6607      2.9866      0.0000      0.0110
         120      1.1851      1.6191      2.9719      0.6595      0.0153
         130      1.0317      1.5485      2.9970      0.3044      0.0042
         140      2.2422      1.5824      2.9324      3.3455      0.0051
         150      0.9096      1.4950      2.9852      0.0000      0.0680
         160      0.9029      1.5402      2.9589      0.0000      0.0154
         170      0.9091      1.5336      2.9798      0.0132      0.0055
         180      1.3961      1.5215      2.9883      0.0000      2.4709
         190      0.9318      1.5785      3.0038      0.0201      0.0363
         200      1.1261      1.5393      2.9472      0.4323      0.2794
         210      0.9146      1.6019      2.9111      0.0142      0.0315
         220      0.9419      1.5570      2.9663      0.0025      0.1810
         230      1.7035      1.6167      2.9251      1.9565      0.0628
         240      0.9171      1.5352      2.9372      0.0262      0.0608
         250      1.5346      1.5599      2.9186      1.5224      0.1494
         260      1.2073      1.5479      2.9171      0.7292      0.1131
         270      0.9143      1.5608      2.9532      0.0005      0.0567
         280      0.9044      1.5641      2.9424      0.0000      0.0152
         290      0.9128      1.5983      2.9535      0.0001      0.0119
         300      0.9328      1.5889      2.9403      0.0291      0.0764
         310      1.4408      1.6168      2.8048      1.2281      0.3264
         320      1.9616      1.6352      2.8890      2.5128      0.2582
         330      0.9158      1.5625      2.9139      0.0000      0.1025
         340      0.8907      1.5753      2.8559      0.0000      0.0222
         350      0.9007      1.5368      2.9474      0.0000      0.0194
         360      0.8959      1.5976      2.8505      0.0091      0.0133
         370      0.9208      1.6830      2.8542      0.0033      0.0602
         380      0.9004      1.6363      2.8274      0.0000      0.0384
         390      0.9353      1.6198      2.9196      0.0001      0.1371
         400      1.5947      1.5948      2.9288      1.7144      0.0210
         410      1.2466      1.5513      2.8752      0.5879      0.6306
         420      0.9102      1.6377      2.9071      0.0000      0.0063
         430      0.8863      1.5528      2.8635      0.0000      0.0149
         440      0.9354      1.6635      2.9737      0.0144      0.0112
         450      0.9143      1.6493      2.9020      0.0000      0.0199
         460      0.9682      1.6268      2.9050      0.1515      0.0060
         470      0.8827      1.6189      2.6901      0.0000      0.1046
         480      0.9069      1.5837      2.8060      0.0196      0.1058
         490      0.8594      1.6350      2.6193      0.0000      0.0429
         500      0.8573      1.6250      2.5848      0.0000      0.0769
         510      0.8568      1.5748      2.6559      0.0000      0.0533
         520      0.8497      1.6235      2.5226      0.0000      0.1026
         530      0.8335      1.5892      2.4933      0.0000      0.0852
         540      0.8781      1.5903      2.7068      0.0000      0.0934
         550      1.1000      1.5770      2.6675      0.6104      0.0347
         560      0.8320      1.6065      2.4912      0.0000      0.0622
         570      0.8187      1.5707      2.4631      0.0000      0.0597
         580      0.8686      1.6618      2.3548      0.1331      0.0601
         590      0.8308      1.5980      2.4948      0.0000      0.0609
         600      0.8194      1.6199      2.3937      0.0000      0.0833
       final      0.7821      1.5148      2.3275      0.0000      0.0681
best loss step: 587
Max CUDA memory: 1.5447G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_26: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_26 in 15.67 minutes.

Generating sh3_r1_27, length 62...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.5141      1.6205      2.8142      0.0000      3.1357
          10      0.9197      1.6389      2.9054      0.0008      0.0528
          20      0.9147      1.4659      2.9394      0.0000      0.1683
          30      1.7431      1.5751      2.9211      2.1064      0.0065
          40      0.8470      1.4528      2.7124      0.0000      0.0698
          50      1.0210      1.5813      2.5900      0.4614      0.0107
          60      0.9827      1.5301      2.6267      0.3620      0.0327
          70      0.8028      1.4805      2.5071      0.0000      0.0263
          80      0.7831      1.4960      2.4000      0.0001      0.0195
          90      0.7713      1.5332      2.3082      0.0000      0.0152
         100      0.8022      1.5639      2.4203      0.0000      0.0268
         110      0.7932      1.5320      2.4193      0.0000      0.0145
         120      0.8062      1.5008      2.4968      0.0000      0.0336
         130      0.7741      1.4735      2.3751      0.0000      0.0220
         140      0.8134      1.5398      2.3996      0.0000      0.1277
         150      0.7924      1.5251      2.3584      0.0000      0.0787
         160      0.7895      1.4567      2.4350      0.0000      0.0558
         170      0.8649      1.5910      2.5853      0.0000      0.1481
         180      1.6730      1.5065      2.5880      0.0000      4.2705
         190      0.7632      1.4502      2.2687      0.0000      0.0970
         200      1.5406      1.6267      2.5578      1.7376      0.0435
         210      0.7436      1.4405      2.2008      0.0000      0.0767
         220      0.8336      1.6706      2.4192      0.0000      0.0780
         230      0.8125      1.6015      2.3740      0.0001      0.0868
         240      0.7989      1.5537      2.3404      0.0000      0.1002
         250      0.8589      1.6163      2.5872      0.0000      0.0907
         260      0.7997      1.5391      2.3713      0.0000      0.0881
         270      0.7987      1.5545      2.3404      0.0170      0.0644
         280      0.8116      1.6404      2.3713      0.0000      0.0464
         290      0.8277      1.5968      2.4487      0.0000      0.0927
         300      0.7765      1.5009      2.3352      0.0000      0.0463
         310      0.7838      1.5796      2.2512      0.0000      0.0880
         320      0.7465      1.5066      2.1740      0.0000      0.0520
         330      0.8243      1.4978      2.4912      0.0343      0.0639
         340      0.7804      1.5728      2.2415      0.0000      0.0876
         350      0.8071      1.5552      2.4236      0.0000      0.0566
         360      1.0346      1.5775      2.5342      0.4975      0.0667
         370      0.7925      1.5400      2.3612      0.0000      0.0613
         380      0.7652      1.5119      2.2626      0.0011      0.0491
         390      0.8172      1.6293      2.3939      0.0000      0.0630
         400      0.7936      1.5871      2.3264      0.0000      0.0542
         410      0.7993      1.5061      2.4277      0.0000      0.0625
         420      0.7487      1.4700      2.1884      0.0000      0.0853
         430      0.7769      1.5341      2.3160      0.0001      0.0343
         440      0.8404      1.6700      2.4728      0.0167      0.0260
         450      0.8337      1.5392      2.5850      0.0000      0.0443
         460      0.7773      1.5844      2.2519      0.0000      0.0503
         470      0.8417      1.6185      2.3227      0.1168      0.0337
         480      0.7851      1.5688      2.3046      0.0000      0.0523
         490      0.7632      1.5165      2.2557      0.0000      0.0439
         500      0.7767      1.5489      2.2882      0.0000      0.0465
         510      0.8151      1.5806      2.4215      0.0000      0.0735
         520      0.7556      1.5023      2.2104      0.0000      0.0652
         530      0.7938      1.5604      2.3433      0.0000      0.0650
         540      0.8002      1.6472      2.3166      0.0000      0.0369
         550      0.7961      1.5435      2.3407      0.0000      0.0961
         560      0.7922      1.5255      2.3523      0.0000      0.0833
         570      0.7630      1.5374      2.1958      0.0000      0.0819
         580      0.7862      1.4851      2.3619      0.0000      0.0839
         590      0.7776      1.5257      2.2311      0.0000      0.1311
         600      0.8007      1.5697      2.3414      0.0001      0.0924
       final      0.7246      1.4777      2.1002      0.0000      0.0451
best loss step: 336
Max CUDA memory: 0.8264G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_27: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_27 in 13.24 minutes.
