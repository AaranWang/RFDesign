/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[19:56:32] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 14, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_14, length 91...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.2670      1.5812      2.9380      0.6219      0.5722
          10      1.4621      1.7202      2.7478      1.2815      0.2795
          20      2.8472      1.6945      2.5458      4.9282      0.1394
          30      0.7948      1.5845      2.2873      0.0000      0.1023
          40      0.8591      1.6109      2.5974      0.0001      0.0871
          50      0.7840      1.5030      2.2971      0.0000      0.1198
          60      0.8048      1.4861      2.4965      0.0000      0.0414
          70      0.8500      1.5706      2.5964      0.0000      0.0829
          80      0.8420      1.5792      2.4241      0.0392      0.1281
          90      0.7674      1.5076      2.2219      0.0000      0.1075
         100      0.7934      1.6572      2.2231      0.0000      0.0869
         110      0.8133      1.5724      2.4008      0.0007      0.0921
         120      0.7928      1.5769      2.2364      0.0324      0.0859
         130      0.9661      1.5383      2.2504      0.4659      0.1102
         140      0.8171      1.6485      2.3611      0.0024      0.0709
         150      0.7761      1.5544      2.2251      0.0000      0.1011
         160      0.9319      1.5180      2.1826      0.4378      0.0833
         170      0.7929      1.5059      2.3397      0.0126      0.0935
         180      0.7440      1.4382      2.1676      0.0000      0.1141
         190      0.9713      1.5260      2.2456      0.5010      0.0830
         200      2.6483      1.4948      2.6260      0.0000      9.1207
         210      1.5463      1.5238      2.6716      0.9845      1.5672
         220      1.2069      1.5752      2.6566      0.0000      1.8025
         230      1.3640      1.6339      2.7420      0.0000      2.4439
         240      0.8588      1.5717      2.6623      0.0000      0.0598
         250      1.2556      1.5416      2.6975      0.0000      2.0391
         260      1.1793      1.5074      2.6638      0.5199      0.6856
         270      0.8549      1.5930      2.5382      0.0002      0.1430
         280      0.8169      1.5383      2.2778      0.0747      0.1188
         290      0.7799      1.4278      2.3408      0.0000      0.1309
         300      0.7877      1.4637      2.3565      0.0000      0.1181
         310      0.8742      1.5487      2.6332      0.0001      0.1889
         320      1.0085      1.6249      2.4477      0.4409      0.0882
         330      1.6860      1.5250      2.4300      0.0000      4.4751
         340      0.8171      1.5099      2.3528      0.0685      0.0856
         350      0.7899      1.5007      2.3538      0.0000      0.0950
         360      0.7552      1.5156      2.1579      0.0006      0.1011
         370      0.7806      1.5887      2.1937      0.0000      0.1204
         380      0.7596      1.6692      2.0400      0.0001      0.0886
         390      0.7884      1.5294      2.2861      0.0165      0.0934
         400      0.7785      1.5811      2.2143      0.0000      0.0972
         410      0.9218      1.5046      2.1667      0.4151      0.1077
         420      0.9216      1.5017      2.1576      0.4255      0.0979
         430      0.7483      1.5024      2.1375      0.0000      0.1018
         440      0.7598      1.5025      2.1933      0.0004      0.1022
         450      0.7595      1.5387      2.1764      0.0000      0.0823
         460      0.7947      1.4833      2.1716      0.1171      0.0843
         470      0.7387      1.4768      2.1260      0.0000      0.0907
         480      0.7593      1.5567      2.1454      0.0000      0.0945
         490      0.7564      1.5306      2.1573      0.0000      0.0942
         500      0.7666      1.5590      2.2001      0.0001      0.0737
         510      0.7814      1.5377      2.2752      0.0058      0.0828
         520      0.7940      1.5929      2.1700      0.0541      0.0990
         530      0.7903      1.5879      2.2805      0.0001      0.0832
         540      0.7817      1.5727      2.2608      0.0015      0.0721
         550      1.9079      1.6084      2.5291      0.0000      5.4018
         560      0.7874      1.5570      2.2787      0.0000      0.1014
         570      0.7755      1.4925      2.2816      0.0001      0.1033
         580      0.7930      1.5016      2.2040      0.0904      0.0785
         590      0.7737      1.5283      2.2445      0.0000      0.0958
         600      0.7668      1.5097      2.2275      0.0012      0.0944
       final      0.7189      1.4514      2.0563      0.0000      0.0870
best loss step: 463
Max CUDA memory: 1.4532G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_14: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_14 in 16.20 minutes.

Generating sh3_r1_15, length 85...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      0.9115      1.6675      2.7934      0.0000      0.0966
          10      3.2835      1.7397      2.5933      6.0256      0.0334
          20      1.8855      1.8427      2.7524      1.4782      1.8758
          30      0.9013      1.6687      2.6888      0.0156      0.1180
          40      1.1752      1.6828      2.6490      0.7285      0.0874
          50      0.9225      1.6447      2.7135      0.0685      0.1171
          60      0.9031      1.6608      2.7459      0.0000      0.1086
          70      0.8933      1.6988      2.6760      0.0003      0.0908
          80      1.1771      1.5832      2.7312      0.0000      1.5710
          90      0.8465      1.5790      2.5146      0.0520      0.0349
         100      0.7947      1.5124      2.4120      0.0011      0.0472
         110      0.8323      1.5029      2.5855      0.0000      0.0733
         120      0.7517      1.4962      2.2196      0.0004      0.0419
         130      0.9488      1.3840      2.1081      0.5998      0.0520
         140      0.6950      1.3549      2.0441      0.0168      0.0424
         150      0.7110      1.4138      2.0612      0.0127      0.0545
         160      0.7042      1.4579      2.0250      0.0000      0.0383
         170      0.7152      1.4891      2.0454      0.0000      0.0416
         180      0.6747      1.3956      1.9241      0.0000      0.0538
         190      0.7047      1.4412      2.0187      0.0030      0.0576
         200      0.7198      1.4442      2.1017      0.0000      0.0529
         210      0.7002      1.4599      2.0055      0.0013      0.0327
         220      0.7313      1.3817      2.2131      0.0144      0.0332
         230      0.6975      1.4743      1.9865      0.0001      0.0263
         240      0.7008      1.3718      2.0927      0.0012      0.0373
         250      1.8444      1.4977      2.5151      0.0000      5.2092
         260      1.7523      1.4444      2.5718      0.0006      4.7444
         270      0.8280      1.4567      2.4026      0.0010      0.2784
         280      0.7879      1.4174      2.3387      0.0357      0.1119
         290      0.7665      1.4153      2.3492      0.0060      0.0560
         300      0.7987      1.5325      2.3929      0.0009      0.0662
         310      0.7104      1.4711      2.0355      0.0000      0.0454
         320      0.7581      1.5285      2.2193      0.0000      0.0428
         330      1.8690      1.4193      2.4873      0.0002      5.4383
         340      0.7203      1.4302      2.1180      0.0066      0.0403
         350      0.6769      1.4182      1.9310      0.0000      0.0351
         360      0.7274      1.3784      2.1018      0.0464      0.0638
         370      0.6911      1.3621      2.0168      0.0172      0.0423
         380      0.7605      1.4011      2.1786      0.0860      0.0508
         390      0.7086      1.4922      2.0230      0.0000      0.0277
         400      0.6997      1.4067      1.9786      0.0358      0.0413
         410      0.7066      1.3726      1.9858      0.0707      0.0328
         420      0.7080      1.3855      2.1132      0.0009      0.0398
         430      1.9380      1.4183      2.4960      0.1619      5.4517
         440      1.9045      1.4189      2.5018      0.5119      4.5779
         450      2.0178      1.4731      2.5254      0.2024      5.6855
         460      1.9657      1.3942      2.4408      0.0129      5.9678
         470      1.8735      1.4351      2.4429      0.0000      5.4892
         480      0.6874      1.3823      2.0012      0.0044      0.0449
         490      0.6913      1.3876      2.0265      0.0023      0.0378
         500      0.7378      1.4614      2.1881      0.0004      0.0388
         510      0.6994      1.3776      2.0762      0.0022      0.0391
         520      0.6846      1.3583      2.0229      0.0000      0.0416
         530      0.6762      1.4130      1.9224      0.0000      0.0457
         540      0.7217      1.4402      2.1046      0.0045      0.0546
         550      0.7651      1.4169      2.3343      0.0000      0.0745
         560      0.6818      1.3422      2.0166      0.0003      0.0499
         570      0.7679      1.3681      2.1488      0.1419      0.0387
         580      0.6834      1.3985      1.9865      0.0001      0.0318
         590      0.7011      1.3959      2.0696      0.0003      0.0392
         600      0.7063      1.4029      2.0628      0.0058      0.0544
       final      0.6593      1.3161      1.9319      0.0000      0.0484
best loss step: 579
Max CUDA memory: 1.3035G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_15: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_15 in 15.59 minutes.
