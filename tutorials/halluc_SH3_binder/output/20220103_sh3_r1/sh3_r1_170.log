/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[23:54:45] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 170, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_170, length 78...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      2.2187      1.6905      2.9630      0.8146      4.8111
          10      1.3367      1.7196      2.6849      1.1051      0.0690
          20      0.8833      1.6828      2.6828      0.0000      0.0506
          30      0.9615      1.5444      2.4310      0.3884      0.0552
          40      0.7799      1.5732      2.2741      0.0003      0.0517
          50      0.7732      1.4937      2.3067      0.0000      0.0656
          60      0.8898      1.5814      2.2222      0.2997      0.0462
          70      0.7846      1.4714      2.3868      0.0000      0.0647
          80      0.7992      1.5753      2.3828      0.0000      0.0379
          90      0.7632      1.4653      2.2912      0.0126      0.0342
         100      0.7367      1.4408      2.2012      0.0009      0.0398
         110      0.7390      1.4131      2.2240      0.0018      0.0544
         120      0.7538      1.4445      2.2761      0.0000      0.0486
         130      0.7454      1.4637      2.2205      0.0000      0.0428
         140      0.7647      1.4789      2.2233      0.0293      0.0628
         150      0.7860      1.5236      2.3773      0.0000      0.0292
         160      0.7798      1.5127      2.3601      0.0001      0.0262
         170      1.0717      1.5859      2.4070      0.0000      1.3657
         180      0.7628      1.4767      2.2830      0.0000      0.0543
         190      0.7375      1.4282      2.1967      0.0000      0.0623
         200      0.7424      1.4690      2.1873      0.0004      0.0550
         210      0.7890      1.5453      2.1214      0.1200      0.0383
         220      0.7939      1.4705      2.4596      0.0003      0.0388
         230      0.7570      1.4944      2.2604      0.0000      0.0304
         240      0.7693      1.5086      2.2819      0.0004      0.0552
         250      0.8060      1.6469      2.3380      0.0000      0.0449
         260      0.7879      1.5103      2.3803      0.0000      0.0487
         270      0.7735      1.4733      2.3638      0.0000      0.0304
         280      0.7130      1.4331      2.0763      0.0086      0.0385
         290      0.7442      1.4859      2.1964      0.0003      0.0381
         300      0.7784      1.6025      2.2510      0.0000      0.0383
         310      0.7474      1.5035      2.1810      0.0000      0.0523
         320      0.7683      1.5456      2.2616      0.0000      0.0343
         330      0.7352      1.4818      2.1649      0.0000      0.0293
         340      0.7859      1.5452      2.3492      0.0000      0.0353
         350      0.7430      1.4706      2.2046      0.0000      0.0398
         360      0.7304      1.4880      2.1020      0.0111      0.0396
         370      0.7384      1.4609      2.2032      0.0000      0.0280
         380      0.7811      1.6054      2.2679      0.0002      0.0317
         390      0.7645      1.4617      2.3132      0.0000      0.0476
         400      0.7513      1.5480      2.1644      0.0000      0.0442
         410      0.7478      1.4588      2.2421      0.0008      0.0365
         420      0.7514      1.4526      2.2492      0.0002      0.0551
         430      0.7936      1.4814      2.4468      0.0000      0.0397
         440      0.7374      1.4857      2.1645      0.0000      0.0368
         450      0.7843      1.5421      2.3381      0.0000      0.0416
         460      0.7139      1.4007      2.1343      0.0000      0.0343
         470      0.7699      1.5351      2.2584      0.0000      0.0562
         480      0.7372      1.3883      2.2553      0.0000      0.0424
         490      0.7912      1.4713      2.1743      0.1398      0.0310
         500      0.7567      1.4800      2.2580      0.0000      0.0454
         510      0.7619      1.4703      2.3062      0.0000      0.0332
         520      0.7334      1.4440      2.1284      0.0336      0.0274
         530      0.8055      1.4990      2.4875      0.0000      0.0409
         540      0.8063      1.5272      2.4719      0.0000      0.0322
         550      0.7146      1.4321      2.1024      0.0000      0.0384
         560      0.7454      1.4563      2.2306      0.0000      0.0401
         570      0.7321      1.4532      2.1797      0.0001      0.0273
         580      0.8628      1.6997      2.5951      0.0000      0.0189
         590      0.7873      1.5112      2.2930      0.0470      0.0384
         600      0.7459      1.4043      2.1230      0.0801      0.0417
       final      0.6876      1.3592      2.0391      0.0006      0.0383
best loss step: 553
Max CUDA memory: 1.1405G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_170: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_170 in 13.85 minutes.

Generating sh3_r1_171, length 55...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.5281      1.6216      2.9536      1.4658      0.1336
          10      1.6734      1.6791      2.9497      0.0000      3.7381
          20      0.9268      1.6826      2.8314      0.0529      0.0143
          30      0.9033      1.5998      2.9062      0.0000      0.0103
          40      0.9243      1.5828      2.8675      0.0000      0.1712
          50      0.9388      1.5731      2.8883      0.0000      0.2328
          60      0.8547      1.5216      2.7369      0.0016      0.0116
          70      0.8529      1.5456      2.7075      0.0001      0.0115
          80      1.3262      1.4788      2.7340      1.1859      0.0466
          90      0.8559      1.5204      2.7377      0.0000      0.0213
         100      0.8397      1.4958      2.6655      0.0003      0.0369
         110      0.8456      1.4792      2.7017      0.0000      0.0472
         120      0.8450      1.4871      2.6925      0.0000      0.0454
         130      0.8223      1.4450      2.6238      0.0086      0.0253
         140      0.8327      1.4109      2.6724      0.0258      0.0284
         150      0.8658      1.5140      2.7567      0.0000      0.0583
         160      0.8231      1.4412      2.6568      0.0006      0.0161
         170      0.7805      1.3470      2.5002      0.0001      0.0549
         180      1.0147      1.4434      2.7288      0.3977      0.1061
         190      1.3512      1.4765      2.6992      1.2772      0.0257
         200      0.8602      1.6576      2.5981      0.0012      0.0429
         210      0.9744      1.4765      2.6740      0.3238      0.0738
         220      1.2295      1.6150      2.7617      0.8774      0.0160
         230      0.8965      1.4777      2.6906      0.1466      0.0212
         240      0.8344      1.4727      2.6797      0.0000      0.0197
         250      0.8575      1.5202      2.7229      0.0000      0.0444
         260      1.5222      1.5380      2.7564      1.6466      0.0233
         270      0.8961      1.4985      2.6473      0.1387      0.0570
         280      0.8592      1.5021      2.7390      0.0028      0.0493
         290      0.8370      1.5152      2.6499      0.0004      0.0192
         300      1.5232      1.4808      2.7958      1.6092      0.1211
         310      0.8617      1.4563      2.8437      0.0003      0.0078
         320      1.6538      1.5413      2.7664      1.9378      0.0854
         330      0.8701      1.4855      2.7852      0.0000      0.0798
         340      0.8405      1.5104      2.6439      0.0000      0.0483
         350      1.2087      1.4969      2.8522      0.8305      0.0336
         360      0.8284      1.4774      2.6099      0.0000      0.0547
         370      0.8435      1.5389      2.6395      0.0007      0.0379
         380      0.9070      1.4919      2.7469      0.0000      0.2959
         390      1.3473      1.4598      2.8330      0.8284      0.7870
         400      0.8537      1.4443      2.5785      0.0003      0.2450
         410      1.2249      1.4779      2.9038      0.8486      0.0457
         420      1.1735      1.5500      2.8686      0.6401      0.1689
         430      0.9110      1.4483      2.8581      0.1049      0.0389
         440      0.9618      1.4850      2.8426      0.2337      0.0137
         450      1.0719      1.4576      2.6172      0.6308      0.0230
         460      0.8331      1.4866      2.6426      0.0000      0.0361
         470      0.8607      1.4586      2.7876      0.0000      0.0572
         480      0.9019      1.4290      2.6129      0.2118      0.0443
         490      0.8091      1.4161      2.4409      0.0620      0.0644
         500      0.8581      1.4193      2.5942      0.1081      0.0609
         510      0.8474      1.5239      2.6536      0.0093      0.0411
         520      0.8634      1.5844      2.6834      0.0000      0.0493
         530      0.8221      1.4459      2.6090      0.0000      0.0555
         540      0.8057      1.4390      2.5494      0.0000      0.0400
         550      0.9831      1.4899      2.8238      0.0041      0.5935
         560      1.2625      1.5114      2.7551      0.5927      0.8607
         570      1.0984      1.5015      2.8640      0.0001      1.1264
         580      0.9522      1.4989      2.8531      0.0244      0.3603
         590      0.8693      1.6210      2.6302      0.0000      0.0953
         600      0.9043      1.5585      2.6287      0.0000      0.3343
       final      0.7695      1.3827      2.4310      0.0000      0.0338
best loss step: 163
Max CUDA memory: 0.7037G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_171: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_171 in 13.05 minutes.
