/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[19:52:46] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
/mnt/home/dzorine/software/homog/homog/homog.py:98: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if degrees is 'auto': degrees = guess_is_degrees(angle)
[22:22:39] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: libtorch_cuda_cpp.so: cannot open shared object file: No such file or directory
Using backend: pytorch
--steps was given. Ignoring --grad_steps, --mcmc_steps.

Run settings:
{'network_name': 'rf_Nov05_2021', 'use_template': None, 'num': 2, 'start_num': 104, 'msa_num': 1, 'out': '/mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1', 'cautious': 1, 'save_pdb': 1, 'save_batch_fas': False, 'track_step': 10, 'track_logits': False, 'out_step': None, 'seed_rng': False, 'steps': 'g600', 'grad_steps': 400, 'mcmc_steps': 0, 'optimizer': 'nsgd', 'drop': 0.2, 'init_sd': 1e-06, 'learning_rate': 0.05, 'grad_check': True, 'logit_scale': 1, 'seq_prob_type': 'hard', 'seq_sample': False, 'calc_bkg': True, 'cce_sd': None, 'hal_sd': None, 'corrupt_sequence': None, 'corrupt_fraction': None, 'pdb': '/mnt/home/jue/halluc/linear_motifs/input/SH3_2w0z.pdb', 'mask': None, 'contigs': 'B7-14', 'con_set_id': None, 'len': '55-100', 'keep_order': False, 'contig_min_gap': 5, 'spike': None, 'spike_fas': None, 'force_aa': 'B7-14', 'exclude_aa': 'C', 'force_aa_hal': None, 'template_pdbs': None, 'no_bkg_mask': False, 'num_repeats': 0, 'init_seq': None, 'masks_bkg': None, 'masks_pass': None, 'force_logits': None, 'receptor': None, 'rec_placement': 'second', 'gap': 200, 'w_cce': 1, 'w_crmsd': -1, 'w_entropy': 1, 'w_kl': -1, 'n_bkg': 100, 'w_rep': 2.0, 'w_set_rep': -1, 'w_atr': -1, 'w_set_atr': -1, 'w_rog': 1.0, 'w_aspect_ratio': -1, 'w_cyc_sym': -1, 'w_surfnp': -1, 'w_nc': -1, 'w_cce_bg': -1, 'w_sym': -1, 'cce_cutoff': 19.9, 'rep_pdb': 'input/SH3_2w0z_rec.pdb', 'rep_sigma': 3.5, 'atr_pdb': None, 'atr_sigma': 5, 'entropy_beta': 10, 'rog_thresh': 16.0, 'surfnp_nbr_thresh': 2.5, 'nc_target': -7, 'entropy_dist_bins': 16, 'mcmc_halflife': 500.0, 'T_acc_0': 0.002, 'mcmc_batch': 1, 'anneal_t1d': False, 'erode_template': False, 'num_masked_tokens': 1, 'weights_dir': '/projects/ml/trDesign', 'nthreads': 4, 'cce_cutstep': None, 'cce_thresh': 2.2, 'batch': 64, 'lr': 0.2, 'nsteps': 100, 'commit': 'c344913efafbbfe8f452574b0c86c348792a5045'}

Loading structure prediction model onto device cuda:0...
#   trunk_msa_v00     [ens=1]   AF2-inspired 12-block 2-track trunk
#   trunk_tbm_v00     [ens=1]   AF2-inspired 3-track trunk
#   rf_v00            [ens=1]   RoseTTAFold 3-track trunk + refiner (formerly trunk_e2e_v00)
# * rf_Nov05_2021     [ens=1]   RoseTTAFold 3-track, no perceiver, Nov. 5 2021
#   rf_perceiver_v00  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=zeros)
#   rf_perceiver_v01  [ens=1]   RoseTTAFold w/ Perceiver & FAPE loss (msa_full=msa_latent)
#   af2_v00           [ens=0]   AlphaFold2 (only works with rescue.py)
Loaded sequence-to-structure model rf_Nov05_2021 with 66037142 parameters

Model hyperparameters:
{'SE3_param': {'div': 4, 'l0_in_features': 32, 'l0_out_features': 32, 'l1_in_features': 3, 'l1_out_features': 2, 'n_heads': 4, 'num_channels': 32, 'num_degrees': 2, 'num_edge_features': 32, 'num_layers': 3}, 'd_hidden': 32, 'd_hidden_templ': 64, 'd_msa': 256, 'd_msa_full': 64, 'd_pair': 128, 'd_templ': 64, 'n_head_msa': 8, 'n_head_pair': 4, 'n_head_templ': 4, 'n_module_2track': 24, 'n_module_3track': 8, 'p_drop': 0.0}

Using CUDA device(s):  cuda:0: (GeForce RTX 2080); 

Parsing input pdb...

Generating sh3_r1_104, length 88...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.1388      1.9011      2.9543      0.0001      0.8386
          10      0.9318      1.6308      2.9246      0.0000      0.1035
          20      0.9220      1.5494      2.7631      0.0920      0.1136
          30      0.9897      1.7343      2.8290      0.1903      0.0049
          40      1.1634      1.7214      2.8096      0.2485      0.7890
          50      0.8499      1.6308      2.6023      0.0000      0.0166
          60      0.8454      1.5816      2.6090      0.0000      0.0366
          70      0.8368      1.5780      2.5980      0.0000      0.0082
          80      0.8250      1.5578      2.5507      0.0000      0.0165
          90      0.9043      1.5875      2.5593      0.0125      0.3496
         100      0.7897      1.5299      2.4037      0.0000      0.0149
         110      0.7647      1.4683      2.3415      0.0000      0.0139
         120      0.7837      1.5875      2.3204      0.0000      0.0107
         130      0.7651      1.5693      2.2328      0.0000      0.0236
         140      0.7426      1.5269      2.1739      0.0000      0.0122
         150      0.7990      1.4888      2.4975      0.0000      0.0086
         160      0.7716      1.5484      2.2958      0.0000      0.0141
         170      0.8385      1.5163      2.4519      0.0000      0.2243
         180      0.8037      1.4885      2.4245      0.0000      0.1052
         190      0.8224      1.6599      2.4013      0.0000      0.0508
         200      0.8232      1.5971      2.4607      0.0000      0.0581
         210      0.8033      1.5243      2.4196      0.0000      0.0725
         220      0.7864      1.4528      2.3581      0.0000      0.1213
         230      0.7745      1.6128      2.1995      0.0000      0.0604
         240      0.7487      1.5256      2.1249      0.0000      0.0929
         250      2.1754      1.4061      2.5139      0.0023      6.9525
         260      0.7070      1.4262      1.9586      0.0195      0.1112
         270      0.7198      1.4234      2.0941      0.0000      0.0813
         280      0.7404      1.5923      2.0390      0.0003      0.0700
         290      0.7142      1.4345      2.0466      0.0012      0.0876
         300      0.6971      1.4436      1.9634      0.0000      0.0785
         310      0.7091      1.4853      1.9603      0.0002      0.0994
         320      0.7504      1.4910      2.1904      0.0014      0.0680
         330      0.6963      1.4392      1.9651      0.0000      0.0774
         340      0.7802      1.5008      2.3148      0.0000      0.0854
         350      0.7048      1.4815      1.9578      0.0000      0.0845
         360      0.6999      1.4369      1.9769      0.0000      0.0858
         370      0.6954      1.4126      1.9743      0.0000      0.0898
         380      0.7117      1.4718      2.0151      0.0000      0.0717
         390      0.7472      1.5046      2.1389      0.0000      0.0924
         400      0.7122      1.5145      1.9602      0.0000      0.0862
         410      0.6799      1.4230      1.8994      0.0000      0.0770
         420      0.7031      1.4580      1.9640      0.0000      0.0937
         430      0.7253      1.5702      1.9818      0.0000      0.0743
         440      0.6935      1.4580      1.9393      0.0000      0.0700
         450      0.7253      1.4639      2.0862      0.0000      0.0765
         460      0.7082      1.4440      2.0279      0.0000      0.0689
         470      0.7042      1.4301      2.0075      0.0000      0.0831
         480      1.9948      1.6231      2.3256      0.0042      6.0171
         490      1.5035      1.4833      2.3527      0.0001      3.6814
         500      0.8059      1.4373      2.3198      0.0907      0.0910
         510      0.7579      1.4508      2.1433      0.0000      0.1952
         520      0.7113      1.4151      2.0625      0.0000      0.0788
         530      0.6988      1.4063      2.0073      0.0000      0.0805
         540      0.6951      1.4319      1.9618      0.0000      0.0820
         550      0.7133      1.4359      2.0497      0.0000      0.0809
         560      2.0592      1.4405      2.4455      0.0001      6.4099
         570      0.7622      1.5035      2.2219      0.0000      0.0854
         580      2.1518      1.4615      2.4332      0.0000      6.8642
         590      0.6948      1.4023      2.0031      0.0000      0.0687
         600      0.7407      1.4467      2.1579      0.0000      0.0987
       final      0.6663      1.3318      1.9262      0.0000      0.0738
best loss step: 549
Max CUDA memory: 1.3862G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_104: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_104 in 15.12 minutes.

Generating sh3_r1_105, length 83...
Forcing amino acids:  B7P,B8P,B9P,B10R,B11P,B12P,B13K,B14P
Loss term           | Weight      
cce                   1.00
entropy               1.00
rep                   2.00
rog                   1.00

Stage 0
Starting gradient descent...
        step    avg loss         cce     entropy         rep         rog
           0      1.2796      1.7698      2.8115      0.0001      1.8165
          10      2.0068      2.0103      2.8949      1.3347      2.4594
          20      0.9613      1.7689      2.9103      0.0598      0.0076
          30      1.5247      1.8202      2.7751      0.0001      3.0282
          40      1.5602      1.7894      2.6789      1.6570      0.0186
          50      0.8732      1.6972      2.6462      0.0001      0.0227
          60      0.8892      1.6513      2.5955      0.0002      0.1987
          70      1.5765      1.6778      2.6231      1.7810      0.0198
          80      0.8116      1.6821      2.3099      0.0000      0.0660
          90      0.7920      1.6057      2.2889      0.0000      0.0655
         100      0.7902      1.5763      2.3334      0.0001      0.0409
         110      0.7710      1.5969      2.2250      0.0003      0.0322
         120      0.7906      1.6424      2.2838      0.0003      0.0259
         130      0.8084      1.5410      2.4620      0.0001      0.0389
         140      1.2342      1.5104      2.4214      0.0285      2.1823
         150      1.2229      1.4440      2.4177      0.0000      2.2528
         160      0.7959      1.5055      2.4183      0.0000      0.0559
         170      0.7712      1.4649      2.3439      0.0000      0.0471
         180      0.7712      1.5063      2.3161      0.0001      0.0334
         190      0.9536      1.5143      2.5114      0.0000      0.7425
         200      0.8186      1.5737      2.2958      0.0909      0.0414
         210      1.0020      1.4998      2.4196      0.5352      0.0201
         220      0.8431      1.6448      2.4858      0.0000      0.0848
         230      0.8330      1.6369      2.5108      0.0003      0.0165
         240      0.8437      1.5355      2.6270      0.0000      0.0561
         250      0.8892      1.6517      2.5921      0.0889      0.0247
         260      0.8515      1.5526      2.5741      0.0000      0.1305
         270      1.7050      1.5385      2.5521      0.4420      3.5504
         280      0.8117      1.4838      2.5264      0.0000      0.0485
         290      0.7758      1.4756      2.2519      0.0000      0.1513
         300      0.7411      1.4344      2.2122      0.0000      0.0590
         310      0.7720      1.4575      2.3696      0.0000      0.0329
         320      0.8191      1.4383      2.2823      0.1406      0.0938
         330      0.8078      1.5273      2.3311      0.0718      0.0367
         340      1.2318      1.4479      2.3874      0.0000      2.3238
         350      0.7402      1.4201      2.2269      0.0000      0.0538
         360      1.3913      1.3840      2.3853      0.0509      3.0855
         370      0.6936      1.3779      2.0321      0.0000      0.0578
         380      0.7508      1.3760      2.3011      0.0000      0.0770
         390      0.9260      1.4156      2.1698      0.4944      0.0559
         400      0.8021      1.3925      2.1357      0.2159      0.0503
         410      0.7882      1.4485      2.4299      0.0000      0.0625
         420      0.7724      1.5500      2.2846      0.0000      0.0275
         430      0.9142      1.3691      2.4157      0.3517      0.0828
         440      0.7472      1.4603      2.2001      0.0053      0.0648
         450      0.8754      1.4421      2.1842      0.3592      0.0324
         460      0.7333      1.4382      2.1639      0.0000      0.0643
         470      0.7161      1.4474      2.0802      0.0000      0.0529
         480      0.7868      1.5785      2.3139      0.0000      0.0417
         490      0.7459      1.3819      2.1844      0.0448      0.0737
         500      2.1566      1.4036      2.4250      0.0003      6.9535
         510      0.7569      1.4269      2.2637      0.0000      0.0938
         520      0.7237      1.4478      2.1175      0.0009      0.0513
         530      0.7074      1.4445      2.0470      0.0003      0.0448
         540      0.7460      1.4258      2.1787      0.0469      0.0317
         550      0.7453      1.5080      2.1617      0.0000      0.0571
         560      0.7030      1.3778      2.0803      0.0000      0.0569
         570      0.6889      1.4325      1.9752      0.0000      0.0370
         580      0.7193      1.4302      2.0616      0.0258      0.0531
         590      0.7225      1.5304      2.0365      0.0000      0.0459
         600      0.6656      1.3593      1.9250      0.0000      0.0434
       final      0.6656      1.3593      1.9250      0.0000      0.0434
best loss step: 600
Max CUDA memory: 1.2560G
Saving /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_105: npz, fas, trb, trk, trfold pdb
Finished design /mnt/home/jue/halluc/linear_motifs/output/20220103_sh3_r1/sh3_r1_105 in 14.71 minutes.
