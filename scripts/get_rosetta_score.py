#!/software/conda/envs/pyrosetta/bin/python3.7
#
# Performs a short relax (same as in trfold_relax.py) and then saves Rosetta
# energy and score terms. Used to get Rosetta energy for structures that
# weren't generated by trfold_relax.sh (i.e. AF2 models)
# 
#
# Usage:
#
#   ./get_rosetta_score.py FOLDER
#
# where FOLDER contains PDBs of complexes you want to score.
#

import pandas as pd
import numpy as np
import os, glob, argparse, multiprocessing

import pyrosetta
from pyrosetta import *

script_dir = os.path.dirname(__file__)
DATADIR = '/home/jue/git/rfdesign/scripts/RosettaTR/data/'

p = argparse.ArgumentParser()
p.add_argument('data_dir', help='Folder of FastDesign outputs to process.')
p.add_argument('--out_dir', default='short_relax', help='Output folder for relaxed structures. Relative to data_dir')
p.add_argument('--out_suffix', default='', help='Output file name suffix for relaxed structures.')
p.add_argument('--out', help='Output file name. Default: rosetta_scores.csv')
args = p.parse_args()

if args.out is None: args.out = os.path.join(args.data_dir, 'rosetta_scores.csv')
outdir = os.path.join(args.data_dir, args.out_dir)
os.makedirs(outdir, exist_ok=True)


def add_crd_rst(pose, nres, std=1.0, tol=1.0):
    flat_har = rosetta.core.scoring.func.FlatHarmonicFunc(0.0, std, tol)
    rst = list()
    for i in range(1, nres+1):
        xyz = pose.residue(i).atom("CA").xyz() # xyz coord of CA atom
        ida = rosetta.core.id.AtomID(2,i) # CA idx for residue i
        rst.append(rosetta.core.scoring.constraints.CoordinateConstraint(ida, ida, xyz, flat_har))

    if len(rst) < 1:
        return

    cset = rosetta.core.scoring.constraints.ConstraintSet()
    [cset.add_constraint(a) for a in rst]

    # add to pose
    constraints = rosetta.protocols.constraint_movers.ConstraintSetMover()
    constraints.constraint_set(cset)
    constraints.add_constraints(True)
    constraints.apply(pose)

def calculate(fn):
    pose0 = pose_from_file(fn)
    print(f'Scoring {fn}...')

    mmap = MoveMap()
    mmap.set_bb(True)
    mmap.set_chi(True)
    mmap.set_jump(True)

    # First round: Repeat 2 torsion space relax w/ strong disto/anglogram constraints
    sf_fa_round1 = create_score_function('ref2015_cart')
    sf_fa_round1.set_weight(rosetta.core.scoring.atom_pair_constraint, 3.0)
    sf_fa_round1.set_weight(rosetta.core.scoring.dihedral_constraint, 1.0)
    sf_fa_round1.set_weight(rosetta.core.scoring.angle_constraint, 1.0)
    sf_fa_round1.set_weight(rosetta.core.scoring.pro_close, 0.0)

    relax_round1 = rosetta.protocols.relax.FastRelax(sf_fa_round1, f"{DATADIR}/relax_round1.txt")
    relax_round1.set_movemap(mmap)
    relax_round1.apply(pose0)

    rosetta.basic.options.set_real_option('in:detect_disulf_tolerance', 0.5)

    sf_fa = create_score_function('ref2015_cart')
    sf_fa.set_weight(rosetta.core.scoring.atom_pair_constraint, 0.1)
    sf_fa.set_weight(rosetta.core.scoring.dihedral_constraint, 0.0)
    sf_fa.set_weight(rosetta.core.scoring.angle_constraint, 0.0)

    relax_round2 = rosetta.protocols.relax.FastRelax(sf_fa, f"{DATADIR}/relax_round2.txt")
    relax_round2.set_movemap(mmap)
    relax_round2.cartesian(True)
    relax_round2.dualspace(True)

    L = len(pose0.sequence())

    pose0.conformation().detect_disulfides()
    add_crd_rst(pose0, L, std=1.0, tol=2.0)
    relax_round2.apply(pose0)

    # Re-evaluate score w/o any constraints
    scorefxn_min=create_score_function('ref2015_cart')
    scorefxn_min.score(pose0)

    record = dict(pose0.scores) # so we can add the 'name' key below
    name = os.path.basename(fn).replace('.pdb','')
    record['name'] = name

    # save relaxed structure
    pose0.dump_pdb(os.path.join(outdir, name+args.out_suffix+'.pdb'))

    return record

init("-multithreading:interaction_graph_threads 1 -multithreading:total_threads 1 "\
     "-hb_cen_soft -mute all "\
     "-detect_disulf -detect_disulf_tolerance 2.0 "\
     "-relax:dualspace true -relax::minimize_bond_angles -default_max_cycles 200 ")

ncpu = len(os.sched_getaffinity(0))
print(f'Using {ncpu} cores')

files = glob.glob(os.path.join(args.data_dir, f'*.pdb'))
with multiprocessing.Pool(ncpu) as p:
    records = p.map(calculate, files)
df = pd.DataFrame.from_records(records)
df.to_csv(args.out)

